{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome\n#\n\n\nI don\nt know what\ns going on here\n#\n\n\n\n\nAbout this documentation\n#\n\n\nCollecting tips and tricks is huge fun. I am doing it \nalong the way\n every time I get stuck and later find the solution. Every bit of information here has at some point proved to be useful to me. So, the documentation is never complete and finished. \nIt is always \nwork in progress\n.\n\n\n\n\nInstalling prerequisites\n#\n\n\nIn order to view the documents offline, you need Python and the following dependencies:\n\n\npip install -U mkdocs pygments pymdown-extensions\npip install -U fontawesome-markdown\n\n\n\n\n\n\n\nRunning the project in DEV\n#\n\n\nOpen the command prompt in the project root directory and type:\n\n\nmkdocs serve\n\n\n\n\n\nThen open your browser and navigate to \nhttp://localhost:8000\n.\n\n\n\n\nPublishing the project\n#\n\n\nTo publish the project to \nGitHub Pages\n as a subdomain, e.g. \n/kdocs\n of the main \nyour-github-login.github.io\n website, one needs first to create the repository with that name, e.g. \nkdocs\n and add it to one\ns project as a remote. Now, open the command prompt in the root directory (on the \nmaster\n branch) and type:\n\n\nmkdocs gh-publish\n\n\n\n\n\nAfter that, the project website is available at \nyour-github-login.github.io/kdocs\n.\n\n\n\n\nThemes\n#\n\n\n\n\nMkDocs Themes\n\n\n12 \nBootswatch\n themes\n\n\nCinder\n theme\n\n\nAlabaster\n theme (quite simple)\n\n\nBootstrap\n theme\n\n\n\n\n\n\nReferences\n#\n\n\nHere are the most important links that have inspired me:\n\n\n\n\nLatest official MkDocs \ndocumentation\n\n\nMkDocs \nUser Guide", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome", 
            "text": "", 
            "title": "Welcome"
        }, 
        {
            "location": "/#i-dont-know-whats-going-on-here", 
            "text": "", 
            "title": "I don't know what's going on here"
        }, 
        {
            "location": "/#about-this-documentation", 
            "text": "Collecting tips and tricks is huge fun. I am doing it  along the way  every time I get stuck and later find the solution. Every bit of information here has at some point proved to be useful to me. So, the documentation is never complete and finished.  It is always  work in progress .", 
            "title": "About this documentation"
        }, 
        {
            "location": "/#installing-prerequisites", 
            "text": "In order to view the documents offline, you need Python and the following dependencies:  pip install -U mkdocs pygments pymdown-extensions\npip install -U fontawesome-markdown", 
            "title": "Installing prerequisites"
        }, 
        {
            "location": "/#running-the-project-in-dev", 
            "text": "Open the command prompt in the project root directory and type:  mkdocs serve  Then open your browser and navigate to  http://localhost:8000 .", 
            "title": "Running the project in DEV"
        }, 
        {
            "location": "/#publishing-the-project", 
            "text": "To publish the project to  GitHub Pages  as a subdomain, e.g.  /kdocs  of the main  your-github-login.github.io  website, one needs first to create the repository with that name, e.g.  kdocs  and add it to one s project as a remote. Now, open the command prompt in the root directory (on the  master  branch) and type:  mkdocs gh-publish  After that, the project website is available at  your-github-login.github.io/kdocs .", 
            "title": "Publishing the project"
        }, 
        {
            "location": "/#themes", 
            "text": "MkDocs Themes  12  Bootswatch  themes  Cinder  theme  Alabaster  theme (quite simple)  Bootstrap  theme", 
            "title": "Themes"
        }, 
        {
            "location": "/#references", 
            "text": "Here are the most important links that have inspired me:   Latest official MkDocs  documentation  MkDocs  User Guide", 
            "title": "References"
        }, 
        {
            "location": "/engine/technicalities/", 
            "text": "Some technical details\n#\n\n\n\n\n\n\nSome technical details\n\n\nProject layout\n\n\nUseful Commands\n\n\nFont Awesome\n\n\nExamples\n\n\n\n\n\n\nDeployment to GitHub Pages\n\n\nDeployment to GitHub pages via Travis CI\n\n\n\n\n\n\n\n\n\n\n\n\nProject layout\n#\n\n\nmkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n\n\n\n\n\n\n\nUseful Commands\n#\n\n\n\n\nmkdocs new [dir-name]\n - Create a new project.\n\n\nmkdocs serve\n - Start the live-reloading docs server.\n\n\nmkdocs build\n - Build the documentation site.\n\n\nmkdocs help\n - Print this help message.\n\n\n\n\n\n\nFont Awesome\n#\n\n\nFont Awesome\n gives you scalable vector icons that can instantly be customized \n size, color, drop shadow, and anything that can be done with the power of CSS. For more inpiration see these \nexamples\n.\n\n\nFont Awesome Markdown\n is a Markdown extension that looks for things like \n:fa-coffee:\n (\n) or \n:fa-refresh:\n (\n) and replaces them with the Font Awesome icon markup.\n\n\nExamples\n#\n\n\nThis examples use the fontawesome_markdown extension:\n\n\nWhat would you drink, :fa-coffee: or :fa-beer:?\n\n\n\n\n\nWhat would you drink, \n or \n?\n\n\nFor this example, you must install the \nfontawesome_markdown\n extension with \npip\n. Right now version \n0.2.5\n is the latest but it doesn\nt work out of the box. Instead, you have to install the latest version from the github repository. You can do that with the command below:\n\n\npip install https://github.com/bmcorser/fontawesome-markdown/archive/master.zip\n\n\n\n\n\nYou may need to include \n-U\n in the above command if you already have this extension installed.\n\n\nThen add the below to your \nmkdocs.yml\n file.\n\n\nmarkdown_extensions:\n  - fontawesome_markdown`\n\n\n\n\n\n\n\nDeployment to GitHub Pages\n#\n\n\nThe first step you\nll need to do is simply make sure you have a \ngh-pages\n branch that exists, if it doesn\nt:\n\n\ngit checkout -b gh-pages\ngit rm -rf .\ngit push --set-upstream origin gh-pages\n\n\n\n\n\nThen run this command:\n\n\nmkdocs gh-deploy\n\n\n\n\n\nThis will push the \nmaster\n  branch to the remote \ngh-pages\n. After that, you can view your website here:\n\n\nhttp://your-github-name.github.io/mkdocs-repo-name\n\n\n\n\nDeployment to GitHub pages via Travis CI\n#\n\n\nGo to your GitHub account and create a new \nPersonal access token\n in your Developer settings. Copy the hash string.\n\n\n\n\nKeep well the hash string!\n\n\nYou will see it only once when you create it.\n\n\n\n\nIn the Travis CI settings of your project add a new \nGH_TOKEN\n environment variable with the value of the hash string your have just copied. Don\nt forget to turn in \nON\n and to \nADD\n.\n\n\nConfigure the \n.travis.yml\n file. You may start with something like this:\n\n\nsudo\n:\n \nfalse\n\n\nlanguage\n:\n \npython\n\n\npython\n:\n \n2.7\n\n\ninstall\n:\n\n\n-\n \npip install --upgrade pip\n\n\n-\n \npip install -r requirements.txt\n\n\n-\n \npip install https://github.com/bmcorser/fontawesome-markdown/archive/master.zip\n\n\nscript\n:\n\n\n-\n \ngit config credential.helper \nstore --file=.git/credentials\n\n\n-\n \necho \nhttps://${GH_TOKEN}:@github.com\n \n .git/credentials\n\n\n-\n \nmkdocs build\n\n\n-\n \nif [ $TRAVIS_TEST_RESULT == 0 ]; then\n\n    \nmkdocs gh-deploy --force;\n\n  \nfi\n\n\n\n\n\n\nThe credentials here are necessary for the Travis agent to be able to connect to your Github repository and perform the necessary actions with it. Note that the credentials are based on the \nPersonal access token\n you have created. \n\n\nAlso, I have put deployment inside the \nscript\n fase instead of \nafter_success\n as a workaround (see the tip of Chronial on this \nTravis issue #758\n). Otherwise, the batch succeeds with a successful build even if deploy \nfails\n after it.\n\n\nNext, you need to have \ntravis\n Rubygem installed on your local machine. If not, install it:\n\n\ngem install travis\n\n\n\n\n\nUsing \ntravis\n, add the encrypted token to \n.travis.yml\n: \n\n\ntravis encrypt \nGH_TOKEN\n=\nthe-token-from-github\n --add\n\n\n\n\n\nThis will add the following block at the end of the file:\n\n\nenv\n:\n\n  \nglobal\n:\n\n  \n-\n \nsecure\n:\n \nlots-of-seemingly-random-characters\n\n\n\n\n\n\nNow, when you push your changes to the remote \nmaster\n, Travis CI should publish the compiled website to \nGitHub Pages\n if the build succeeds.", 
            "title": "Technicalities"
        }, 
        {
            "location": "/engine/technicalities/#some-technical-details", 
            "text": "Some technical details  Project layout  Useful Commands  Font Awesome  Examples    Deployment to GitHub Pages  Deployment to GitHub pages via Travis CI", 
            "title": "Some technical details"
        }, 
        {
            "location": "/engine/technicalities/#project-layout", 
            "text": "mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.", 
            "title": "Project layout"
        }, 
        {
            "location": "/engine/technicalities/#useful-commands", 
            "text": "mkdocs new [dir-name]  - Create a new project.  mkdocs serve  - Start the live-reloading docs server.  mkdocs build  - Build the documentation site.  mkdocs help  - Print this help message.", 
            "title": "Useful Commands"
        }, 
        {
            "location": "/engine/technicalities/#font-awesome", 
            "text": "Font Awesome  gives you scalable vector icons that can instantly be customized   size, color, drop shadow, and anything that can be done with the power of CSS. For more inpiration see these  examples .  Font Awesome Markdown  is a Markdown extension that looks for things like  :fa-coffee:  ( ) or  :fa-refresh:  ( ) and replaces them with the Font Awesome icon markup.", 
            "title": "Font Awesome"
        }, 
        {
            "location": "/engine/technicalities/#examples", 
            "text": "This examples use the fontawesome_markdown extension:  What would you drink, :fa-coffee: or :fa-beer:?  What would you drink,   or  ?  For this example, you must install the  fontawesome_markdown  extension with  pip . Right now version  0.2.5  is the latest but it doesn t work out of the box. Instead, you have to install the latest version from the github repository. You can do that with the command below:  pip install https://github.com/bmcorser/fontawesome-markdown/archive/master.zip  You may need to include  -U  in the above command if you already have this extension installed.  Then add the below to your  mkdocs.yml  file.  markdown_extensions:\n  - fontawesome_markdown`", 
            "title": "Examples"
        }, 
        {
            "location": "/engine/technicalities/#deployment-to-github-pages", 
            "text": "The first step you ll need to do is simply make sure you have a  gh-pages  branch that exists, if it doesn t:  git checkout -b gh-pages\ngit rm -rf .\ngit push --set-upstream origin gh-pages  Then run this command:  mkdocs gh-deploy  This will push the  master   branch to the remote  gh-pages . After that, you can view your website here:  http://your-github-name.github.io/mkdocs-repo-name", 
            "title": "Deployment to GitHub Pages"
        }, 
        {
            "location": "/engine/technicalities/#deployment-to-github-pages-via-travis-ci", 
            "text": "Go to your GitHub account and create a new  Personal access token  in your Developer settings. Copy the hash string.   Keep well the hash string!  You will see it only once when you create it.   In the Travis CI settings of your project add a new  GH_TOKEN  environment variable with the value of the hash string your have just copied. Don t forget to turn in  ON  and to  ADD .  Configure the  .travis.yml  file. You may start with something like this:  sudo :   false  language :   python  python :   2.7  install :  -   pip install --upgrade pip  -   pip install -r requirements.txt  -   pip install https://github.com/bmcorser/fontawesome-markdown/archive/master.zip  script :  -   git config credential.helper  store --file=.git/credentials  -   echo  https://${GH_TOKEN}:@github.com    .git/credentials  -   mkdocs build  -   if [ $TRAVIS_TEST_RESULT == 0 ]; then \n     mkdocs gh-deploy --force; \n   fi   The credentials here are necessary for the Travis agent to be able to connect to your Github repository and perform the necessary actions with it. Note that the credentials are based on the  Personal access token  you have created.   Also, I have put deployment inside the  script  fase instead of  after_success  as a workaround (see the tip of Chronial on this  Travis issue #758 ). Otherwise, the batch succeeds with a successful build even if deploy  fails  after it.  Next, you need to have  travis  Rubygem installed on your local machine. If not, install it:  gem install travis  Using  travis , add the encrypted token to  .travis.yml :   travis encrypt  GH_TOKEN = the-token-from-github  --add  This will add the following block at the end of the file:  env : \n   global : \n   -   secure :   lots-of-seemingly-random-characters   Now, when you push your changes to the remote  master , Travis CI should publish the compiled website to  GitHub Pages  if the build succeeds.", 
            "title": "Deployment to GitHub pages via Travis CI"
        }, 
        {
            "location": "/engine/styling/", 
            "text": "Custom Styling\n#\n\n\n\n\n\n\nCustom Styling\n\n\nAdmonition extension\n\n\nSyntax\n\n\nSpecial words\n\n\nSome examples\n\n\n\n\n\n\nSmartyPants extension\n\n\nnl2br extension\n\n\nCustom Theme\n\n\n\n\n\n\n\n\n\n\n\n\nAdmonition extension\n#\n\n\nAdmonition extension\n for the MkDocs Markdown provides for a way to draw attention of the reader. In order to use this extension\n\n\nSyntax\n#\n\n\n!!! special_word \nsome text within double quotes\n\n    Any number of lines aligned with the special_word\n\n\n\n\n\n\n\n3 exclamation marks ( \n!!!\n ) at the beginning of the line\n\n\n1 space\n\n\n1 special word (see below)\n\n\n1 space\n\n\n(optional) some text within double quotes\n\n\n(optional) 1 empty line\n\n\n(optional) any number of lines beginning at pos. 4 (aligned with the special word after the exclamation marks)\n\n\n\n\nSpecial words\n#\n\n\nThese special words result in a colored adminition blocks. It is nice to experiment with them.\n\n\n\n\nnote\n, \nseealso\n - light blue\n\n\nimportant\n, \nhint\n, \ntip\n - green\n\n\nwarning\n, \ncaution\n, \nattention\n - beige/brown\n\n\ndanger\n, \nerror\n - pink/red\n\n\n\n\n\n\nNote\n\n\nThe special word can be also any other word. In that case, the color will always be light blue.\n\n\n\n\nSome examples\n#\n\n\nA custom text message on the first line\n\n\n!!! note \nExplicit title within double quotes\n\n\n    Any number of other indented markdown elements.\n    And this is the second paragraph.\n\n\n\n\n\nreplaces the 1st word:\n\n\n\n\nExplicit title within double quotes\n\n\nAny number of other indented markdown elements.\n\nAnd this is the second paragraph.\n\n\n\n\nAny single word on the first line\n\n\n!!! hint\n\n    You should note that the title will be automatically capitalized.\n\n\n\n\n\nwill be capitalized:\n\n\n\n\nHint\n\n\nYou should note that the title will be automatically capitalized.\n\n\n\n\nThe empty custom title\n\n\n!!! warning \n\n\n    This is an admonition box without a title.\n\n\n\n\n\nresults in no title:\n\n\n\n\nThis is an admonition box without a title.\n\n\n\n\nThe word \nwarning\n plus custom title\n\n\n!!! danger \nDon\nt try this at home\n\n\n    Or you will regret it for the rest of your life!\n\n\n\n\n\nresults in the red background:\n\n\n\n\nDon\nt try this at home\n\n\nOr you will regret it for the rest of your life!\n\n\n\n\nSmartyPants extension\n#\n\n\nAdding\n\n\n-\n \nsmarty\n:\n\n    \nsmart_angled_quotes\n:\n \ntrue\n\n\n\n\n\n\nto \nmarkdown_extentions\n gives you the possibility to print out nicely looking ASCII dashes, quotes and ellipes:\n\n\nYou write:\n\n\nsingle quotes\n\n\ndouble qoutes\n\n\nangled quotes\n\n... ellipsis\n-- ndash\n--- mdash\n\n\n\n\n\nYou get:\n\n\nsingle quotes\n\n\ndouble qoutes\n\n\nangled quotes\n\n\n ellipsis\n\n\n ndash\n\n\n mdash\n\n\n\n\nnl2br extension\n#\n\n\nAdding\n\n\n-\n \nnl2br\n\n\n\n\n\n\nto \nmarkdown_extentions\n creates a newline within fences when you make a newline in Markdown. You type:\n\n\nline 1\nline 2\n\n\n\n\n\nWithout \nnl2br\n you see this:\n\n\nline 1 line 2\n\n\n\n\n\nWith \nnl2br\n you see this:\n\n\nline 1\nline 2\n\n\n\n\n\n\n\nCustom Theme\n#\n\n\n\n\nNote\n\n\nIf you are looking for third party themes, they are listed in the MkDocs\n\n\ncommunity wiki\n.\n\n\n\n\nHere are some themes I have already considered:\n\n\n\n\nMkDocs Themes\n\n\n12 \nBootswatch\n themes\n\n\nCinder\n theme\n\n\nAlabaster\n theme (quite simple)\n\n\nBootstrap\n theme\n\n\n\n\nIt is possible to add extra customization via a \nCustom Theme\n option.\n\n\n\n\ncreate the \ncustom_theme\n and \ncustom_theme/css\n directories under \ndoc_dir\n (see \nmkdocs.yml\n file)\n\n\ninside the \ncustom_theme/css\n directory create \nextra.less\n file with your styles\n\n\nuse any LESS compiler to compile the \nextra.less\n file to the minified \nextra.min.css\n and its map \nextra.min.css.map\n\n\nadd the following lines to \nmkdoc.yml\n under the \ndoc_dir\n variable:\n\n\n\n\n  \ntheme_dir\n:\n \ncustom_theme\n\n  \nextra_css\n:\n \n  \n-\n \ncss\n/\nextra\n.\nmin\n.\ncss\n\n\n\n\n\n\n\n\nnow when you build and serve the website, you should see the custom styling in action\n\n\n\n\nSimilarly, it is possible to add extra JavaScript inside the \ncustom_theme/js\n directory. You add the corresponding setting to the \nmkdocs.yml\n file:\n\n\n  \nextra_javascript\n:\n \n  \n-\n \njs\n/\nyour\n-\njs\n-\nfile\n.\nmin\n.\njs", 
            "title": "Styling"
        }, 
        {
            "location": "/engine/styling/#custom-styling", 
            "text": "Custom Styling  Admonition extension  Syntax  Special words  Some examples    SmartyPants extension  nl2br extension  Custom Theme", 
            "title": "Custom Styling"
        }, 
        {
            "location": "/engine/styling/#admonition-extension", 
            "text": "Admonition extension  for the MkDocs Markdown provides for a way to draw attention of the reader. In order to use this extension", 
            "title": "Admonition extension"
        }, 
        {
            "location": "/engine/styling/#syntax", 
            "text": "!!! special_word  some text within double quotes \n    Any number of lines aligned with the special_word   3 exclamation marks (  !!!  ) at the beginning of the line  1 space  1 special word (see below)  1 space  (optional) some text within double quotes  (optional) 1 empty line  (optional) any number of lines beginning at pos. 4 (aligned with the special word after the exclamation marks)", 
            "title": "Syntax"
        }, 
        {
            "location": "/engine/styling/#special-words", 
            "text": "These special words result in a colored adminition blocks. It is nice to experiment with them.   note ,  seealso  - light blue  important ,  hint ,  tip  - green  warning ,  caution ,  attention  - beige/brown  danger ,  error  - pink/red    Note  The special word can be also any other word. In that case, the color will always be light blue.", 
            "title": "Special words"
        }, 
        {
            "location": "/engine/styling/#some-examples", 
            "text": "A custom text message on the first line  !!! note  Explicit title within double quotes \n\n    Any number of other indented markdown elements.\n    And this is the second paragraph.  replaces the 1st word:   Explicit title within double quotes  Any number of other indented markdown elements. \nAnd this is the second paragraph.   Any single word on the first line  !!! hint\n\n    You should note that the title will be automatically capitalized.  will be capitalized:   Hint  You should note that the title will be automatically capitalized.   The empty custom title  !!! warning  \n\n    This is an admonition box without a title.  results in no title:   This is an admonition box without a title.   The word  warning  plus custom title  !!! danger  Don t try this at home \n\n    Or you will regret it for the rest of your life!  results in the red background:   Don t try this at home  Or you will regret it for the rest of your life!", 
            "title": "Some examples"
        }, 
        {
            "location": "/engine/styling/#smartypants-extension", 
            "text": "Adding  -   smarty : \n     smart_angled_quotes :   true   to  markdown_extentions  gives you the possibility to print out nicely looking ASCII dashes, quotes and ellipes:  You write:  single quotes  double qoutes  angled quotes \n... ellipsis\n-- ndash\n--- mdash  You get:  single quotes  double qoutes  angled quotes   ellipsis   ndash   mdash", 
            "title": "SmartyPants extension"
        }, 
        {
            "location": "/engine/styling/#nl2br-extension", 
            "text": "Adding  -   nl2br   to  markdown_extentions  creates a newline within fences when you make a newline in Markdown. You type:  line 1\nline 2  Without  nl2br  you see this:  line 1 line 2  With  nl2br  you see this:  line 1\nline 2", 
            "title": "nl2br extension"
        }, 
        {
            "location": "/engine/styling/#custom-theme", 
            "text": "Note  If you are looking for third party themes, they are listed in the MkDocs  community wiki .   Here are some themes I have already considered:   MkDocs Themes  12  Bootswatch  themes  Cinder  theme  Alabaster  theme (quite simple)  Bootstrap  theme   It is possible to add extra customization via a  Custom Theme  option.   create the  custom_theme  and  custom_theme/css  directories under  doc_dir  (see  mkdocs.yml  file)  inside the  custom_theme/css  directory create  extra.less  file with your styles  use any LESS compiler to compile the  extra.less  file to the minified  extra.min.css  and its map  extra.min.css.map  add the following lines to  mkdoc.yml  under the  doc_dir  variable:      theme_dir :   custom_theme \n   extra_css :  \n   -   css / extra . min . css    now when you build and serve the website, you should see the custom styling in action   Similarly, it is possible to add extra JavaScript inside the  custom_theme/js  directory. You add the corresponding setting to the  mkdocs.yml  file:     extra_javascript :  \n   -   js / your - js - file . min . js", 
            "title": "Custom Theme"
        }, 
        {
            "location": "/aurelia/technicalities/", 
            "text": "Some Technical Notes\n#\n\n\n\n\n\n\nSome Technical Notes\n\n\nFont Awesome in Aurelia project\n\n\n\n\n\n\n\n\n\n\n\n\nFont Awesome in Aurelia project\n#\n\n\nAdd new \nprepare-font-awesome.ts\n task file to \naurelia_project/tasks\n:\n\n\nimport\n \n*\n \nas\n \ngulp\n \nfrom\n \ngulp\n;\n\n\nimport\n \n*\n \nas\n \nmerge\n \nfrom\n \nmerge-stream\n;\n\n\nimport\n \n*\n \nas\n \nchangedInPlace\n \nfrom\n \ngulp-changed-in-place\n;\n\n\nimport\n \n*\n \nas\n \nproject\n \nfrom\n \n../aurelia.json\n;\n\n\n\nexport\n \ndefault\n \nfunction\n \nprepareFontAwesome\n()\n \n{\n\n  \nconst\n \nsource\n \n=\n \nnode_modules/font-awesome\n;\n\n  \nconst\n \ncssSource\n \n=\n \n`\n${\nsource\n}\n/css/font-awesome.min.css`\n;\n\n  \nconst\n \ncssDest\n \n=\n \n`\n${\nproject\n.\nplatform\n.\noutput\n}\n/css`\n;\n\n  \nconst\n \nfontsSource\n \n=\n \n`\n${\nsource\n}\n/fonts/*`\n;\n\n  \nconst\n \nfontsDest\n \n=\n \n`\n${\nproject\n.\nplatform\n.\noutput\n}\n/fonts`\n;\n\n\n  \nconst\n \ntaskCss\n \n=\n \ngulp\n.\nsrc\n(\ncssSource\n)\n\n    \n.\npipe\n(\nchangedInPlace\n({\n \nfirstPass\n:\n \ntrue\n \n}))\n\n    \n.\npipe\n(\ngulp\n.\ndest\n(\ncssDest\n));\n\n\n  \nconst\n \ntaskFonts\n \n=\n \ngulp\n.\nsrc\n(\nfontsSource\n)\n\n    \n.\npipe\n(\nchangedInPlace\n({\n \nfirstPass\n:\n \ntrue\n \n}))\n\n    \n.\npipe\n(\ngulp\n.\ndest\n(\nfontsDest\n));\n\n\n  \nreturn\n \nmerge\n(\ntaskCss\n,\n \ntaskFonts\n);\n\n\n};\n\n\n\n\n\n\nAdd this new task to \naurelia_project/tasks/build.ts\n. You will get something like this:\n\n\nimport\n \n*\n \nas\n \ngulp\n \nfrom\n \ngulp\n;\n\n\nimport\n \ntranspile\n \nfrom\n \n./transpile\n;\n\n\nimport\n \nprocessMarkup\n \nfrom\n \n./process-markup\n;\n\n\nimport\n \nprocessCSS\n \nfrom\n \n./process-css\n;\n\n\nimport\n \n{\n \nbuild\n \n}\n \nfrom\n \naurelia-cli\n;\n\n\nimport\n \n*\n \nas\n \nproject\n \nfrom\n \n../aurelia.json\n;\n\n\nimport\n \nprepareFontAwesome\n \nfrom\n \n./prepare-font-awesome\n;\n \n// our custom task\n\n\n\nexport\n \ndefault\n \ngulp\n.\nseries\n(\n\n  \nreadProjectConfiguration\n,\n\n  \ngulp\n.\nparallel\n(\n\n    \ntranspile\n,\n\n    \nprocessMarkup\n,\n\n    \nprocessCSS\n,\n\n    \nprepareFontAwesome\n \n// our custom task\n\n  \n),\n\n  \nwriteBundles\n\n\n);\n\n\n\nfunction\n \nreadProjectConfiguration\n()\n \n{\n\n  \nreturn\n \nbuild\n.\nsrc\n(\nproject\n);\n\n\n}\n\n\n\nfunction\n \nwriteBundles\n()\n \n{\n\n  \nreturn\n \nbuild\n.\ndest\n();\n\n\n}\n\n\n\n\n\n\nFinally, add \n\n\nlink\n \nrel\n=\nstylesheet\n \nhref\n=\nscripts/css/font-awesome.min.css\n\n\n\n\n\n\nto \nwwwroot/index.html\n. Now, if you run \nau build\n, you will see two new directories created under \nwwwwroot/scripts\n:\n\n\n\n\ncss\n\n\nfonts\n\n\n\n\nand inside these folders the \nFont Awesome\n stylesheet and fonts.", 
            "title": "Technicalities"
        }, 
        {
            "location": "/aurelia/technicalities/#some-technical-notes", 
            "text": "Some Technical Notes  Font Awesome in Aurelia project", 
            "title": "Some Technical Notes"
        }, 
        {
            "location": "/aurelia/technicalities/#font-awesome-in-aurelia-project", 
            "text": "Add new  prepare-font-awesome.ts  task file to  aurelia_project/tasks :  import   *   as   gulp   from   gulp ;  import   *   as   merge   from   merge-stream ;  import   *   as   changedInPlace   from   gulp-changed-in-place ;  import   *   as   project   from   ../aurelia.json ;  export   default   function   prepareFontAwesome ()   { \n   const   source   =   node_modules/font-awesome ; \n   const   cssSource   =   ` ${ source } /css/font-awesome.min.css` ; \n   const   cssDest   =   ` ${ project . platform . output } /css` ; \n   const   fontsSource   =   ` ${ source } /fonts/*` ; \n   const   fontsDest   =   ` ${ project . platform . output } /fonts` ; \n\n   const   taskCss   =   gulp . src ( cssSource ) \n     . pipe ( changedInPlace ({   firstPass :   true   })) \n     . pipe ( gulp . dest ( cssDest )); \n\n   const   taskFonts   =   gulp . src ( fontsSource ) \n     . pipe ( changedInPlace ({   firstPass :   true   })) \n     . pipe ( gulp . dest ( fontsDest )); \n\n   return   merge ( taskCss ,   taskFonts );  };   Add this new task to  aurelia_project/tasks/build.ts . You will get something like this:  import   *   as   gulp   from   gulp ;  import   transpile   from   ./transpile ;  import   processMarkup   from   ./process-markup ;  import   processCSS   from   ./process-css ;  import   {   build   }   from   aurelia-cli ;  import   *   as   project   from   ../aurelia.json ;  import   prepareFontAwesome   from   ./prepare-font-awesome ;   // our custom task  export   default   gulp . series ( \n   readProjectConfiguration , \n   gulp . parallel ( \n     transpile , \n     processMarkup , \n     processCSS , \n     prepareFontAwesome   // our custom task \n   ), \n   writeBundles  );  function   readProjectConfiguration ()   { \n   return   build . src ( project );  }  function   writeBundles ()   { \n   return   build . dest ();  }   Finally, add   link   rel = stylesheet   href = scripts/css/font-awesome.min.css   to  wwwroot/index.html . Now, if you run  au build , you will see two new directories created under  wwwwroot/scripts :   css  fonts   and inside these folders the  Font Awesome  stylesheet and fonts.", 
            "title": "Font Awesome in Aurelia project"
        }, 
        {
            "location": "/dotnet/new_project/", 
            "text": "Workflow with an new ASP.NET Core MVC Project\n#\n\n\n\n\n\n\nWorkflow with an new ASP.NET Core MVC Project\n\n\n.NET Core Prerequisites\n\n\nCreate a new minimal ASP.NET Core project\n\n\nDotnet Command Line Version\n\n\nVisual Studio 2015 Version\n\n\nDependencies\n\n\nProject.json\n\n\nGlobal.json\n\n\nBower.json\n\n\nProgram.cs\n\n\nStartup.cs\n\n\nControllers/HomeController.cs\n\n\nViews/_ViewImports.cshtml\n\n\nViews/Home/Index.cshtml\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.NET Core Prerequisites\n#\n\n\nIdeally, you have to have a number of components installed on your system (Windows | Linux | MacOS):\n\n\n\n\n.NET Core\n\n\n.NET Core SDK\n\n\nNode.js\n\n\n\n\n\n\nCreate a new minimal ASP.NET Core project\n#\n\n\n\n\nIMPORTANT!\n\n\nWhen working with Visual Studio as IDE, make sure that - \nAT ALL TIMES!\n - you can run your application both from inside the Visual Studio by pressing \nCtrl + F5\n, and from the command prompt by executing \ndotnet run\n command.\n\n\n\n\nDotnet Command Line Version\n#\n\n\n\n\nCreate a new project directory and CD to it:\n\n\n\n\nmkdir myproj \n cd myproj\n\n\n\n\nCreate the default initial project:\n\n\n\n\ndotnet new\n\n\n\n\nRestore the default dependencies:\n\n\n\n\ndotnet restore\n\n\n\n\nRun the project and see the \nHello World!\n message:\n\n\n\n\ndotnet run\n\n\nVisual Studio 2015 Version\n#\n\n\nStart Visual Studio. Click on \nFile | New | Project\n. In the \nTemplates\n choose \nVisual C# | .NET Core\n and then \nASP.NET Core Web Application (.NET Core)\n. Browse to the root location for your new solution. Choose a nice name for it, e.g. \nMyGreatApp\n. Click the \nOK\n button. Choose now the empty ASP.NET Core template.\n\n\nThe solution is created. Wait for the dependencies to be installed. Build and run the solution with \nCtrl + F5\n. When the browser starts, you will see the \nHello World!\n message.\n\n\nYou can also start the command prompt in the \nMyGreatApp/Src/MyGreatApp\n folder. Run this command:\n\n\ndotnet restore \n dotnet run\n\n\nBrowse to the \nlocalhost:5000\n and you will see the \nHello World!\n message.\n\n\nDependencies\n#\n\n\n\n\nVersions are constantly changing\n\n\nASP.NET Core is constantly being developed and new versions of different components are being released. Therefore, the versions stated below can get outdated at any moment. If you wish to upgrade a version, you have to install the referenced component first.\n\n\n\n\nProject.json\n#\n\n\nYou can start with this configuration:\n\n\n{\n\n    \nversion\n:\n \n1.0.0-*\n,\n\n    \ndescription\n:\n \nYour best description of the application\n,\n\n    \nauthors\n:\n \n[\n \nYour Name\n \n],\n\n    \npackOptions\n:\n \n{\n\n        \ntags\n:\n \n[\n \n \n],\n\n        \nprojectUrl\n:\n \n,\n\n        \nlicenseUrl\n:\n \n\n    \n},\n\n\n    \ndependencies\n:\n \n{\n\n        \nMicrosoft.NETCore.App\n:\n \n{\n\n            \nversion\n:\n \n1.1.*\n,\n\n            \ntype\n:\n \nplatform\n\n        \n},\n\n        \nMicrosoft.AspNetCore.Diagnostics\n:\n \n1.1.0\n,\n\n        \nMicrosoft.AspNetCore.Mvc\n:\n \n1.1.0\n,\n\n        \nMicrosoft.AspNetCore.Razor.Tools\n:\n \n{\n\n            \nversion\n:\n \n1.1.0-preview4-final\n,\n\n            \ntype\n:\n \nbuild\n\n        \n},\n\n        \nMicrosoft.AspNetCore.Server.IISIntegration\n:\n \n1.1.0\n,\n\n        \nMicrosoft.AspNetCore.Server.Kestrel\n:\n \n1.1.0\n,\n\n        \nMicrosoft.AspNetCore.StaticFiles\n:\n \n1.1.0\n,\n\n        \nMicrosoft.Extensions.Logging.Console\n:\n \n1.1.0\n,\n\n        \nMicrosoft.VisualStudio.Web.BrowserLink.Loader\n:\n \n14.1.0\n,\n\n        \nSystem.Net.Http\n:\n \n4.3.0\n\n    \n},\n\n\n    \ntools\n:\n \n{\n\n        \nMicrosoft.AspNetCore.Server.IISIntegration.Tools\n:\n \n1.0.0-preview2-final\n\n    \n},\n\n\n    \nframeworks\n:\n \n{\n\n        \nnetcoreapp1.0\n:\n \n{\n\n            \nimports\n:\n \n[\n\n                \ndotnet5.6\n,\n\n                \nportable-net45+win8\n,\n\n                \ndnxcore50\n\n            \n]\n\n        \n}\n\n    \n},\n\n\n    \nbuildOptions\n:\n \n{\n\n        \nemitEntryPoint\n:\n \ntrue\n,\n\n        \npreserveCompilationContext\n:\n \ntrue\n\n    \n},\n\n\n    \nruntimes\n:\n \n{\n\n        \nwin81-x64\n:\n \n{},\n\n        \nwin7-x64\n:\n \n{},\n\n        \nosx.10.12-x64\n:\n \n{}\n\n    \n},\n\n\n    \nruntimeOptions\n:\n \n{\n\n        \nconfigProperties\n:\n \n{\n\n            \nSystem.GC.Server\n:\n \ntrue\n\n        \n}\n\n    \n},\n\n\n    \npublishOptions\n:\n \n{\n\n        \ninclude\n:\n \n[\n\n            \nwwwroot\n,\n\n            \nweb.config\n\n        \n]\n\n    \n},\n\n\n    \nscripts\n:\n \n{\n\n        \npostpublish\n:\n \n[\n\n          \ndotnet publish-iis --publish-folder %publish:OutputPath% --framework %publish:FullTargetFramework%\n\n        \n]\n\n    \n}\n\n\n}\n\n\n\n\n\n\nGlobal.json\n#\n\n\nWhen you install the .NET Core SDK on Windows, it shows up in \nC:\\Program Files\\dotnet\\sdk\n folder. Using the \nsdk\n option, we can override the default version.\n\n\n{\n\n  \nprojects\n:\n \n[\n \nsrc\n,\n \ntest\n \n],\n\n  \nsdk\n:\n \n{\n\n    \nversion\n:\n \n1.0.0-preview2-1-003177\n\n  \n}\n\n\n}\n\n\n\n\n\n\nBower.json\n#\n\n\nIf you need \nBootstrap 3\n for the styling of your website, add this \nbower.json\n file in the project root.\n\n\n{\n\n    \nname\n:\n \nasp.net\n,\n\n    \nprivate\n:\n \ntrue\n,\n\n    \ndependencies\n:\n \n{\n\n      \nbootstrap\n:\n \n3.3.*\n\n    \n}\n\n\n}\n\n\n\n\n\n\nProgram.cs\n#\n\n\nusing\n \nMicrosoft.AspNetCore.Hosting\n;\n\n\nusing\n \nSystem.IO\n;\n\n\n\nnamespace\n \nNNMeta\n\n\n{\n\n    \npublic\n \nclass\n \nProgram\n\n    \n{\n\n        \npublic\n \nstatic\n \nvoid\n \nMain\n(\nstring\n[]\n \nargs\n)\n\n        \n{\n\n            \nvar\n \nhost\n \n=\n \nnew\n \nWebHostBuilder\n()\n\n                \n.\nUseKestrel\n()\n\n                \n.\nUseContentRoot\n(\nDirectory\n.\nGetCurrentDirectory\n())\n\n                \n.\nUseIISIntegration\n()\n\n                \n.\nUseStartup\nStartup\n()\n\n                \n.\nBuild\n();\n\n\n            \nhost\n.\nRun\n();\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\nStartup.cs\n#\n\n\nusing\n \nMicrosoft.AspNetCore.Builder\n;\n\n\nusing\n \nMicrosoft.AspNetCore.Hosting\n;\n\n\nusing\n \nMicrosoft.Extensions.DependencyInjection\n;\n\n\nusing\n \nMicrosoft.Extensions.Logging\n;\n\n\n\nnamespace\n \nNNMeta\n\n\n{\n\n    \npublic\n \nclass\n \nStartup\n\n    \n{\n\n        \npublic\n \nvoid\n \nConfigureServices\n(\nIServiceCollection\n \nservices\n)\n\n        \n{\n\n            \nservices\n.\nAddMvc\n();\n\n        \n}\n\n\n        \npublic\n \nvoid\n \nConfigure\n(\nIApplicationBuilder\n \napp\n,\n \nIHostingEnvironment\n \nenv\n,\n \nILoggerFactory\n \nloggerFactory\n)\n\n        \n{\n\n            \nif\n \n(\nenv\n.\nIsDevelopment\n())\n\n            \n{\n\n                \napp\n.\nUseDeveloperExceptionPage\n();\n\n            \n}\n\n\n            \napp\n.\nUseStaticFiles\n();\n\n            \napp\n.\nUseMvcWithDefaultRoute\n();\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\n\nControllers/HomeController.cs\n#\n\n\nusing\n \nSystem.Collections.Generic\n;\n\n\nusing\n \nMicrosoft.AspNetCore.Mvc\n;\n\n\n\nnamespace\n \nNNMeta.Controllers\n\n\n{\n\n    \npublic\n \nclass\n \nHomeController\n \n:\n \nController\n\n    \n{\n\n        \npublic\n \nViewResult\n \nIndex\n()\n\n            \n=\n \nView\n(\nnew\n \nDictionary\nstring\n,\n \nstring\n\n            \n{\n\n\n                [\nMessage1\n]\n \n=\n \nThis is the first message from the Index action\n,\n\n\n                [\nMessage2\n]\n \n=\n \nThis is the second message from the Index action\n\n            \n});\n\n    \n}\n\n\n}\n\n\n\n\n\n\nViews/_ViewImports.cshtml\n#\n\n\n@addTagHelper *, Microsoft.AspNetCore.Mvc.TagHelpers\n\n\n\n\n\nViews/Home/Index.cshtml\n#\n\n\n@model Dictionary\nstring\n,\n \nstring\n\n@{ Layout = null; }\n\n!DOCTYPE html\n\n\nhtml\n\n\nhead\n\n  \nmeta\n \nname\n=\nviewport\n \ncontent\n=\nwidth=device-width\n \n/\n\n  \nlink\n \nasp-href-include\n=\n~/lib/bootstrap/dist/css/*.min.css\n \nrel\n=\nstylesheet\n \n/\n\n  \ntitle\nResult\n/\ntitle\n\n\n/\nhead\n\n\nbody\n \nclass\n=\npanel-body\n\n  \ntable\n \nclass\n=\ntable table-condensed table-bordered table-striped\n\n    \ntr\n\n      @foreach (var kvp in Model)\n      {\n          \nth\n@kvp.Key\n/\nth\n\n      }\n    \n/\ntr\n\n    \ntr\n\n      @foreach (var kvp in Model)\n      {\n          \ntd\n@kvp.Value\n/\ntd\n\n      }\n    \n/\ntr\n\n  \n/\ntable\n\n\n/\nbody\n\n\n/\nhtml", 
            "title": "New Project"
        }, 
        {
            "location": "/dotnet/new_project/#workflow-with-an-new-aspnet-core-mvc-project", 
            "text": "Workflow with an new ASP.NET Core MVC Project  .NET Core Prerequisites  Create a new minimal ASP.NET Core project  Dotnet Command Line Version  Visual Studio 2015 Version  Dependencies  Project.json  Global.json  Bower.json  Program.cs  Startup.cs  Controllers/HomeController.cs  Views/_ViewImports.cshtml  Views/Home/Index.cshtml", 
            "title": "Workflow with an new ASP.NET Core MVC Project"
        }, 
        {
            "location": "/dotnet/new_project/#net-core-prerequisites", 
            "text": "Ideally, you have to have a number of components installed on your system (Windows | Linux | MacOS):   .NET Core  .NET Core SDK  Node.js", 
            "title": ".NET Core Prerequisites"
        }, 
        {
            "location": "/dotnet/new_project/#create-a-new-minimal-aspnet-core-project", 
            "text": "IMPORTANT!  When working with Visual Studio as IDE, make sure that -  AT ALL TIMES!  - you can run your application both from inside the Visual Studio by pressing  Ctrl + F5 , and from the command prompt by executing  dotnet run  command.", 
            "title": "Create a new minimal ASP.NET Core project"
        }, 
        {
            "location": "/dotnet/new_project/#dotnet-command-line-version", 
            "text": "Create a new project directory and CD to it:   mkdir myproj   cd myproj   Create the default initial project:   dotnet new   Restore the default dependencies:   dotnet restore   Run the project and see the  Hello World!  message:   dotnet run", 
            "title": "Dotnet Command Line Version"
        }, 
        {
            "location": "/dotnet/new_project/#visual-studio-2015-version", 
            "text": "Start Visual Studio. Click on  File | New | Project . In the  Templates  choose  Visual C# | .NET Core  and then  ASP.NET Core Web Application (.NET Core) . Browse to the root location for your new solution. Choose a nice name for it, e.g.  MyGreatApp . Click the  OK  button. Choose now the empty ASP.NET Core template.  The solution is created. Wait for the dependencies to be installed. Build and run the solution with  Ctrl + F5 . When the browser starts, you will see the  Hello World!  message.  You can also start the command prompt in the  MyGreatApp/Src/MyGreatApp  folder. Run this command:  dotnet restore   dotnet run  Browse to the  localhost:5000  and you will see the  Hello World!  message.", 
            "title": "Visual Studio 2015 Version"
        }, 
        {
            "location": "/dotnet/new_project/#dependencies", 
            "text": "Versions are constantly changing  ASP.NET Core is constantly being developed and new versions of different components are being released. Therefore, the versions stated below can get outdated at any moment. If you wish to upgrade a version, you have to install the referenced component first.", 
            "title": "Dependencies"
        }, 
        {
            "location": "/dotnet/new_project/#projectjson", 
            "text": "You can start with this configuration:  { \n     version :   1.0.0-* , \n     description :   Your best description of the application , \n     authors :   [   Your Name   ], \n     packOptions :   { \n         tags :   [     ], \n         projectUrl :   , \n         licenseUrl :   \n     }, \n\n     dependencies :   { \n         Microsoft.NETCore.App :   { \n             version :   1.1.* , \n             type :   platform \n         }, \n         Microsoft.AspNetCore.Diagnostics :   1.1.0 , \n         Microsoft.AspNetCore.Mvc :   1.1.0 , \n         Microsoft.AspNetCore.Razor.Tools :   { \n             version :   1.1.0-preview4-final , \n             type :   build \n         }, \n         Microsoft.AspNetCore.Server.IISIntegration :   1.1.0 , \n         Microsoft.AspNetCore.Server.Kestrel :   1.1.0 , \n         Microsoft.AspNetCore.StaticFiles :   1.1.0 , \n         Microsoft.Extensions.Logging.Console :   1.1.0 , \n         Microsoft.VisualStudio.Web.BrowserLink.Loader :   14.1.0 , \n         System.Net.Http :   4.3.0 \n     }, \n\n     tools :   { \n         Microsoft.AspNetCore.Server.IISIntegration.Tools :   1.0.0-preview2-final \n     }, \n\n     frameworks :   { \n         netcoreapp1.0 :   { \n             imports :   [ \n                 dotnet5.6 , \n                 portable-net45+win8 , \n                 dnxcore50 \n             ] \n         } \n     }, \n\n     buildOptions :   { \n         emitEntryPoint :   true , \n         preserveCompilationContext :   true \n     }, \n\n     runtimes :   { \n         win81-x64 :   {}, \n         win7-x64 :   {}, \n         osx.10.12-x64 :   {} \n     }, \n\n     runtimeOptions :   { \n         configProperties :   { \n             System.GC.Server :   true \n         } \n     }, \n\n     publishOptions :   { \n         include :   [ \n             wwwroot , \n             web.config \n         ] \n     }, \n\n     scripts :   { \n         postpublish :   [ \n           dotnet publish-iis --publish-folder %publish:OutputPath% --framework %publish:FullTargetFramework% \n         ] \n     }  }", 
            "title": "Project.json"
        }, 
        {
            "location": "/dotnet/new_project/#globaljson", 
            "text": "When you install the .NET Core SDK on Windows, it shows up in  C:\\Program Files\\dotnet\\sdk  folder. Using the  sdk  option, we can override the default version.  { \n   projects :   [   src ,   test   ], \n   sdk :   { \n     version :   1.0.0-preview2-1-003177 \n   }  }", 
            "title": "Global.json"
        }, 
        {
            "location": "/dotnet/new_project/#bowerjson", 
            "text": "If you need  Bootstrap 3  for the styling of your website, add this  bower.json  file in the project root.  { \n     name :   asp.net , \n     private :   true , \n     dependencies :   { \n       bootstrap :   3.3.* \n     }  }", 
            "title": "Bower.json"
        }, 
        {
            "location": "/dotnet/new_project/#programcs", 
            "text": "using   Microsoft.AspNetCore.Hosting ;  using   System.IO ;  namespace   NNMeta  { \n     public   class   Program \n     { \n         public   static   void   Main ( string []   args ) \n         { \n             var   host   =   new   WebHostBuilder () \n                 . UseKestrel () \n                 . UseContentRoot ( Directory . GetCurrentDirectory ()) \n                 . UseIISIntegration () \n                 . UseStartup Startup () \n                 . Build (); \n\n             host . Run (); \n         } \n     }  }", 
            "title": "Program.cs"
        }, 
        {
            "location": "/dotnet/new_project/#startupcs", 
            "text": "using   Microsoft.AspNetCore.Builder ;  using   Microsoft.AspNetCore.Hosting ;  using   Microsoft.Extensions.DependencyInjection ;  using   Microsoft.Extensions.Logging ;  namespace   NNMeta  { \n     public   class   Startup \n     { \n         public   void   ConfigureServices ( IServiceCollection   services ) \n         { \n             services . AddMvc (); \n         } \n\n         public   void   Configure ( IApplicationBuilder   app ,   IHostingEnvironment   env ,   ILoggerFactory   loggerFactory ) \n         { \n             if   ( env . IsDevelopment ()) \n             { \n                 app . UseDeveloperExceptionPage (); \n             } \n\n             app . UseStaticFiles (); \n             app . UseMvcWithDefaultRoute (); \n         } \n     }  }", 
            "title": "Startup.cs"
        }, 
        {
            "location": "/dotnet/new_project/#controllershomecontrollercs", 
            "text": "using   System.Collections.Generic ;  using   Microsoft.AspNetCore.Mvc ;  namespace   NNMeta.Controllers  { \n     public   class   HomeController   :   Controller \n     { \n         public   ViewResult   Index () \n             =   View ( new   Dictionary string ,   string \n             {                  [ Message1 ]   =   This is the first message from the Index action ,                  [ Message2 ]   =   This is the second message from the Index action \n             }); \n     }  }", 
            "title": "Controllers/HomeController.cs"
        }, 
        {
            "location": "/dotnet/new_project/#views_viewimportscshtml", 
            "text": "@addTagHelper *, Microsoft.AspNetCore.Mvc.TagHelpers", 
            "title": "Views/_ViewImports.cshtml"
        }, 
        {
            "location": "/dotnet/new_project/#viewshomeindexcshtml", 
            "text": "@model Dictionary string ,   string \n@{ Layout = null; } !DOCTYPE html  html  head \n   meta   name = viewport   content = width=device-width   / \n   link   asp-href-include = ~/lib/bootstrap/dist/css/*.min.css   rel = stylesheet   / \n   title Result / title  / head  body   class = panel-body \n   table   class = table table-condensed table-bordered table-striped \n     tr \n      @foreach (var kvp in Model)\n      {\n           th @kvp.Key / th \n      }\n     / tr \n     tr \n      @foreach (var kvp in Model)\n      {\n           td @kvp.Value / td \n      }\n     / tr \n   / table  / body  / html", 
            "title": "Views/Home/Index.cshtml"
        }, 
        {
            "location": "/dotnet/notes/", 
            "text": "Notes on ASP.NET Core\n#\n\n\n\n\n\n\nNotes on ASP.NET Core\n\n\nConventions\n\n\nExtension methods\n\n\nClass extensions\n\n\nInterface extensions\n\n\nFiltering\n\n\n\n\n\n\nLambda anonymous functions\n\n\nAsynchronous methods\n\n\nGetting property names with nameof\n\n\nWorkflow with an empty project\n\n\nThe JSON Configuration Files\n\n\nRazor\n\n\nView Imports File\n\n\nView Start File\n\n\nViewBag property\n\n\nAttribute values\n\n\nSwitch statement\n\n\n\n\n\n\nVisual Studio tips and tricks\n\n\nEnable Developer Exception Page\n\n\n\n\n\n\nBrowser Link Loader\n\n\nStatic files\n\n\nBundling and minifying\n\n\nUnit Testing with xUnit Framework\n\n\nPreparation\n\n\nFact and Theory\n\n\nGetting Test Data from a Method or Property\n\n\n\n\n\n\nMocking with MOQ\n\n\nSportsStore\n\n\nScaffolding\n\n\nSetup the database\n\n\nViewModels and TagHelpers\n\n\nInstalling Bootstrap package\n\n\nImproving the URLs\n\n\nEnabling Sessions\n\n\nAnnotations\n\n\nAdding migrations\n\n\n\n\n\n\nResetting the Database\n\n\nUsing TempData\n\n\nLocalization hell\n\n\nAdding Identity\n\n\nAdding Identity migrations\n\n\nAdding Authorization\n\n\nSources used\n\n\n\n\n\n\n\n\n\n\n\n\nI have written these notes while working on a couple of great books on the subject. See \nSources used\n.\n\n\nModels\n - the \nM\n in \nMVC\n - contain the data that users work with. There are two broad types of model:\n\n\n\n\nview models\n, which represent just data passed from the controller to the view, and\n\n\ndomain models\n, which contain the data in a business domain, along with the operations, transformations, and rules for creating, storing, and manipulating that data, collectively referred to as the model logic.\n\n\n\n\nIn ASP.NET Core MVC, \ncontrollers\n are C# classes, usually derived from the \nMicrosoft.AspNetCore.Mvc.Controller\n class. Each \npublic\n method in a class derived from \nController\n is an \naction method\n, which is associated with a \nURL\n.\n\n\n\n\n\n\nConventions\n#\n\n\n\n\nput the third-party JavaScript and CSS packages you rely on in the \nwwwroot/lib\n folder.\n\n\nconvention over configuration\n\n\nthe controller for \n/product\n uri should have the name \nProductController.cs\n and reside in the \n/Controllers\n folder; from other parts in the project, such as when using an HTML helper method, you specify the first part of the name (\nProduct\n), and MVC automatically appends \nController\n to the name and starts looking for the controller class.\n\n\nviews for \n/product\n uri associated with \nProductController\n should all reside in the \n/Views/Product\n folder.\n\n\nMVC expects that the \ndefault view\n for an \naction method\n should be named after that method. For example, the default view associated with an action method called \nList\n should be called \nList.cshtml\n. Thus, for the \nList action method\n in the \nProductController\n class, the \ndefault view\n is expected to be \n/Views/Product/List.cshtml\n. The \ndefault view\n is used when you return the result of calling the \nView\n method in an action method, like this:\n\n\n\n\n  \nreturn\n \nView\n();\n\n\n\n\n\n\nYou can specify a different view by name, like this:\n\n\n  \nreturn\n \nView\n(\nMyOtherView\n);\n\n\n\n\n\n\n\n\nWhen looking for a \nview\n, MVC looks in the folder named after the controller and then in the \n/Views/Shared\n folder. This means that I can put views that will be used by more than one controller in the \n/Views/Shared\n folder and MVC will find them.\n\n\nThe naming convention for \nlayouts\n is to prefix the file with an underscore (\n_\n) character, and layout files are placed in the \n/Views/Shared\n folder. This layout is applied to all views by default through the \n/Views/_ViewStart.cshtml\n file. If you do not want the default layout applied to views, you can change the settings in \nViewStart.cshtml\n (or delete the file entirely) to specify another layout in the view, like this:\n\n\n\n\n  \n@\n{\n\n    \nLayout\n \n=\n \n~/_MyLayout.cshtml\n;\n\n  \n}\n\n\n\n\n\n\n\n\nOr you can disable any layout for a given view, like this:\n\n\n\n\n  \n@\n{\n\n    \nLayout\n \n=\n \nnull\n;\n\n  \n}\n\n\n\n\n\n\n\n\nExtension methods\n#\n\n\nClass extensions\n#\n\n\nSuppose we have a simple class:\n\n\nusing\n \nSystem.Collections.Generic\n;\n\n\n\nnamespace\n \nLanguageFeatures.Models\n\n\n{\n\n    \npublic\n \nclass\n \nShoppingCart\n\n    \n{\n\n        \npublic\n \nIEnumerable\nProduct\n \nProducts\n \n{\n \nget\n;\n \nset\n;\n \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\nWe want to extend its functionality with a new method to calculate the total amount:\n\n\npublic\n \nstatic\n \ndecimal\n \nTotalPrices\n(\nthis\n \nShoppingCart\n \ncartParam\n)\n\n\n{\n\n    \ndecimal\n \ntotal\n \n=\n \n0\n;\n\n\n    \nforeach\n \n(\nProduct\n \nprod\n \nin\n \ncartParam\n.\nProducts\n)\n\n    \n{\n\n        \ntotal\n \n+=\n \nprod\n?.\nPrice\n \n??\n \n0\n;\n\n    \n}\n\n    \nreturn\n \ntotal\n;\n\n\n}\n\n\n\n\n\n\nWe can then use this extension method like this:\n\n\nShoppingCart\n \ncart\n \n=\n \nnew\n \nShoppingCart\n \n{\n \nProducts\n \n=\n \nProduct\n.\nGetProducts\n()\n \n};\n\n\ndecimal\n \ncartTotal\n \n=\n \ncart\n.\nTotalPrices\n();\n\n\n\n\n\n\nInterface extensions\n#\n\n\nusing\n \nSystem.Collections\n;\n\n\nusing\n \nSystem.Collections.Generic\n;\n\n\n\nnamespace\n \nLanguageFeatures.Models\n\n\n{\n\n    \npublic\n \nclass\n \nShoppingCart\n \n:\n \nIEnumerable\nProduct\n\n    \n{\n\n        \npublic\n \nIEnumerable\nProduct\n \nProducts\n \n{\n \nget\n;\n \nset\n;\n \n}\n\n\n        \npublic\n \nIEnumerator\nProduct\n \nGetEnumerator\n()\n\n        \n{\n\n           \nreturn\n \nProducts\n.\nGetEnumerator\n();\n\n        \n}\n\n\n        \nIEnumerator\n \nIEnumerable\n.\nGetEnumerator\n()\n\n        \n{\n\n            \nreturn\n \nGetEnumerator\n();\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\nWe can rewrite our extension method like this:\n\n\npublic\n \nstatic\n \ndecimal\n \nTotalPrices\n(\nthis\n \nIEnumerable\nProduct\n \nproducts\n)\n\n\n{\n\n    \ndecimal\n \ntotal\n \n=\n \n0\n;\n\n\n    \nforeach\n \n(\nProduct\n \nprod\n \nin\n \nproducts\n)\n\n    \n{\n\n        \ntotal\n \n+=\n \nprod\n?.\nPrice\n \n??\n \n0\n;\n\n    \n}\n\n    \nreturn\n \ntotal\n;\n\n\n}\n\n\n\n\n\n\nand use it with any object of type \nIEnumerable\nProduct\n like \nShoppingCart\n and \nProduct\n array:\n\n\nShoppingCart\n \ncart\n \n=\n \nnew\n \nShoppingCart\n \n{\n \nProducts\n \n=\n \nProduct\n.\nGetProducts\n()\n \n};\n\n\n\nProduct\n[]\n \nproductArray\n \n=\n\n\n{\n\n    \nnew\n \nProduct\n \n{\nName\n \n=\n \nKayak\n,\n \nPrice\n \n=\n \n275\nM\n},\n\n    \nnew\n \nProduct\n \n{\nName\n \n=\n \nLifejacket\n,\n \nPrice\n \n=\n \n48.95\nM\n}\n\n\n};\n\n\n\ndecimal\n \ncartTotal\n \n=\n \ncart\n.\nTotalPrices\n();\n\n\ndecimal\n \narrayTotal\n \n=\n \nproductArray\n.\nTotalPrices\n();\n\n\n\n\n\n\nFiltering\n#\n\n\nExtension methods can be used to \nfilter\n collections of objects. An extension method that operates on an \nIEnumerable\nT\n and that also returns an \nIEnumerable\nT\n can use the \nyield\n keyword to apply selection criteria to items in the source data to produce a reduced set of results.\n\n\nusing\n \nSystem.Collections.Generic\n;\n\n\n\nnamespace\n \nLanguageFeatures.Models\n\n\n{\n\n    \npublic\n \nstatic\n \nclass\n \nMyExtensionMethods\n\n    \n{\n\n        \npublic\n \nstatic\n \nIEnumerable\nProduct\n \nFilterByPrice\n(\n\n            \nthis\n \nIEnumerable\nProduct\n \nproductEnum\n,\n\n            \ndecimal\n \nminimumPrice\n)\n\n        \n{\n\n            \nforeach\n \n(\nProduct\n \nprod\n \nin\n \nproductEnum\n)\n\n            \n{\n\n                \nif\n \n((\nprod\n?.\nPrice\n \n??\n \n0\n)\n \n=\n \nminimumPrice\n)\n\n                \n{\n\n                    \nyield\n \nreturn\n \nprod\n;\n\n                \n}\n\n            \n}\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\n\nLambda anonymous functions\n#\n\n\nWe can repeat this process indefinitely and create a different filter method for every property and every combination of properties that we are interested in. A more elegant approach is to separate out the code that processes the enumeration from the selection criteria. C# makes this easy by allowing functions to be passed around as objects. We can then create a single extension method that filters an enumeration of Product objects but that delegates the decision about which ones are included in the results to a separate function.\n\n\npublic\n \nstatic\n \nIEnumerable\nProduct\n \nFilter\n(\n\n    \nthis\n \nIEnumerable\nProduct\n \nproductEnum\n,\n\n    \nFunc\nProduct\n,\n \nbool\n \nselector\n)\n\n\n{\n\n    \nforeach\n \n(\nProduct\n \nprod\n \nin\n \nproductEnum\n)\n\n    \n{\n\n        \nif\n \n(\nselector\n(\nprod\n))\n\n        \n{\n\n            \nyield\n \nreturn\n \nprod\n;\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\nNow, we can use this \nFilter\n function as follows:\n\n\ndecimal\n \npriceFilterTotal\n \n=\n \nproductArray\n\n    \n.\nFilter\n(\np\n \n=\n \n(\np\n?.\nPrice\n \n??\n \n0\n)\n \n=\n \n20\n)\n\n    \n.\nTotalPrices\n();\n\n\ndecimal\n \nnameFilterTotal\n \n=\n \nproductArray\n\n    \n.\nFilter\n(\np\n \n=\n \np\n?.\nName\n?[\n0\n]\n \n==\n \nS\n)\n\n    \n.\nTotalPrices\n();\n\n\n\n\n\n\nLambdas\n can also be used in class properties, e.g.:\n\n\npublic\n \nbool\n \nNameBeginsWithS\n \n=\n \nName\n?[\n0\n]\n \n==\n \nS\n;\n\n\n\n\n\n\n\n\nAsynchronous methods\n#\n\n\nAdd \n\"System.Net.Http\": \"4.1.0\"\n dependency in \nproject.json\n.\n\n\nHere is how we could make an asynchronous call \nthe hard way\n:\n\n\npublic\n \nstatic\n \nTask\nlong?\n \nGetPageLengthWithoutAsyncAwait\n()\n\n\n{\n\n    \nHttpClient\n \nclient\n \n=\n \nnew\n \nHttpClient\n();\n\n    \nvar\n \nhttpTask\n \n=\n \nclient\n.\nGetAsync\n(\nhttp://apress.com\n);\n\n    \n// we could do other things here while the HTTP request is performed\n\n    \nreturn\n \nhttpTask\n.\nContinueWith\n((\nTask\nHttpResponseMessage\n \nantecedent\n)\n \n=\n\n    \n{\n\n        \nreturn\n \nantecedent\n.\nResult\n.\nContent\n.\nHeaders\n.\nContentLength\n;\n\n    \n});\n\n\n}\n\n\n\n\n\n\nAnd here is the clever way:\n\n\npublic\n \nstatic\n \nasync\n \nTask\nlong?\n \nGetPageLength\n()\n\n\n{\n\n    \nHttpClient\n \nclient\n \n=\n \nnew\n \nHttpClient\n();\n\n    \nvar\n \nhttpMessage\n \n=\n \nawait\n \nclient\n.\nGetAsync\n(\nhttp://apress.com\n);\n\n    \n// we could do other things here while the HTTP request is performed\n\n    \nreturn\n \nhttpMessage\n.\nContent\n.\nHeaders\n.\nContentLength\n;\n\n\n}\n\n\n\n\n\n\nAnd we could use this in our controller:\n\n\nusing\n \nLanguageFeatures.Models\n;\n\n\nusing\n \nMicrosoft.AspNetCore.Mvc\n;\n\n\nusing\n \nSystem.Threading.Tasks\n;\n\n\n\nnamespace\n \nLanguageFeatures.Controllers\n\n\n{\n\n    \npublic\n \nclass\n \nHomeController\n \n:\n \nController\n\n    \n{\n\n        \npublic\n \nasync\n \nTask\nViewResult\n \nIndex\n()\n\n        \n{\n\n            \nlong?\n \nlength\n \n=\n \nawait\n \nMyAsyncMethods\n.\nGetPageLength\n();\n\n            \nreturn\n \nView\n(\nnew\n \nstring\n[]\n \n{\n \n$\nLength: {length}\n \n});\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\n\nGetting property names with nameof\n#\n\n\nIf we use lambdas the classic way:\n\n\nproducts\n.\nSelect\n(\np\n \n=\n \n$\nName: {p.Name}, Price: {p.Price}\n)\n\n\n\n\n\n\nwe of course get no intellisense on \nName:\n and \nPrice:\n. So, if we change the property name in the class and forget to change these strings here, we get a mismatch.\n\n\nFortunately, we can now rewrite the same code like this:\n\n\nproducts\n.\nSelect\n(\np\n \n=\n \n$\n{nameof(p.Name)}: {p.Name}, {nameof(p.Price)}: {p.Price}\n)\n\n\n\n\n\n\nbut then we will get intellisense and type safety.\n\n\n\n\nWorkflow with an empty project\n#\n\n\n\n\ncreate a new empty ASP.NET Core project\n\n\nadd \n\"Microsoft.AspNetCore.Mvc\": \"1.0.1\"\n dependency in \nproject.json\n\n\nadd \n\"System.Net.Http\": \"4.1.0\"\n dependency in \nproject.json\n\n\nadd \nMvc\n to \nStartup.cs\n:\n\n\n\n\nusing\n \nMicrosoft.AspNetCore.Builder\n;\n\n\nusing\n \nMicrosoft.AspNetCore.Hosting\n;\n\n\nusing\n \nMicrosoft.Extensions.DependencyInjection\n;\n\n\nusing\n \nMicrosoft.Extensions.Logging\n;\n\n\n\nnamespace\n \nLanguageFeatures\n\n\n{\n\n    \npublic\n \nclass\n \nStartup\n\n    \n{\n\n        \npublic\n \nvoid\n \nConfigureServices\n(\nIServiceCollection\n \nservices\n)\n\n        \n{\n\n            \nservices\n.\nAddMvc\n();\n\n        \n}\n\n\n        \npublic\n \nvoid\n \nConfigure\n(\nIApplicationBuilder\n \napp\n,\n \nIHostingEnvironment\n \nenv\n,\n \nILoggerFactory\n \nloggerFactory\n)\n\n        \n{\n\n            \napp\n.\nUseMvcWithDefaultRoute\n();\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\n\nThe JSON Configuration Files\n#\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nglobal.json\n\n\nThis file, which is found in the Solution Items folder, is responsible for telling Visual Studio where to find the projects in the solution and which version of the .NET execution environment should be used to run the application.\n\n\n\n\n\n\nlaunchSettings.json\n\n\nThis file, which is revealed by expanding the Properties item in the MVC application project, is used to specify how the application is started.\n\n\n\n\n\n\nappsettings.json\n\n\nThis file is used to define application-specific settings.\n\n\n\n\n\n\nbower.json\n\n\nThis file is used by Bower to list the client-side packages that are installed into the project.\n\n\n\n\n\n\nbundleconfig.json\n\n\nThis file is used to bundle and minify JavaScript and CSS files.\n\n\n\n\n\n\nproject.json\n\n\nThis file is used to specify the NuGet packages that are installed into the application. This file is also used for other project settings.\n\n\n\n\n\n\nproject.lock.json\n\n\nThis file, which is revealed by expanding the project.json item in the Solution Explorer, contains detailed dependencies between packages installed in the project. It is generated automatically and should not be edited manually.\n\n\n\n\n\n\n\n\n\n\nRazor\n#\n\n\nView Imports File\n#\n\n\nUse \n_ViewImports.cshtml\n file in the \nViews\n folder to specify the standard include namespaces. Then you can omit them in the individual views.\n\n\nView Start File\n#\n\n\nNormally, we have to specify the layout file we want in every view. Therefore, if we need to rename the layout file, we are going to have to find every view that refers to it and make a change, which will be an error-prone process and counter to the general theme of easy maintenance that runs through MVC development.\n\n\nWe can resolve this by using a \nview start file\n. When it renders a view, MVC will look for a file called \n_ViewStart.cshtml\n and we can put it in the \nViews\n folder. The contents of this file will be treated as though they were contained in the view file itself, and we can use this feature to automatically set a value for the Layout property.\n\n\n@\n{\n\n    \nLayout\n \n=\n \n_BasicLayout\n;\n\n\n}\n\n\n\n\n\n\nNow, in the views that should use this \n_BasicLayout\n, we can omit the layout line.\n\n\nWe do not have to specify that we want to use the view start file. MVC will locate the file and use its contents automatically. The values defined in the view file take precedence, which makes it easy to override the view start file.\n\n\nWe can also use \nmultiple view start files\n to set defaults for different parts of the application. Razor looks for the closest view start file to the view that it being processed, which means that you can override the default setting by adding a view start file to the \nViews/Home\n or \nViews/Shared\n folders, for example.\n\n\n\n\nCaution\n\n\nIt is important to understand the difference between \nomitting the Layout property\n from the view file and \nsetting it to null\n. If your view is self-contained and you do not want to use a layout, then set the Layout property to null. If you omit the Layout property, then MVC will assume that you do want a layout and that it should use the value it finds in the view start file.\n\n\n\n\nViewBag property\n#\n\n\nThe \nViewBag\n property returns a \ndynamic object\n that can be used to define arbitrary properties. Since the \nViewBag\n is dynamic, we don\u2019t have to declare the property names in advance, but it does mean that Visual Studio is unable to provide autocomplete suggestions for view bag properties.\n\n\nAttribute values\n#\n\n\nWe can also use Razor expressions to set the value of \nelement attributes\n, not only on the content.\n\n\ndiv data-productid=\n@Model.ProductID\n data-stocklevel=\n@ViewBag.StockLevel\n\n    \np\nProduct Name: @Model.Name\n/p\n\n    \np\nProduct Price: @($\n{Model.Price:C2}\n)\n/p\n\n    \np\nStock Level: @ViewBag.StockLevel\n/p\n\n\n/div\n\n\n\n\n\n\nSwitch statement\n#\n\n\nWe have to cast the dynamic ViewBag properties to the right type once, inside the condition:\n\n\n@switch ((int)ViewBag.StockLevel) {...}\n\n\n\n\n\nAfter that, inside the body, we dont need to do it any more:\n\n\ndefault:\n    @: @ViewBag.StockLevel in Stock\n    break;\n\n\n\n\n\nWe do not have to put the elements or expressions in quotes or denote them in any special way\u2014the Razor engine will interpret these as output to be processed. However, if we want to insert literal text into the view when it is not contained in an HTML element, then we need to give Razor a helping hand and prefix the line with an \n@\n character (see above).\n\n\n\n\nVisual Studio tips and tricks\n#\n\n\nEnable Developer Exception Page\n#\n\n\nIn \nStartup.cs\n add this line to the \nConfigure\n method:\n\n\napp\n.\nUseDeveloperExceptionPage\n();\n\n\n\n\n\n\n\n\nBrowser Link Loader\n#\n\n\nAdd\n\n\nMicrosoft.VisualStudio.Web.BrowserLink.Loader\n:\n \n14.0.0\n\n\n\n\n\n\nto \nproject.json\n dependencies list. Also add\n\n\napp\n.\nUseBrowserLink\n();\n\n\n\n\n\n\nto the \nConfigure\n method of \nStartup.cs\n.\n\n\nRun the project without debugging (Ctrl + F5) and you see this kind of code added to the HTML:\n\n\n!-- Visual Studio Browser Link --\n\n\nscript\n \ntype\n=\napplication/json\n \nid\n=\n__browserLink_initializationData\n\n    \n{\nrequestId\n:\n497a61f26544432a857e06ab5d501b7f\n,\nrequestMappingFromServer\n:\nfalse\n}\n\n\n/\nscript\n\n\nscript\n \ntype\n=\ntext/javascript\n\n        \nsrc\n=\nhttp://localhost:2701/029471b4ee954e43adc0d452954d080f/browserLink\n\n        \nasync\n=\nasync\n\n\n/\nscript\n\n\n!-- End Browser Link --\n\n\n\n\n\n\n\n\nAlas\n\n\nI still see no added value to it. :( Unless it is just the synchronized browsing using multiple browsers. I also see this error in the browser console:\n\n\n[14:07:17 GMT+0200 (West-Europa (zomertijd))] Browser Link: Failed to invoke return value\n\n\ncallback: TypeError: Cannot read property 'files' of null\n\n\n\n\n\n\nStatic files\n#\n\n\nASP.NET Core includes support for delivering \nstatic files\n from the wwwroot folder to clients but it isn\u2019t enabled by default when the Empty template is used to create the project. To enable static file support, add\n\n\nMicrosoft.AspNetCore.StaticFiles\n:\n \n1.0.0\n\n\n\n\n\n\nto \nproject.json\n dependencies list. Also add\n\n\napp\n.\nUseStaticFiles\n();\n\n\n\n\n\n\nto the \nConfigure\n method of \nStartup.cs\n.\n\n\n\n\nBundling and minifying\n#\n\n\nInstall \nBundler and Minifier\n extension for the Visual Studio. After that it is possible to add \ncss\n or \njs\n files to the bundle by selecting them one by one and choosing \nBundler \n Minifier | Bundle and Minify Files (Shift + Alt + F)\n from the right mouse button menu.\n\n\nThis will create a \nbundle.css\n or \nbundle.js\n file and also \nbundleconfig.json\n in the project root folder. Make sure the order of the files is what you need as \nloading order\n.\n\n\n\n\nUnit Testing with xUnit Framework\n#\n\n\nPreparation\n#\n\n\n\n\ncreate \ntest\n folder inside the solution folder next to \nsrc\n folder\n\n\nadd new \n.NET Core | Class Library (.NET Core)\n project inside the \ntest\n folder\n\n\nadd this code to its \nproject.json\n file (check the latest versions):\n\n\n\n\n  \n{\n\n      \nversion\n:\n \n1.0.0-*\n,\n\n      \ntestRunner\n:\n \nxunit\n,\n\n\n      \ndependencies\n:\n \n{\n\n          \nMicrosoft.NETCore.App\n:\n \n{\n\n              \ntype\n:\n \nplatform\n,\n\n              \nversion\n:\n \n1.0.1\n\n          \n},\n\n          \nxunit\n:\n \n2.1.0\n,\n\n          \ndotnet-test-xunit\n:\n \n2.2.0-preview2-build1029\n\n      \n},\n\n\n      \nframeworks\n:\n \n{\n\n          \nnetcoreapp1.0\n:\n \n{\n\n              \nimports\n:\n \n[\ndotnet5.6\n,\n \nportable-net45+win8\n]\n\n          \n}\n\n      \n}\n\n  \n}\n\n\n\n\n\n\n\n\nthis configuration tells Visual Studio that three packages are required:\n\n\nthe \nMicrosoft.NETCore.App\n package provides the \n.NET Core API\n.\n\n\nthe \nxunit\n package provides the testing framework.\n\n\nthe \ndotnet-test-xunit\n package provides the integration between \nxUnit\n and \nVisual Studio\n.\n\n\n\n\n\n\nadd the main project reference to the dependencies, e.g.\n\n\n\n\n  \n{\n\n      \ndependencies\n:\n \n{\n\n          \n...\n\n          \nWorkingWithVisualStudio\n:\n \n1.0.0\n\n          \n...\n\n      \n}\n\n  \n}\n\n\n\n\n\n\nFact and Theory\n#\n\n\n\n\nIn the \nxUnit\n framework, a \nFact\n is one single unit test. Example:\n\n\n\n\n  [Fact]\n\n  \npublic\n \nvoid\n \nIndexActionModelIsComplete\n()\n \n{\n\n      \n// Arrange\n\n      \nvar\n \ncontroller\n \n=\n \nnew\n \nHomeController\n();\n\n      \ncontroller\n.\nRepository\n \n=\n \nnew\n \nModelCompleteFakeRepository\n();\n\n\n      \n// Act\n\n      \nvar\n \nmodel\n \n=\n \n(\ncontroller\n.\nIndex\n()\n \nas\n \nViewResult\n)?.\nViewData\n.\nModel\n\n      \nas\n \nIEnumerable\nProduct\n;\n\n\n      \n// Assert\n\n      \nAssert\n.\nEqual\n(\ncontroller\n.\nRepository\n.\nProducts\n,\n \nmodel\n,\n\n          \nComparer\n.\nGet\nProduct\n((\np1\n,\n \np2\n)\n \n=\n \np1\n.\nName\n \n==\n \np2\n.\nName\n\n              \n \np1\n.\nPrice\n \n==\n \np2\n.\nPrice\n));\n\n  \n}\n\n\n\n\n\n\n\n\nA \nTheory\n is a way to parametrize the unit test in such a way that it becomes possible to run the same test multiple times, each time with a different set of parameter values. Example:\n\n\n\n\n  [Theory]\n\n\n  [InlineData(275, 48.95, 19.50, 24.95)]\n\n\n  [InlineData(5, 48.95, 19.50, 24.95)]\n\n  \npublic\n \nvoid\n \nIndexActionModelIsComplete\n(\ndecimal\n \nprice1\n,\n \ndecimal\n \nprice2\n,\n\n  \ndecimal\n \nprice3\n,\n \ndecimal\n \nprice4\n)\n \n{\n\n      \n// Arrange\n\n      \nvar\n \ncontroller\n \n=\n \nnew\n \nHomeController\n();\n\n      \ncontroller\n.\nRepository\n \n=\n \nnew\n \nModelCompleteFakeRepository\n \n{\n\n          \nProducts\n \n=\n \nnew\n \nProduct\n[]\n \n{\n\n              \nnew\n \nProduct\n \n{\nName\n \n=\n \nP1\n,\n \nPrice\n \n=\n \nprice1\n \n},\n\n              \nnew\n \nProduct\n \n{\nName\n \n=\n \nP2\n,\n \nPrice\n \n=\n \nprice2\n \n},\n\n              \nnew\n \nProduct\n \n{\nName\n \n=\n \nP3\n,\n \nPrice\n \n=\n \nprice3\n \n},\n\n              \nnew\n \nProduct\n \n{\nName\n \n=\n \nP4\n,\n \nPrice\n \n=\n \nprice4\n \n},\n\n          \n}\n\n      \n};\n\n\n      \n// Act\n\n      \nvar\n \nmodel\n \n=\n \n(\ncontroller\n.\nIndex\n()\n \nas\n \nViewResult\n)?.\nViewData\n.\nModel\n\n                      \nas\n \nIEnumerable\nProduct\n;\n\n\n      \n// Assert\n\n      \nAssert\n.\nEqual\n(\ncontroller\n.\nRepository\n.\nProducts\n,\n \nmodel\n,\n\n          \nComparer\n.\nGet\nProduct\n((\np1\n,\n \np2\n)\n \n=\n \np1\n.\nName\n \n==\n \np2\n.\nName\n\n              \n \np1\n.\nPrice\n \n==\n \np2\n.\nPrice\n));\n\n  \n}\n\n\n\n\n\n\nGetting Test Data from a Method or Property\n#\n\n\nWe can create methods or properties giving us the enumerations for the test parameter values in a separate class, e.g. \nProductTestData.cs\n. Then we can use \nMemberData\n attribute to specify it for the unit test to use. Example:\n\n\n[Theory]\n\n\n[ClassData(typeof(ProductTestData))]\n\n\npublic\n \nvoid\n \nIndexActionModelIsComplete\n(\nProduct\n[]\n \nproducts\n \n)\n \n{...}\n\n\n\n\n\n\nIf we want to include the test data in the same class as the unit tests, then you can use the \nMemberData\n attribute instead of \nClassData\n. The \nMemberData\n attribute is configured using a string that specifies the name of a static method that will provide an \nIEnumerable\nobject[]\n, where each object array in the sequence is a set of arguments for the test method. Example:\n\n\n[Theory]\n\n\n[MemberData(\nGetData\n)]\n\n\npublic\n \nvoid\n \nIndexActionModelIsComplete\n(\nProduct\n[]\n \nproducts\n \n)\n \n{...}\n\n\n\n\n\n\nand the \nGetData\n should look something like this\n\n\npublic\n \nstatic\n \nIEnumerable\nobject\n[]\n \nGetData\n\n\n{\n\n    \nget\n\n    \n{\n\n        \n// ...\n\n        \nyield\n \nreturn\n \nnew\n \nobject\n[]\n \n{\n \n8\n,\n \n21\n \n};\n\n        \nyield\n \nreturn\n \nnew\n \nobject\n[]\n \n{\n \n16\n,\n \n987\n \n};\n\n    \n}\n\n\n}\n\n\n\n\n\n\nEvery \nyield\n statement should return an array of objects to substitute for the Product properties. And the method itself should be of type \nIEnumerable\nobject[]\n.\n\n\n\n\nMocking with MOQ\n#\n\n\nMicrosoft\n created a special fork of the \nMoq\n project and ported it to work with \n.NET Core\n.\n\n\nIn order to be able to install the \nMoq NuGet package\n, we need first to configure the \nNuGet Options\n. Open \nTools | Options | NuGet Package Manager\n, click on \nPackage Sources\n and then on the green plus sign. Configure the new package source as follows:\n\n\n\n\nName: ASP.NET Contrib\n\n\nSource: https://www.myget.org/F/aspnet-contrib/api/v3/index.json\n\n\n\n\nAdd these two packages to the \npackage.json\n in the test project:\n\n\nmoq.netcore\n:\n \n4.4.0-beta8\n\n\nSystem.Diagnostics.TraceSource\n:\n \n4.0.0\n\n\n\n\n\n\nUsage example:\n\n\n[Fact]\n\n\npublic\n \nvoid\n \nRepositoryPropertyCalledOnce\n()\n\n\n{\n\n    \n// Arrange\n\n    \nvar\n \nmock\n \n=\n \nnew\n \nMock\nIRepository\n();\n\n    \nmock\n.\nSetupGet\n(\nm\n \n=\n \nm\n.\nProducts\n)\n\n        \n.\nReturns\n(\nnew\n[]\n \n{\n \nnew\n \nProduct\n \n{\n \nName\n \n=\n \nP1\n,\n \nPrice\n \n=\n \n100\n \n}\n \n});\n\n    \nvar\n \ncontroller\n \n=\n \nnew\n \nHomeController\n \n{\n \nRepository\n \n=\n \nmock\n.\nObject\n \n};\n\n\n    \n// Act\n\n    \nvar\n \nresult\n \n=\n \ncontroller\n.\nIndex\n();\n\n\n    \n// Assert\n\n    \nmock\n.\nVerifyGet\n(\nm\n \n=\n \nm\n.\nProducts\n,\n \nTimes\n.\nOnce\n);\n\n\n}\n\n\n\n\n\n\nExplanation:\n\n\n\n\nvar mock = new Mock\nIRepository\n();\n - define the interface to be mocked\n\n\nSetupGet(m =\n m.Products)\n - specify the property to be tested\n\n\n.Returns(...)\n - specify the test value to be returned\n\n\nRepository = mock.Object\n - \nObject\n is the special property that gives back the object we mock for this test\n\n\nmock.VerifyGet(m =\n m.Products, Times.Once);\n - one of the verify methods to inspect the getter property\n\n\n\n\n\n\nSportsStore\n#\n\n\n\n\nCreate a new empty \nASP.NET Core Web Application (.NET Core)\n project/solution.\n\n\nAdd these packages/tools to the \nproject.json\n file:\n\n\n\n\n  \ndependencies\n:\n \n{\n\n      \n...\n\n      \nMicrosoft.AspNetCore.Razor.Tools\n:\n \n{\n\n          \nversion\n:\n \n1.0.0-preview2-final\n,\n\n          \ntype\n:\n \nbuild\n\n      \n},\n\n      \nMicrosoft.AspNetCore.StaticFiles\n:\n \n1.0.0\n,\n\n      \nMicrosoft.AspNetCore.Mvc\n:\n \n1.0.1\n\n  \n}\n,\n\n  \ntools\n:\n \n{\n\n      \nMicrosoft.AspNetCore.Razor.Tools\n:\n \n1.0.0-preview2-final\n,\n\n      \n...\n\n  \n}\n,\n\n\n\n\n\n\n\n\nIn addition to the packages in the \ndependencies\n section, there is an addition to the \ntools\n section of the \nproject.json\n file that configures the \nMicrosoft.AspNetCore.Razor.Tools\n package for use in Visual Studio and enables IntelliSense for the built-in tag helpers, which are used to create HTML content that is tailored to the configuration of the MVC application.\n\n\nHere is the \nStartup.cs\n:\n\n\n\n\n  \nusing\n \nMicrosoft.AspNetCore.Builder\n;\n\n  \nusing\n \nMicrosoft.AspNetCore.Hosting\n;\n\n  \nusing\n \nMicrosoft.AspNetCore.Http\n;\n\n  \nusing\n \nMicrosoft.Extensions.DependencyInjection\n;\n\n  \nusing\n \nMicrosoft.Extensions.Logging\n;\n\n\n  \nnamespace\n \nSportsStore\n\n  \n{\n\n      \npublic\n \nclass\n \nStartup\n\n      \n{\n\n          \npublic\n \nvoid\n \nConfigureServices\n(\nIServiceCollection\n \nservices\n)\n\n          \n{\n\n              \nservices\n.\nAddMvc\n();\n\n          \n}\n\n\n          \npublic\n \nvoid\n \nConfigure\n(\nIApplicationBuilder\n \napp\n,\n\n          \nIHostingEnvironment\n \nenv\n,\n \nILoggerFactory\n \nloggerFactory\n)\n\n          \n{\n\n              \napp\n.\nUseDeveloperExceptionPage\n();\n\n              \napp\n.\nUseStatusCodePages\n();\n\n              \napp\n.\nUseStaticFiles\n();\n\n              \napp\n.\nUseMvcWithDefaultRoute\n();\n\n          \n}\n\n      \n}\n\n  \n}\n\n\n\n\n\n\n\n\nThe \nConfigureServices\n method is used to set up shared objects that can be used throughout the application through the \ndependency injection\n feature. The \nAddMvc\n method that is called in the \nConfigureServices\n method is an extension method that sets up the shared objects used in MVC applications.\n\n\nThe \nConfigure\n method is used to set up the features that receive and process \nHTTP requests\n.\n\n\nadd these folders: \nModels\n, \nControllers\n, \nViews\n\n\nin the \nViews\n folder add \n_ViewImports.cshtml\n file:\n\n\n\n\n  \n@using\n \nSportsStore\n.\nModels\n\n  \n@addTagHelper\n \n*,\n \nMicrosoft\n.\nAspNetCore\n.\nMvc\n.\nTagHelpers\n\n\n\n\n\n\n\n\ncreate the unit test project \nSportsStore.Tests\n in the \ntest\n folder.\n\n\nConfigure its \nproject .json\n as follows:\n\n\n\n\n  \n{\n\n      \nversion\n:\n \n1.0.0-*\n,\n\n      \ntestRunner\n:\n \nxunit\n,\n\n      \ndependencies\n:\n \n{\n\n          \nMicrosoft.NETCore.App\n:\n \n{\n\n              \ntype\n:\n \nplatform\n,\n\n              \nversion\n:\n \n1.0.1\n\n          \n},\n\n          \nxunit\n:\n \n2.1.0\n,\n\n          \ndotnet-test-xunit\n:\n \n2.2.0-preview2-build1029\n,\n\n          \nmoq.netcore\n:\n \n4.4.0-beta8\n,\n\n          \nSystem.Diagnostics.TraceSource\n:\n \n4.0.0\n,\n\n          \nSportsStore\n:\n \n1.0.0\n\n      \n},\n\n      \nframeworks\n:\n \n{\n\n          \nnetcoreapp1.0\n:\n \n{\n\n              \nimports\n:\n \n[\n \ndotnet5.6\n,\n \nportable-net45+win8\n \n]\n\n          \n}\n\n      \n}\n\n  \n}\n\n\n\n\n\n\n\n\nMake sure that both \nproject.json\n files refer to the same \nASP.NET Core MVC\n version.\n\n\nAdd your model class \nProduct.cs\n, repository interface \nIProductRepository\n and a simple fake repository \nFakeProductRepository\n\n\nRegister the fake repository as a service in \nStartup.cs\n:\n\n\n\n\n  \npublic\n \nvoid\n \nConfigureServices\n(\nIServiceCollection\n \nservices\n)\n\n  \n{\n\n      \nservices\n.\nAddTransient\nIProductRepository\n,\n \nFakeProductRepository\n();\n\n      \n...\n\n  \n}\n\n\n\n\n\n\n\n\nAdd the following standard views:\n\n\nViews/Shared/_Layout.cshtml\n\n\nViews/_ViewStart.cshtml\n refering to \n_Layout.cshtml\n by default\n\n\nExample of setting up the default route in \nStartup.cs\n. Substitute\n\n\n\n\n  \napp\n.\nUseMvcWithDefaultRoute\n();\n\n\n\n\n\n\n\n\nwith\n\n\n\n\n  \napp\n.\nUseMvc\n(\nroutes\n \n=\n\n  \n{\n\n      \nroutes\n.\nMapRoute\n(\n\n          \nname\n:\n \ndefault\n,\n\n          \ntemplate\n:\n \n{controller=Product}/{action=List}/{id?}\n);\n\n  \n});\n\n\n\n\n\n\n\n\nScaffolding\n#\n\n\nSome people prefer to have certain features automatically created when they create new controller or views. That is called \nscaffolding\n. If you want that, add the following packages to the \nproject.json\n file:\n\n\n...\n\n\ndependencies\n:\n \n{\n\n    \n...\n\n    \nMicrosoft.AspNetCore.StaticFiles\n:\n \n1.0.0\n,\n\n    \nMicrosoft.AspNetCore.Mvc\n:\n \n1.0.0\n,\n\n    \nMicrosoft.VisualStudio.Web.CodeGeneration.Tools\n:\n \n{\n\n        \nversion\n:\n \n1.0.0-preview2-final\n,\n\n        \ntype\n:\n \nbuild\n\n    \n},\n\n    \nMicrosoft.VisualStudio.Web.CodeGenerators.Mvc\n:\n \n{\n\n        \nversion\n:\n \n1.0.0-preview2-final\n,\n\n        \ntype\n:\n \nbuild\n\n    \n}\n\n\n}\n\n\n...\n\n\ntools\n:\n \n{\n\n    \n...\n\n    \nMicrosoft.VisualStudio.Web.CodeGeneration.Tools\n:\n \n{\n\n        \nversion\n:\n \n1.0.0-preview2-final\n,\n\n        \nimports\n:\n \n[\n\n            \nportable-net45+win8+dnxcore50\n,\n\n            \nportable-net45+win8\n\n        \n]\n\n    \n}\n\n\n}\n\n\n...\n\n\n\n\n\n\n\n\nSetup the database\n#\n\n\n\n\nadd \nEntityFramework\n packages to \npackage.json\n:\n\n\n\n\n  \ndependencies\n:\n \n{\n\n      \n...\n\n      \nMicrosoft.EntityFrameworkCore.SqlServer\n:\n \n1.0.1\n,\n\n      \nMicrosoft.EntityFrameworkCore.Tools\n:\n \n1.0.0-preview2-final\n\n  \n}\n\n\n\n\n\n\n\n\nand the tools:\n\n\n\n\n  \ntools\n:\n \n{\n\n      \n...\n\n      \nMicrosoft.EntityFrameworkCore.Tools\n:\n \n{\n\n          \nversion\n:\n \n1.0.0-preview2-final\n,\n\n          \nimports\n:\n \n[\n \nportable-net45+win8+dnxcore50\n,\n \nportable-net45+win8\n \n]\n\n      \n}\n\n  \n}\n\n\n\n\n\n\n\n\nThe \ndatabase context class\n is the bridge between the \napplication\n and the \nEF Core\n and provides access to the application\u2019s data using model objects. To create the database context class for the \nSportsStore\n application, we add a class file called \nApplicationDbContext.cs\n to the \nModels\n folder:\n\n\n\n\n  \nusing\n \nMicrosoft.EntityFrameworkCore\n;\n\n\n  \nnamespace\n \nSportsStore.Models\n\n  \n{\n\n      \npublic\n \nclass\n \nApplicationDbContext\n \n:\n \nDbContext\n\n      \n{\n\n          \npublic\n \nApplicationDbContext\n(\nDbContextOptions\nApplicationDbContext\n \noptions\n)\n\n              \n:\n \nbase\n(\noptions\n)\n \n{\n \n}\n\n          \npublic\n \nDbSet\nProduct\n \nProducts\n \n{\n \nget\n;\n \nset\n;\n \n}\n\n      \n}\n\n  \n}\n\n\n\n\n\n\n\n\nTo populate the database initially with some data, we use \nSeedData.cs\n class:\n\n\n\n\n  \nusing\n \nSystem.Linq\n;\n\n  \nusing\n \nMicrosoft.AspNetCore.Builder\n;\n\n  \nusing\n \nMicrosoft.Extensions.DependencyInjection\n;\n\n  \nnamespace\n \nSportsStore.Models\n\n  \n{\n\n      \npublic\n \nstatic\n \nclass\n \nSeedData\n\n      \n{\n\n          \npublic\n \nstatic\n \nvoid\n \nEnsurePopulated\n(\nIApplicationBuilder\n \napp\n)\n\n          \n{\n\n              \nApplicationDbContext\n \ncontext\n \n=\n\n                  \napp\n.\nApplicationServices\n.\nGetRequiredService\nApplicationDbContext\n();\n\n\n              \nif\n \n(!\ncontext\n.\nProducts\n.\nAny\n())\n\n              \n{\n\n                  \ncontext\n.\nProducts\n.\nAddRange\n(\n\n                  \nnew\n \nProduct\n\n                  \n{\n\n                      \nName\n \n=\n \nKayak\n,\n\n                      \nDescription\n \n=\n \nA boat for one person\n,\n\n                      \nCategory\n \n=\n \nWatersports\n,\n\n                      \nPrice\n \n=\n \n275\n\n                  \n},\n\n                  \n...\n\n\n                  \ncontext\n.\nSaveChanges\n();\n\n              \n}\n\n          \n}\n\n      \n}\n\n  \n}\n\n\n\n\n\n\n\n\nThe static \nEnsurePopulated\n method receives an \nIApplicationBuilder\n argument, which is the class used in the \nConfigure\n method of the \nStartup\n class to register middleware classes to handle HTTP requests, which is where we ensure that the database has content.\n\n\nThe \nEnsurePopulated\n method obtains an \nApplicationDbContext\n object through the \nIApplicationBuilder\n interface and uses it to check whether there are any \nProduct\n objects in the database. If there are no objects, then the database is populated using a collection of \nProduct\n objects using the \nAddRange\n method and then written to the database using the \nSaveChanges\n method.\n\n\nThe next step is to create a class that implements the \nIProductRepository\n interface and gets its data using \nEntity Framework Core\n from the \nApplicationDbContext\n.\n\n\n\n\n  \nusing\n \nSystem.Collections.Generic\n;\n\n\n  \nnamespace\n \nSportsStore.Models\n\n  \n{\n\n      \npublic\n \nclass\n \nEFProductRepository\n \n:\n \nIProductRepository\n\n      \n{\n\n          \nprivate\n \nApplicationDbContext\n \ncontext\n;\n\n          \npublic\n \nEFProductRepository\n(\nApplicationDbContext\n \nctx\n)\n\n          \n{\n\n              \ncontext\n \n=\n \nctx\n;\n\n          \n}\n\n          \npublic\n \nIEnumerable\nProduct\n \nProducts\n \n=\n \ncontext\n.\nProducts\n;\n\n      \n}\n\n  \n}\n\n\n\n\n\n\n\n\ncreate \nappsettings.json\n file in the project root folder based on the \nASP.NET Configuration File\n template and configure the connection string:\n\n\n\n\n  \n{\n\n      \nData\n:\n \n{\n\n          \nSportStoreProducts\n:\n \n{\n\n              \nConnectionString\n:\n \nServer=(localdb)\\\\MSSQLLocalDB;Database=SportsStore;Trusted_Connection=True;MultipleActiveResultSets=true\n\n          \n}\n\n      \n}\n\n  \n}\n\n\n\n\n\n\n\n\nadd a new dependency to read the \njson\n configuration file:\n\n\n\n\n  \ndependencies\n:\n \n{\n\n      \n...\n\n      \nMicrosoft.Extensions.Configuration.Json\n:\n \n1.0.0\n\n  \n}\n,\n\n\n\n\n\n\n\n\nconfigure the \nStartup.cs\n:\n\n\n\n\n  \n...\n\n  \nusing\n \nMicrosoft.EntityFrameworkCore\n;\n\n  \nusing\n \nMicrosoft.Extensions.Configuration\n;\n\n\n  \nnamespace\n \nSportsStore\n\n  \n{\n\n      \npublic\n \nclass\n \nStartup\n\n      \n{\n\n          \nIConfigurationRoot\n \nConfiguration\n;\n\n\n          \npublic\n \nStartup\n(\nIHostingEnvironment\n \nenv\n)\n\n          \n{\n\n              \nConfiguration\n \n=\n \nnew\n \nConfigurationBuilder\n()\n\n                  \n.\nSetBasePath\n(\nenv\n.\nContentRootPath\n)\n\n                  \n.\nAddJsonFile\n(\nappsettings.json\n).\nBuild\n();\n\n          \n}\n\n\n          \npublic\n \nvoid\n \nConfigureServices\n(\nIServiceCollection\n \nservices\n)\n\n          \n{\n\n              \nservices\n.\nAddDbContext\nApplicationDbContext\n(\noptions\n \n=\n\n                  \noptions\n.\nUseSqlServer\n(\nConfiguration\n[\nData:SportStoreProducts:ConnectionString\n]));\n\n              \nservices\n.\nAddTransient\nIProductRepository\n,\n \nEFProductRepository\n();\n\n              \n...\n\n          \n}\n\n\n          \npublic\n \nvoid\n \nConfigure\n(\n\n              \nIApplicationBuilder\n \napp\n,\n\n              \nIHostingEnvironment\n \nenv\n,\n\n              \nILoggerFactory\n \nloggerFactory\n)\n\n          \n{\n\n              \n...\n\n              \nSeedData\n.\nEnsurePopulated\n(\napp\n);\n\n          \n}\n\n      \n}\n\n  \n}\n\n\n\n\n\n\n\n\nopen \nTools | Nuget Package Manager | Package Manager Console\n to create and apply database migrations:\n\n\n\n\n  Add-Migration Initial\n  Update-Database\n\n\n\n\n\n\n\nrebuild the solution and run - we will see the list of products loaded from the database.\n\n\n\n\n\n\nViewModels and TagHelpers\n#\n\n\n\n\nIf we want to customize the information to be used in the view, we can do that with \nViewModels\n. For that we create a \nViewModels\n subfolder inside the \nModels\n folder. They can \nbe registered\n in \n_ViewImports.cshtml\n.\n\n\nTagHelpers\n are one of the most useful ways that you can introduce C# logic into your views. The code for a tag helper can look tortured because C# and HTML don\u2019t mix easily. But using tag helpers is preferable to including blocks of C# code in a view because a tag helper can be easily \nunit tested\n. Most MVC components, such as controllers and views, are discovered automatically, but tag helpers \nhave to be registered\n in \n_ViewImports.cshtml\n.\n\n\nTo test the \ntag helper\n class, I call the \nProcess\n method with test data and provide a \nTagHelperOutput\n object that is inspected to see the HTML that was generated.\n\n\nWhen we pass the data to the view via a view model, we need to replace the type. E.g. it can become \n@model ProductsListViewModel\n and \nModel.Products\n instead of \n@model IEnumerable\nProduct\n and \nModel\n.\n\n\n\n\n\n\nInstalling Bootstrap package\n#\n\n\nAdd \nbower.json\n file to the project root:\n\n\n{\n\n    \nname\n:\n \nasp.net\n,\n\n    \nprivate\n:\n \ntrue\n,\n\n    \ndependencies\n:\n \n{\n\n        \nbootstrap\n:\n \n3.3.7\n\n    \n}\n\n\n}\n\n\n\n\n\n\nThis will add \nwwwroot/lib\n folder and inside it \nbootstrap\n and \njquery\n sources.\n\n\n\n\nImproving the URLs\n#\n\n\nNormally, the page links look like this:\n\n\nhttp://localhost/?page=2\n\n\nBut we can make them more user friendly by creating a scheme that follows the pattern of \ncomposable URLs\n, which look like this:\n\n\nhttp://localhost/Page2\n\n\nTo do that we register a new route in our MVC middleware (\nConfigure\n method in \nStartup.cs\n):\n\n\nroutes\n.\nMapRoute\n(\n\n    \nname\n:\n \npagination\n,\n\n    \ntemplate\n:\n \nProducts/Page{page}\n,\n\n    \ndefaults\n:\n \nnew\n \n{\n \nController\n \n=\n \nProduct\n,\n \naction\n \n=\n \nList\n \n});\n\n\n\n\n\n\nIt is important that this route is added \nbefore\n the default route.\n\n\n\n\nEnabling Sessions\n#\n\n\nAdd these new packages to the \npackage.json\n:\n\n\nMicrosoft.AspNetCore.Session\n:\n \n1.0.0\n,\n\n\nMicrosoft.Extensions.Caching.Memory\n:\n \n1.0.0\n,\n\n\nMicrosoft.AspNetCore.Http.Extensions\n:\n \n1.0.0\n\n\n\n\n\n\nRegister new services and middleware to the \nStartup.cs\n:\n\n\npublic\n \nvoid\n \nConfigureServices\n(\nIServiceCollection\n \nservices\n)\n \n{\n\n    \n...\n\n    \nservices\n.\nAddMemoryCache\n();\n\n    \nservices\n.\nAddSession\n();\n\n    \nservices\n.\nAddMvc\n();\n\n\n}\n\n\n\npublic\n \nvoid\n \nConfigure\n(\nIApplicationBuilder\n \napp\n,\n\n    \n...\n\n    \napp\n.\nUseSession\n();\n\n    \napp\n.\nUseMvc\n(...);\n\n\n}\n\n\n\n\n\n\n\n\nAddMemoryCache\n\n\nThe \nAddMemoryCache\n method call sets up the in-memory data store. The \nAddSession\n method registers the services used to access session data, and the \nUseSession\n method allows the session system to automatically associate requests with sessions when they arrive from the client.\n\n\n\n\n\n\nAnnotations\n#\n\n\n\n\nBindNever\n attribute prevents the user supplying values for these properties in an HTTP request.\n\n\n\n\nAdding migrations\n#\n\n\nSuppose we add a new \nDbSet\n to our \nApplicationDbContext.cs\n:\n\n\npublic\n \nclass\n \nApplicationDbContext\n \n:\n \nDbContext\n\n\n{\n\n    \npublic\n \nApplicationDbContext\n(\nDbContextOptions\nApplicationDbContext\n \noptions\n)\n\n        \n:\n \nbase\n(\noptions\n)\n \n{\n \n}\n\n    \n...\n\n    \npublic\n \nDbSet\nOrder\n \nOrders\n \n{\n \nget\n;\n \nset\n;\n \n}\n\n\n}\n\n\n\n\n\n\nTo create the \nmigration\n, open the NuGet \nPackage Manger Console\n from the \nTools \u27a4 NuGet Package Manage\n menu and run the following command :\n\n\nAdd-Migration Orders\n\n\nThis command tells EF Core to take a new snapshot of the application, work out how it differs from the previous database version, and generate a new migration called \nOrders\n. The name \nOrders\n here is arbitrary but it is handy to let it reflect the change.\n\n\nTo update the database schema, run the following command:\n\n\nUpdate-Database\n\n\n\n\nResetting the Database\n#\n\n\nWhen you are making frequent changes to the model, there will come a point when your migrations and your database schema get out of sync. The easiest thing to do is delete the database and start over. However, this applies \nonly during development\n, of course, because you will lose any data you have stored.\n\n\n\n\nSelect the \nSQL Server Object Explorer\n item from the Visual Studio \nView\n menu and click the \nAdd Sql Server\n button.\n\n\nEnter \n(localdb)\\mssqllocaldb\n into the \nServer Name\n field and click the \nConnect\n button. A new item will appear in the \nSQL Server Object Explorer\n window, which you can expand to see the \nLocalDB\n databases that have been created.\n\n\nRight-click the database you want to remove and select \nDelete\n from the pop-up menu. \nCheck the option to close the existing connections\n and then click the \nOK\n button to delete the database.\n\n\nOnce the database has been removed, run the following command from the \nPackage Manager Console\n to create the database and apply the migrations you have created by running the following command:\n\n\n\n\nUpdate-Database\n\n\n\n\nThis will reset the database so that it accurately reflects your model and allow you to return to developing your application.\n\n\n\n\n\n\nUsing TempData\n#\n\n\nWe are using TempData in the POST method in a controller:\n\n\n[HttpPost]\n\n\npublic\n \nIActionResult\n \nEdit\n(\nProduct\n \nproduct\n)\n\n\n{\n\n    \nif\n \n(\nModelState\n.\nIsValid\n)\n\n    \n{\n\n        \n_repository\n.\nSaveProduct\n(\nproduct\n);\n\n        \nTempData\n[\nmessage\n]\n \n=\n \n$\n{product.Name} has been saved\n;\n\n        \nreturn\n \nRedirectToAction\n(\nIndex\n);\n\n    \n}\n\n    \nelse\n\n    \n{\n\n        \n// there is something wrong with the data values\n\n        \nreturn\n \nView\n(\nproduct\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nWe check that the model binding process has been able to validate the data submitted to the user by reading the value of the \nModelState.IsValid\n property. If everything is OK, we save the changes to the repository and redirect the user to the \nIndex\n action so they see the modified list of products. If there is a problem with the data, we render the default view again so that the user can make corrections.\n\n\nAfter we have saved the changes in the repository, we store a message using the \nTempData\n feature, which is part of the \nASP.NET Core session state\n feature. This is a \nkey/value\n dictionary similar to the \nsession data\n and \nview bag\n features we used previously.\n\n\nThe key difference from \nsession data\n is that \ntemp data\n persists until it is read. We cannot use \nViewBag\n in this situation because \nViewBag\n passes data between the \ncontroller\n and \nview\n, and it cannot hold data for longer than \nthe current HTTP request\n. When an edit succeeds, the browser is redirected to a new URL, so the \nViewBag\n data is lost.\n\n\nWe could use the \nsession data\n feature, but then the message would be persistent until we explicitly removed it, which we would rather not have to do.\n\n\nSo, the \ntemp data\n feature is the perfect fit. The data is restricted to a \nsingle user\u2019s session\n (so that users do not see each other\u2019s \nTempData\n) and will persist long enough for us to read it. We will read the data in the \nview\n rendered by the \naction method\n to which we redirect the user\n\n\nThe message will be displayed once and disappear if you reload the screen with the template using this \ntemp data\n, because \nTempData\n is deleted when it is read. That is convenient since we do not want old messages hanging around.\n\n\n\n\nLocalization hell\n#\n\n\nBy the time we get to editing with validation, something bad happens. It looks that by default the \njQuery-validation\n (client side validation) expects \n\"en-US\"\n as its culture and the server side validation expects \n\"nl-NL\"\n. Therefore, when I see \n\u20ac\n as currency and \n\",\"\n as decimal separator, I cannot change the price. Neither \n\",\"\n nor \n\".\"\n are accepted. One is rejected by the client side and the other by the server side validation.\n\n\nTemporary workaround was to configure \n\"en-US\"\n as the default culture, so that \n\"$\"\n and \n\".\"\n are displayed on the screen. Then the validation works.\n\n\n\n\nAdding Identity\n#\n\n\nAdd a new dependency to \nproject.json\n:\n\n\ndependencies\n:\n \n{\n\n    \n...\n\n    \nMicrosoft.AspNetCore.Identity.EntityFrameworkCore\n:\n \n1.0.0\n\n\n}\n\n\n\n\n\n\nAdd a new \nAppIdentityDbContext\n class to \nModels\n folder:\n\n\nusing\n \nMicrosoft.AspNetCore.Identity.EntityFrameworkCore\n;\n\n\nusing\n \nMicrosoft.EntityFrameworkCore\n;\n\n\n\nnamespace\n \nSportsStore.Models\n\n\n{\n\n    \npublic\n \nclass\n \nAppIdentityDbContext\n \n:\n \nIdentityDbContext\nIdentityUser\n\n    \n{\n\n        \npublic\n \nAppIdentityDbContext\n(\nDbContextOptions\nAppIdentityDbContext\n \noptions\n)\n\n            \n:\n \nbase\n(\noptions\n)\n \n{\n \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\nand a new connection string in \nappsettings.json\n file:\n\n\n{\n\n    \nData\n:\n \n{\n\n        \n...\n\n        \nSportStoreIdentity\n:\n \n{\n\n            \nConnectionString\n:\n \nServer=(localdb)\\\\MSSQLLocalDB;Database=Identity;Trusted_Connection=True;MultipleActiveResultSets=true\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\nAdd new services to \nConfigureServices\n in \nStartup.cs\n:\n\n\npublic\n \nvoid\n \nConfigureServices\n(\nIServiceCollection\n \nservices\n)\n\n\n{\n\n    \n...\n\n    \nservices\n.\nAddDbContext\nAppIdentityDbContext\n(\noptions\n \n=\n\n        \noptions\n.\nUseSqlServer\n(\nConfiguration\n[\nData:SportStoreIdentity:ConnectionString\n]));\n\n\n    \nservices\n.\nAddIdentity\nIdentityUser\n,\n \nIdentityRole\n()\n\n        \n.\nAddEntityFrameworkStores\nAppIdentityDbContext\n();\n\n    \n...\n\n\n}\n\n\n\n\n\n\nand new entries in \nConfigure\n:\n\n\npublic\n \nvoid\n \nConfigure\n()\n\n    \napp\n.\nUseIdentity\n();\n\n    \napp\n.\nUseMvc\n();\n\n    \nSeedData\n.\nEnsurePopulated\n(\napp\n);\n\n    \nIdentitySeedData\n.\nEnsurePopulated\n(\napp\n);\n\n\n}\n\n\n\n\n\n\nIdentitySeedData\n should be created in the \nModels\n folder to create an administrative account.\n\n\nusing\n \nMicrosoft.AspNetCore.Builder\n;\n\n\nusing\n \nMicrosoft.AspNetCore.Identity\n;\n\n\nusing\n \nMicrosoft.AspNetCore.Identity.EntityFrameworkCore\n;\n\n\nusing\n \nMicrosoft.Extensions.DependencyInjection\n;\n\n\n\nnamespace\n \nSportsStore.Models\n\n\n{\n\n    \npublic\n \nstatic\n \nclass\n \nIdentitySeedData\n\n    \n{\n\n        \nprivate\n \nconst\n \nstring\n \nadminUser\n \n=\n \nAdmin\n;\n\n        \nprivate\n \nconst\n \nstring\n \nadminPassword\n \n=\n \nSecret123$\n;\n\n\n        \npublic\n \nstatic\n \nasync\n \nvoid\n \nEnsurePopulated\n(\nIApplicationBuilder\n \napp\n)\n\n        \n{\n\n            \nUserManager\nIdentityUser\n \nuserManager\n \n=\n \napp\n.\nApplicationServices\n\n                \n.\nGetRequiredService\nUserManager\nIdentityUser\n();\n\n\n            \nIdentityUser\n \nuser\n \n=\n \nawait\n \nuserManager\n.\nFindByIdAsync\n(\nadminUser\n);\n\n\n            \nif\n \n(\nuser\n \n==\n \nnull\n)\n\n            \n{\n\n                \nuser\n \n=\n \nnew\n \nIdentityUser\n(\nAdmin\n);\n\n                \nawait\n \nuserManager\n.\nCreateAsync\n(\nuser\n,\n \nadminPassword\n);\n\n            \n}\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\n\nAdding Identity migrations\n#\n\n\n\n\nAdd-Migration Initial -Context AppIdentityDbContext\n\n\nUpdate-Database -Context AppIdentityDbContext\n\n\n\n\nThis will create the new database and add the \nAspNetUsers\n and \nAspNetRoles\n in it.\n\n\n\n\nAdding Authorization\n#\n\n\nWhen \nASP.NET Core Identity\n is in place, we can apply \nAuthorization\n. We don\u2019t want to stop unauthenticated users from accessing the other action methods in the \nOrder\n controller, so we have applied the \nAuthorize\n attribute only to the \nList\n and \nMarkShipped\n methods.\n\n\n[Authorize]\n\n\npublic\n \nViewResult\n \nList\n()\n \n=\n\n    \nView\n(\n_repository\n.\nOrders\n.\nWhere\n(\no\n \n=\n \n!\no\n.\nShipped\n));\n\n\n\n[HttpPost]\n\n\n[Authorize]\n\n\npublic\n \nIActionResult\n \nMarkShipped\n(\nint\n \norderID\n)\n \n{...}\n\n\n\n\n\n\nWe want to protect \nall of the action methods\n defined by the \nAdmin\n controller, and we can do this by applying the \nAuthorize\nattribute to the controller class, which then applies the authorization policy to all the action methods it contains.\n\n\n[Authorize]\n\n\npublic\n \nclass\n \nAdminController\n \n:\n \nController\n\n\n{...}\n\n\n\n\n\n\n\n\nCaution\n\n\nIn general, using client-side data validation is a good idea. It offloads some of the work from your server and gives users immediate feedback about the data they are providing. However, you should not be tempted to perform authentication at the client, as this would typically involve sending valid credentials to the client so they can be used to check the username and password that the user has entered, or at least trusting the client\u2019s report of whether they have successfully authenticated. Authentication should always be done at the server.\n\n\n\n\n\n\nSources used\n#\n\n\n\n\nAdam Freeman - Pro ASP.NET Core MVC (2016)\n\n\nChristian Nagel - Professional C# 6 and .NET Core 1.0 (2016)", 
            "title": "Notes"
        }, 
        {
            "location": "/dotnet/notes/#notes-on-aspnet-core", 
            "text": "Notes on ASP.NET Core  Conventions  Extension methods  Class extensions  Interface extensions  Filtering    Lambda anonymous functions  Asynchronous methods  Getting property names with nameof  Workflow with an empty project  The JSON Configuration Files  Razor  View Imports File  View Start File  ViewBag property  Attribute values  Switch statement    Visual Studio tips and tricks  Enable Developer Exception Page    Browser Link Loader  Static files  Bundling and minifying  Unit Testing with xUnit Framework  Preparation  Fact and Theory  Getting Test Data from a Method or Property    Mocking with MOQ  SportsStore  Scaffolding  Setup the database  ViewModels and TagHelpers  Installing Bootstrap package  Improving the URLs  Enabling Sessions  Annotations  Adding migrations    Resetting the Database  Using TempData  Localization hell  Adding Identity  Adding Identity migrations  Adding Authorization  Sources used       I have written these notes while working on a couple of great books on the subject. See  Sources used .  Models  - the  M  in  MVC  - contain the data that users work with. There are two broad types of model:   view models , which represent just data passed from the controller to the view, and  domain models , which contain the data in a business domain, along with the operations, transformations, and rules for creating, storing, and manipulating that data, collectively referred to as the model logic.   In ASP.NET Core MVC,  controllers  are C# classes, usually derived from the  Microsoft.AspNetCore.Mvc.Controller  class. Each  public  method in a class derived from  Controller  is an  action method , which is associated with a  URL .", 
            "title": "Notes on ASP.NET Core"
        }, 
        {
            "location": "/dotnet/notes/#conventions", 
            "text": "put the third-party JavaScript and CSS packages you rely on in the  wwwroot/lib  folder.  convention over configuration  the controller for  /product  uri should have the name  ProductController.cs  and reside in the  /Controllers  folder; from other parts in the project, such as when using an HTML helper method, you specify the first part of the name ( Product ), and MVC automatically appends  Controller  to the name and starts looking for the controller class.  views for  /product  uri associated with  ProductController  should all reside in the  /Views/Product  folder.  MVC expects that the  default view  for an  action method  should be named after that method. For example, the default view associated with an action method called  List  should be called  List.cshtml . Thus, for the  List action method  in the  ProductController  class, the  default view  is expected to be  /Views/Product/List.cshtml . The  default view  is used when you return the result of calling the  View  method in an action method, like this:      return   View ();   You can specify a different view by name, like this:     return   View ( MyOtherView );    When looking for a  view , MVC looks in the folder named after the controller and then in the  /Views/Shared  folder. This means that I can put views that will be used by more than one controller in the  /Views/Shared  folder and MVC will find them.  The naming convention for  layouts  is to prefix the file with an underscore ( _ ) character, and layout files are placed in the  /Views/Shared  folder. This layout is applied to all views by default through the  /Views/_ViewStart.cshtml  file. If you do not want the default layout applied to views, you can change the settings in  ViewStart.cshtml  (or delete the file entirely) to specify another layout in the view, like this:      @ { \n     Layout   =   ~/_MyLayout.cshtml ; \n   }    Or you can disable any layout for a given view, like this:      @ { \n     Layout   =   null ; \n   }", 
            "title": "Conventions"
        }, 
        {
            "location": "/dotnet/notes/#extension-methods", 
            "text": "", 
            "title": "Extension methods"
        }, 
        {
            "location": "/dotnet/notes/#class-extensions", 
            "text": "Suppose we have a simple class:  using   System.Collections.Generic ;  namespace   LanguageFeatures.Models  { \n     public   class   ShoppingCart \n     { \n         public   IEnumerable Product   Products   {   get ;   set ;   } \n     }  }   We want to extend its functionality with a new method to calculate the total amount:  public   static   decimal   TotalPrices ( this   ShoppingCart   cartParam )  { \n     decimal   total   =   0 ; \n\n     foreach   ( Product   prod   in   cartParam . Products ) \n     { \n         total   +=   prod ?. Price   ??   0 ; \n     } \n     return   total ;  }   We can then use this extension method like this:  ShoppingCart   cart   =   new   ShoppingCart   {   Products   =   Product . GetProducts ()   };  decimal   cartTotal   =   cart . TotalPrices ();", 
            "title": "Class extensions"
        }, 
        {
            "location": "/dotnet/notes/#interface-extensions", 
            "text": "using   System.Collections ;  using   System.Collections.Generic ;  namespace   LanguageFeatures.Models  { \n     public   class   ShoppingCart   :   IEnumerable Product \n     { \n         public   IEnumerable Product   Products   {   get ;   set ;   } \n\n         public   IEnumerator Product   GetEnumerator () \n         { \n            return   Products . GetEnumerator (); \n         } \n\n         IEnumerator   IEnumerable . GetEnumerator () \n         { \n             return   GetEnumerator (); \n         } \n     }  }   We can rewrite our extension method like this:  public   static   decimal   TotalPrices ( this   IEnumerable Product   products )  { \n     decimal   total   =   0 ; \n\n     foreach   ( Product   prod   in   products ) \n     { \n         total   +=   prod ?. Price   ??   0 ; \n     } \n     return   total ;  }   and use it with any object of type  IEnumerable Product  like  ShoppingCart  and  Product  array:  ShoppingCart   cart   =   new   ShoppingCart   {   Products   =   Product . GetProducts ()   };  Product []   productArray   =  { \n     new   Product   { Name   =   Kayak ,   Price   =   275 M }, \n     new   Product   { Name   =   Lifejacket ,   Price   =   48.95 M }  };  decimal   cartTotal   =   cart . TotalPrices ();  decimal   arrayTotal   =   productArray . TotalPrices ();", 
            "title": "Interface extensions"
        }, 
        {
            "location": "/dotnet/notes/#filtering", 
            "text": "Extension methods can be used to  filter  collections of objects. An extension method that operates on an  IEnumerable T  and that also returns an  IEnumerable T  can use the  yield  keyword to apply selection criteria to items in the source data to produce a reduced set of results.  using   System.Collections.Generic ;  namespace   LanguageFeatures.Models  { \n     public   static   class   MyExtensionMethods \n     { \n         public   static   IEnumerable Product   FilterByPrice ( \n             this   IEnumerable Product   productEnum , \n             decimal   minimumPrice ) \n         { \n             foreach   ( Product   prod   in   productEnum ) \n             { \n                 if   (( prod ?. Price   ??   0 )   =   minimumPrice ) \n                 { \n                     yield   return   prod ; \n                 } \n             } \n         } \n     }  }", 
            "title": "Filtering"
        }, 
        {
            "location": "/dotnet/notes/#lambda-anonymous-functions", 
            "text": "We can repeat this process indefinitely and create a different filter method for every property and every combination of properties that we are interested in. A more elegant approach is to separate out the code that processes the enumeration from the selection criteria. C# makes this easy by allowing functions to be passed around as objects. We can then create a single extension method that filters an enumeration of Product objects but that delegates the decision about which ones are included in the results to a separate function.  public   static   IEnumerable Product   Filter ( \n     this   IEnumerable Product   productEnum , \n     Func Product ,   bool   selector )  { \n     foreach   ( Product   prod   in   productEnum ) \n     { \n         if   ( selector ( prod )) \n         { \n             yield   return   prod ; \n         } \n     }  }   Now, we can use this  Filter  function as follows:  decimal   priceFilterTotal   =   productArray \n     . Filter ( p   =   ( p ?. Price   ??   0 )   =   20 ) \n     . TotalPrices ();  decimal   nameFilterTotal   =   productArray \n     . Filter ( p   =   p ?. Name ?[ 0 ]   ==   S ) \n     . TotalPrices ();   Lambdas  can also be used in class properties, e.g.:  public   bool   NameBeginsWithS   =   Name ?[ 0 ]   ==   S ;", 
            "title": "Lambda anonymous functions"
        }, 
        {
            "location": "/dotnet/notes/#asynchronous-methods", 
            "text": "Add  \"System.Net.Http\": \"4.1.0\"  dependency in  project.json .  Here is how we could make an asynchronous call  the hard way :  public   static   Task long?   GetPageLengthWithoutAsyncAwait ()  { \n     HttpClient   client   =   new   HttpClient (); \n     var   httpTask   =   client . GetAsync ( http://apress.com ); \n     // we could do other things here while the HTTP request is performed \n     return   httpTask . ContinueWith (( Task HttpResponseMessage   antecedent )   = \n     { \n         return   antecedent . Result . Content . Headers . ContentLength ; \n     });  }   And here is the clever way:  public   static   async   Task long?   GetPageLength ()  { \n     HttpClient   client   =   new   HttpClient (); \n     var   httpMessage   =   await   client . GetAsync ( http://apress.com ); \n     // we could do other things here while the HTTP request is performed \n     return   httpMessage . Content . Headers . ContentLength ;  }   And we could use this in our controller:  using   LanguageFeatures.Models ;  using   Microsoft.AspNetCore.Mvc ;  using   System.Threading.Tasks ;  namespace   LanguageFeatures.Controllers  { \n     public   class   HomeController   :   Controller \n     { \n         public   async   Task ViewResult   Index () \n         { \n             long?   length   =   await   MyAsyncMethods . GetPageLength (); \n             return   View ( new   string []   {   $ Length: {length}   }); \n         } \n     }  }", 
            "title": "Asynchronous methods"
        }, 
        {
            "location": "/dotnet/notes/#getting-property-names-with-nameof", 
            "text": "If we use lambdas the classic way:  products . Select ( p   =   $ Name: {p.Name}, Price: {p.Price} )   we of course get no intellisense on  Name:  and  Price: . So, if we change the property name in the class and forget to change these strings here, we get a mismatch.  Fortunately, we can now rewrite the same code like this:  products . Select ( p   =   $ {nameof(p.Name)}: {p.Name}, {nameof(p.Price)}: {p.Price} )   but then we will get intellisense and type safety.", 
            "title": "Getting property names with nameof"
        }, 
        {
            "location": "/dotnet/notes/#workflow-with-an-empty-project", 
            "text": "create a new empty ASP.NET Core project  add  \"Microsoft.AspNetCore.Mvc\": \"1.0.1\"  dependency in  project.json  add  \"System.Net.Http\": \"4.1.0\"  dependency in  project.json  add  Mvc  to  Startup.cs :   using   Microsoft.AspNetCore.Builder ;  using   Microsoft.AspNetCore.Hosting ;  using   Microsoft.Extensions.DependencyInjection ;  using   Microsoft.Extensions.Logging ;  namespace   LanguageFeatures  { \n     public   class   Startup \n     { \n         public   void   ConfigureServices ( IServiceCollection   services ) \n         { \n             services . AddMvc (); \n         } \n\n         public   void   Configure ( IApplicationBuilder   app ,   IHostingEnvironment   env ,   ILoggerFactory   loggerFactory ) \n         { \n             app . UseMvcWithDefaultRoute (); \n         } \n     }  }", 
            "title": "Workflow with an empty project"
        }, 
        {
            "location": "/dotnet/notes/#the-json-configuration-files", 
            "text": "Name  Description      global.json  This file, which is found in the Solution Items folder, is responsible for telling Visual Studio where to find the projects in the solution and which version of the .NET execution environment should be used to run the application.    launchSettings.json  This file, which is revealed by expanding the Properties item in the MVC application project, is used to specify how the application is started.    appsettings.json  This file is used to define application-specific settings.    bower.json  This file is used by Bower to list the client-side packages that are installed into the project.    bundleconfig.json  This file is used to bundle and minify JavaScript and CSS files.    project.json  This file is used to specify the NuGet packages that are installed into the application. This file is also used for other project settings.    project.lock.json  This file, which is revealed by expanding the project.json item in the Solution Explorer, contains detailed dependencies between packages installed in the project. It is generated automatically and should not be edited manually.", 
            "title": "The JSON Configuration Files"
        }, 
        {
            "location": "/dotnet/notes/#razor", 
            "text": "", 
            "title": "Razor"
        }, 
        {
            "location": "/dotnet/notes/#view-imports-file", 
            "text": "Use  _ViewImports.cshtml  file in the  Views  folder to specify the standard include namespaces. Then you can omit them in the individual views.", 
            "title": "View Imports File"
        }, 
        {
            "location": "/dotnet/notes/#view-start-file", 
            "text": "Normally, we have to specify the layout file we want in every view. Therefore, if we need to rename the layout file, we are going to have to find every view that refers to it and make a change, which will be an error-prone process and counter to the general theme of easy maintenance that runs through MVC development.  We can resolve this by using a  view start file . When it renders a view, MVC will look for a file called  _ViewStart.cshtml  and we can put it in the  Views  folder. The contents of this file will be treated as though they were contained in the view file itself, and we can use this feature to automatically set a value for the Layout property.  @ { \n     Layout   =   _BasicLayout ;  }   Now, in the views that should use this  _BasicLayout , we can omit the layout line.  We do not have to specify that we want to use the view start file. MVC will locate the file and use its contents automatically. The values defined in the view file take precedence, which makes it easy to override the view start file.  We can also use  multiple view start files  to set defaults for different parts of the application. Razor looks for the closest view start file to the view that it being processed, which means that you can override the default setting by adding a view start file to the  Views/Home  or  Views/Shared  folders, for example.   Caution  It is important to understand the difference between  omitting the Layout property  from the view file and  setting it to null . If your view is self-contained and you do not want to use a layout, then set the Layout property to null. If you omit the Layout property, then MVC will assume that you do want a layout and that it should use the value it finds in the view start file.", 
            "title": "View Start File"
        }, 
        {
            "location": "/dotnet/notes/#viewbag-property", 
            "text": "The  ViewBag  property returns a  dynamic object  that can be used to define arbitrary properties. Since the  ViewBag  is dynamic, we don\u2019t have to declare the property names in advance, but it does mean that Visual Studio is unable to provide autocomplete suggestions for view bag properties.", 
            "title": "ViewBag property"
        }, 
        {
            "location": "/dotnet/notes/#attribute-values", 
            "text": "We can also use Razor expressions to set the value of  element attributes , not only on the content.  div data-productid= @Model.ProductID  data-stocklevel= @ViewBag.StockLevel \n     p Product Name: @Model.Name /p \n     p Product Price: @($ {Model.Price:C2} ) /p \n     p Stock Level: @ViewBag.StockLevel /p  /div", 
            "title": "Attribute values"
        }, 
        {
            "location": "/dotnet/notes/#switch-statement", 
            "text": "We have to cast the dynamic ViewBag properties to the right type once, inside the condition:  @switch ((int)ViewBag.StockLevel) {...}  After that, inside the body, we dont need to do it any more:  default:\n    @: @ViewBag.StockLevel in Stock\n    break;  We do not have to put the elements or expressions in quotes or denote them in any special way\u2014the Razor engine will interpret these as output to be processed. However, if we want to insert literal text into the view when it is not contained in an HTML element, then we need to give Razor a helping hand and prefix the line with an  @  character (see above).", 
            "title": "Switch statement"
        }, 
        {
            "location": "/dotnet/notes/#visual-studio-tips-and-tricks", 
            "text": "", 
            "title": "Visual Studio tips and tricks"
        }, 
        {
            "location": "/dotnet/notes/#enable-developer-exception-page", 
            "text": "In  Startup.cs  add this line to the  Configure  method:  app . UseDeveloperExceptionPage ();", 
            "title": "Enable Developer Exception Page"
        }, 
        {
            "location": "/dotnet/notes/#browser-link-loader", 
            "text": "Add  Microsoft.VisualStudio.Web.BrowserLink.Loader :   14.0.0   to  project.json  dependencies list. Also add  app . UseBrowserLink ();   to the  Configure  method of  Startup.cs .  Run the project without debugging (Ctrl + F5) and you see this kind of code added to the HTML:  !-- Visual Studio Browser Link --  script   type = application/json   id = __browserLink_initializationData \n     { requestId : 497a61f26544432a857e06ab5d501b7f , requestMappingFromServer : false }  / script  script   type = text/javascript \n         src = http://localhost:2701/029471b4ee954e43adc0d452954d080f/browserLink \n         async = async  / script  !-- End Browser Link --    Alas  I still see no added value to it. :( Unless it is just the synchronized browsing using multiple browsers. I also see this error in the browser console:  [14:07:17 GMT+0200 (West-Europa (zomertijd))] Browser Link: Failed to invoke return value  callback: TypeError: Cannot read property 'files' of null", 
            "title": "Browser Link Loader"
        }, 
        {
            "location": "/dotnet/notes/#static-files", 
            "text": "ASP.NET Core includes support for delivering  static files  from the wwwroot folder to clients but it isn\u2019t enabled by default when the Empty template is used to create the project. To enable static file support, add  Microsoft.AspNetCore.StaticFiles :   1.0.0   to  project.json  dependencies list. Also add  app . UseStaticFiles ();   to the  Configure  method of  Startup.cs .", 
            "title": "Static files"
        }, 
        {
            "location": "/dotnet/notes/#bundling-and-minifying", 
            "text": "Install  Bundler and Minifier  extension for the Visual Studio. After that it is possible to add  css  or  js  files to the bundle by selecting them one by one and choosing  Bundler   Minifier | Bundle and Minify Files (Shift + Alt + F)  from the right mouse button menu.  This will create a  bundle.css  or  bundle.js  file and also  bundleconfig.json  in the project root folder. Make sure the order of the files is what you need as  loading order .", 
            "title": "Bundling and minifying"
        }, 
        {
            "location": "/dotnet/notes/#unit-testing-with-xunit-framework", 
            "text": "", 
            "title": "Unit Testing with xUnit Framework"
        }, 
        {
            "location": "/dotnet/notes/#preparation", 
            "text": "create  test  folder inside the solution folder next to  src  folder  add new  .NET Core | Class Library (.NET Core)  project inside the  test  folder  add this code to its  project.json  file (check the latest versions):      { \n       version :   1.0.0-* , \n       testRunner :   xunit , \n\n       dependencies :   { \n           Microsoft.NETCore.App :   { \n               type :   platform , \n               version :   1.0.1 \n           }, \n           xunit :   2.1.0 , \n           dotnet-test-xunit :   2.2.0-preview2-build1029 \n       }, \n\n       frameworks :   { \n           netcoreapp1.0 :   { \n               imports :   [ dotnet5.6 ,   portable-net45+win8 ] \n           } \n       } \n   }    this configuration tells Visual Studio that three packages are required:  the  Microsoft.NETCore.App  package provides the  .NET Core API .  the  xunit  package provides the testing framework.  the  dotnet-test-xunit  package provides the integration between  xUnit  and  Visual Studio .    add the main project reference to the dependencies, e.g.      { \n       dependencies :   { \n           ... \n           WorkingWithVisualStudio :   1.0.0 \n           ... \n       } \n   }", 
            "title": "Preparation"
        }, 
        {
            "location": "/dotnet/notes/#fact-and-theory", 
            "text": "In the  xUnit  framework, a  Fact  is one single unit test. Example:     [Fact] \n   public   void   IndexActionModelIsComplete ()   { \n       // Arrange \n       var   controller   =   new   HomeController (); \n       controller . Repository   =   new   ModelCompleteFakeRepository (); \n\n       // Act \n       var   model   =   ( controller . Index ()   as   ViewResult )?. ViewData . Model \n       as   IEnumerable Product ; \n\n       // Assert \n       Assert . Equal ( controller . Repository . Products ,   model , \n           Comparer . Get Product (( p1 ,   p2 )   =   p1 . Name   ==   p2 . Name \n                 p1 . Price   ==   p2 . Price )); \n   }    A  Theory  is a way to parametrize the unit test in such a way that it becomes possible to run the same test multiple times, each time with a different set of parameter values. Example:     [Theory]    [InlineData(275, 48.95, 19.50, 24.95)]    [InlineData(5, 48.95, 19.50, 24.95)] \n   public   void   IndexActionModelIsComplete ( decimal   price1 ,   decimal   price2 , \n   decimal   price3 ,   decimal   price4 )   { \n       // Arrange \n       var   controller   =   new   HomeController (); \n       controller . Repository   =   new   ModelCompleteFakeRepository   { \n           Products   =   new   Product []   { \n               new   Product   { Name   =   P1 ,   Price   =   price1   }, \n               new   Product   { Name   =   P2 ,   Price   =   price2   }, \n               new   Product   { Name   =   P3 ,   Price   =   price3   }, \n               new   Product   { Name   =   P4 ,   Price   =   price4   }, \n           } \n       }; \n\n       // Act \n       var   model   =   ( controller . Index ()   as   ViewResult )?. ViewData . Model \n                       as   IEnumerable Product ; \n\n       // Assert \n       Assert . Equal ( controller . Repository . Products ,   model , \n           Comparer . Get Product (( p1 ,   p2 )   =   p1 . Name   ==   p2 . Name \n                 p1 . Price   ==   p2 . Price )); \n   }", 
            "title": "Fact and Theory"
        }, 
        {
            "location": "/dotnet/notes/#getting-test-data-from-a-method-or-property", 
            "text": "We can create methods or properties giving us the enumerations for the test parameter values in a separate class, e.g.  ProductTestData.cs . Then we can use  MemberData  attribute to specify it for the unit test to use. Example:  [Theory]  [ClassData(typeof(ProductTestData))]  public   void   IndexActionModelIsComplete ( Product []   products   )   {...}   If we want to include the test data in the same class as the unit tests, then you can use the  MemberData  attribute instead of  ClassData . The  MemberData  attribute is configured using a string that specifies the name of a static method that will provide an  IEnumerable object[] , where each object array in the sequence is a set of arguments for the test method. Example:  [Theory]  [MemberData( GetData )]  public   void   IndexActionModelIsComplete ( Product []   products   )   {...}   and the  GetData  should look something like this  public   static   IEnumerable object []   GetData  { \n     get \n     { \n         // ... \n         yield   return   new   object []   {   8 ,   21   }; \n         yield   return   new   object []   {   16 ,   987   }; \n     }  }   Every  yield  statement should return an array of objects to substitute for the Product properties. And the method itself should be of type  IEnumerable object[] .", 
            "title": "Getting Test Data from a Method or Property"
        }, 
        {
            "location": "/dotnet/notes/#mocking-with-moq", 
            "text": "Microsoft  created a special fork of the  Moq  project and ported it to work with  .NET Core .  In order to be able to install the  Moq NuGet package , we need first to configure the  NuGet Options . Open  Tools | Options | NuGet Package Manager , click on  Package Sources  and then on the green plus sign. Configure the new package source as follows:   Name: ASP.NET Contrib  Source: https://www.myget.org/F/aspnet-contrib/api/v3/index.json   Add these two packages to the  package.json  in the test project:  moq.netcore :   4.4.0-beta8  System.Diagnostics.TraceSource :   4.0.0   Usage example:  [Fact]  public   void   RepositoryPropertyCalledOnce ()  { \n     // Arrange \n     var   mock   =   new   Mock IRepository (); \n     mock . SetupGet ( m   =   m . Products ) \n         . Returns ( new []   {   new   Product   {   Name   =   P1 ,   Price   =   100   }   }); \n     var   controller   =   new   HomeController   {   Repository   =   mock . Object   }; \n\n     // Act \n     var   result   =   controller . Index (); \n\n     // Assert \n     mock . VerifyGet ( m   =   m . Products ,   Times . Once );  }   Explanation:   var mock = new Mock IRepository ();  - define the interface to be mocked  SetupGet(m =  m.Products)  - specify the property to be tested  .Returns(...)  - specify the test value to be returned  Repository = mock.Object  -  Object  is the special property that gives back the object we mock for this test  mock.VerifyGet(m =  m.Products, Times.Once);  - one of the verify methods to inspect the getter property", 
            "title": "Mocking with MOQ"
        }, 
        {
            "location": "/dotnet/notes/#sportsstore", 
            "text": "Create a new empty  ASP.NET Core Web Application (.NET Core)  project/solution.  Add these packages/tools to the  project.json  file:      dependencies :   { \n       ... \n       Microsoft.AspNetCore.Razor.Tools :   { \n           version :   1.0.0-preview2-final , \n           type :   build \n       }, \n       Microsoft.AspNetCore.StaticFiles :   1.0.0 , \n       Microsoft.AspNetCore.Mvc :   1.0.1 \n   } , \n   tools :   { \n       Microsoft.AspNetCore.Razor.Tools :   1.0.0-preview2-final , \n       ... \n   } ,    In addition to the packages in the  dependencies  section, there is an addition to the  tools  section of the  project.json  file that configures the  Microsoft.AspNetCore.Razor.Tools  package for use in Visual Studio and enables IntelliSense for the built-in tag helpers, which are used to create HTML content that is tailored to the configuration of the MVC application.  Here is the  Startup.cs :      using   Microsoft.AspNetCore.Builder ; \n   using   Microsoft.AspNetCore.Hosting ; \n   using   Microsoft.AspNetCore.Http ; \n   using   Microsoft.Extensions.DependencyInjection ; \n   using   Microsoft.Extensions.Logging ; \n\n   namespace   SportsStore \n   { \n       public   class   Startup \n       { \n           public   void   ConfigureServices ( IServiceCollection   services ) \n           { \n               services . AddMvc (); \n           } \n\n           public   void   Configure ( IApplicationBuilder   app , \n           IHostingEnvironment   env ,   ILoggerFactory   loggerFactory ) \n           { \n               app . UseDeveloperExceptionPage (); \n               app . UseStatusCodePages (); \n               app . UseStaticFiles (); \n               app . UseMvcWithDefaultRoute (); \n           } \n       } \n   }    The  ConfigureServices  method is used to set up shared objects that can be used throughout the application through the  dependency injection  feature. The  AddMvc  method that is called in the  ConfigureServices  method is an extension method that sets up the shared objects used in MVC applications.  The  Configure  method is used to set up the features that receive and process  HTTP requests .  add these folders:  Models ,  Controllers ,  Views  in the  Views  folder add  _ViewImports.cshtml  file:      @using   SportsStore . Models \n   @addTagHelper   *,   Microsoft . AspNetCore . Mvc . TagHelpers    create the unit test project  SportsStore.Tests  in the  test  folder.  Configure its  project .json  as follows:      { \n       version :   1.0.0-* , \n       testRunner :   xunit , \n       dependencies :   { \n           Microsoft.NETCore.App :   { \n               type :   platform , \n               version :   1.0.1 \n           }, \n           xunit :   2.1.0 , \n           dotnet-test-xunit :   2.2.0-preview2-build1029 , \n           moq.netcore :   4.4.0-beta8 , \n           System.Diagnostics.TraceSource :   4.0.0 , \n           SportsStore :   1.0.0 \n       }, \n       frameworks :   { \n           netcoreapp1.0 :   { \n               imports :   [   dotnet5.6 ,   portable-net45+win8   ] \n           } \n       } \n   }    Make sure that both  project.json  files refer to the same  ASP.NET Core MVC  version.  Add your model class  Product.cs , repository interface  IProductRepository  and a simple fake repository  FakeProductRepository  Register the fake repository as a service in  Startup.cs :      public   void   ConfigureServices ( IServiceCollection   services ) \n   { \n       services . AddTransient IProductRepository ,   FakeProductRepository (); \n       ... \n   }    Add the following standard views:  Views/Shared/_Layout.cshtml  Views/_ViewStart.cshtml  refering to  _Layout.cshtml  by default  Example of setting up the default route in  Startup.cs . Substitute      app . UseMvcWithDefaultRoute ();    with      app . UseMvc ( routes   = \n   { \n       routes . MapRoute ( \n           name :   default , \n           template :   {controller=Product}/{action=List}/{id?} ); \n   });", 
            "title": "SportsStore"
        }, 
        {
            "location": "/dotnet/notes/#scaffolding", 
            "text": "Some people prefer to have certain features automatically created when they create new controller or views. That is called  scaffolding . If you want that, add the following packages to the  project.json  file:  ...  dependencies :   { \n     ... \n     Microsoft.AspNetCore.StaticFiles :   1.0.0 , \n     Microsoft.AspNetCore.Mvc :   1.0.0 , \n     Microsoft.VisualStudio.Web.CodeGeneration.Tools :   { \n         version :   1.0.0-preview2-final , \n         type :   build \n     }, \n     Microsoft.VisualStudio.Web.CodeGenerators.Mvc :   { \n         version :   1.0.0-preview2-final , \n         type :   build \n     }  }  ...  tools :   { \n     ... \n     Microsoft.VisualStudio.Web.CodeGeneration.Tools :   { \n         version :   1.0.0-preview2-final , \n         imports :   [ \n             portable-net45+win8+dnxcore50 , \n             portable-net45+win8 \n         ] \n     }  }  ...", 
            "title": "Scaffolding"
        }, 
        {
            "location": "/dotnet/notes/#setup-the-database", 
            "text": "add  EntityFramework  packages to  package.json :      dependencies :   { \n       ... \n       Microsoft.EntityFrameworkCore.SqlServer :   1.0.1 , \n       Microsoft.EntityFrameworkCore.Tools :   1.0.0-preview2-final \n   }    and the tools:      tools :   { \n       ... \n       Microsoft.EntityFrameworkCore.Tools :   { \n           version :   1.0.0-preview2-final , \n           imports :   [   portable-net45+win8+dnxcore50 ,   portable-net45+win8   ] \n       } \n   }    The  database context class  is the bridge between the  application  and the  EF Core  and provides access to the application\u2019s data using model objects. To create the database context class for the  SportsStore  application, we add a class file called  ApplicationDbContext.cs  to the  Models  folder:      using   Microsoft.EntityFrameworkCore ; \n\n   namespace   SportsStore.Models \n   { \n       public   class   ApplicationDbContext   :   DbContext \n       { \n           public   ApplicationDbContext ( DbContextOptions ApplicationDbContext   options ) \n               :   base ( options )   {   } \n           public   DbSet Product   Products   {   get ;   set ;   } \n       } \n   }    To populate the database initially with some data, we use  SeedData.cs  class:      using   System.Linq ; \n   using   Microsoft.AspNetCore.Builder ; \n   using   Microsoft.Extensions.DependencyInjection ; \n   namespace   SportsStore.Models \n   { \n       public   static   class   SeedData \n       { \n           public   static   void   EnsurePopulated ( IApplicationBuilder   app ) \n           { \n               ApplicationDbContext   context   = \n                   app . ApplicationServices . GetRequiredService ApplicationDbContext (); \n\n               if   (! context . Products . Any ()) \n               { \n                   context . Products . AddRange ( \n                   new   Product \n                   { \n                       Name   =   Kayak , \n                       Description   =   A boat for one person , \n                       Category   =   Watersports , \n                       Price   =   275 \n                   }, \n                   ... \n\n                   context . SaveChanges (); \n               } \n           } \n       } \n   }    The static  EnsurePopulated  method receives an  IApplicationBuilder  argument, which is the class used in the  Configure  method of the  Startup  class to register middleware classes to handle HTTP requests, which is where we ensure that the database has content.  The  EnsurePopulated  method obtains an  ApplicationDbContext  object through the  IApplicationBuilder  interface and uses it to check whether there are any  Product  objects in the database. If there are no objects, then the database is populated using a collection of  Product  objects using the  AddRange  method and then written to the database using the  SaveChanges  method.  The next step is to create a class that implements the  IProductRepository  interface and gets its data using  Entity Framework Core  from the  ApplicationDbContext .      using   System.Collections.Generic ; \n\n   namespace   SportsStore.Models \n   { \n       public   class   EFProductRepository   :   IProductRepository \n       { \n           private   ApplicationDbContext   context ; \n           public   EFProductRepository ( ApplicationDbContext   ctx ) \n           { \n               context   =   ctx ; \n           } \n           public   IEnumerable Product   Products   =   context . Products ; \n       } \n   }    create  appsettings.json  file in the project root folder based on the  ASP.NET Configuration File  template and configure the connection string:      { \n       Data :   { \n           SportStoreProducts :   { \n               ConnectionString :   Server=(localdb)\\\\MSSQLLocalDB;Database=SportsStore;Trusted_Connection=True;MultipleActiveResultSets=true \n           } \n       } \n   }    add a new dependency to read the  json  configuration file:      dependencies :   { \n       ... \n       Microsoft.Extensions.Configuration.Json :   1.0.0 \n   } ,    configure the  Startup.cs :      ... \n   using   Microsoft.EntityFrameworkCore ; \n   using   Microsoft.Extensions.Configuration ; \n\n   namespace   SportsStore \n   { \n       public   class   Startup \n       { \n           IConfigurationRoot   Configuration ; \n\n           public   Startup ( IHostingEnvironment   env ) \n           { \n               Configuration   =   new   ConfigurationBuilder () \n                   . SetBasePath ( env . ContentRootPath ) \n                   . AddJsonFile ( appsettings.json ). Build (); \n           } \n\n           public   void   ConfigureServices ( IServiceCollection   services ) \n           { \n               services . AddDbContext ApplicationDbContext ( options   = \n                   options . UseSqlServer ( Configuration [ Data:SportStoreProducts:ConnectionString ])); \n               services . AddTransient IProductRepository ,   EFProductRepository (); \n               ... \n           } \n\n           public   void   Configure ( \n               IApplicationBuilder   app , \n               IHostingEnvironment   env , \n               ILoggerFactory   loggerFactory ) \n           { \n               ... \n               SeedData . EnsurePopulated ( app ); \n           } \n       } \n   }    open  Tools | Nuget Package Manager | Package Manager Console  to create and apply database migrations:     Add-Migration Initial\n  Update-Database   rebuild the solution and run - we will see the list of products loaded from the database.", 
            "title": "Setup the database"
        }, 
        {
            "location": "/dotnet/notes/#viewmodels-and-taghelpers", 
            "text": "If we want to customize the information to be used in the view, we can do that with  ViewModels . For that we create a  ViewModels  subfolder inside the  Models  folder. They can  be registered  in  _ViewImports.cshtml .  TagHelpers  are one of the most useful ways that you can introduce C# logic into your views. The code for a tag helper can look tortured because C# and HTML don\u2019t mix easily. But using tag helpers is preferable to including blocks of C# code in a view because a tag helper can be easily  unit tested . Most MVC components, such as controllers and views, are discovered automatically, but tag helpers  have to be registered  in  _ViewImports.cshtml .  To test the  tag helper  class, I call the  Process  method with test data and provide a  TagHelperOutput  object that is inspected to see the HTML that was generated.  When we pass the data to the view via a view model, we need to replace the type. E.g. it can become  @model ProductsListViewModel  and  Model.Products  instead of  @model IEnumerable Product  and  Model .", 
            "title": "ViewModels and TagHelpers"
        }, 
        {
            "location": "/dotnet/notes/#installing-bootstrap-package", 
            "text": "Add  bower.json  file to the project root:  { \n     name :   asp.net , \n     private :   true , \n     dependencies :   { \n         bootstrap :   3.3.7 \n     }  }   This will add  wwwroot/lib  folder and inside it  bootstrap  and  jquery  sources.", 
            "title": "Installing Bootstrap package"
        }, 
        {
            "location": "/dotnet/notes/#improving-the-urls", 
            "text": "Normally, the page links look like this:  http://localhost/?page=2  But we can make them more user friendly by creating a scheme that follows the pattern of  composable URLs , which look like this:  http://localhost/Page2  To do that we register a new route in our MVC middleware ( Configure  method in  Startup.cs ):  routes . MapRoute ( \n     name :   pagination , \n     template :   Products/Page{page} , \n     defaults :   new   {   Controller   =   Product ,   action   =   List   });   It is important that this route is added  before  the default route.", 
            "title": "Improving the URLs"
        }, 
        {
            "location": "/dotnet/notes/#enabling-sessions", 
            "text": "Add these new packages to the  package.json :  Microsoft.AspNetCore.Session :   1.0.0 ,  Microsoft.Extensions.Caching.Memory :   1.0.0 ,  Microsoft.AspNetCore.Http.Extensions :   1.0.0   Register new services and middleware to the  Startup.cs :  public   void   ConfigureServices ( IServiceCollection   services )   { \n     ... \n     services . AddMemoryCache (); \n     services . AddSession (); \n     services . AddMvc ();  }  public   void   Configure ( IApplicationBuilder   app , \n     ... \n     app . UseSession (); \n     app . UseMvc (...);  }    AddMemoryCache  The  AddMemoryCache  method call sets up the in-memory data store. The  AddSession  method registers the services used to access session data, and the  UseSession  method allows the session system to automatically associate requests with sessions when they arrive from the client.", 
            "title": "Enabling Sessions"
        }, 
        {
            "location": "/dotnet/notes/#annotations", 
            "text": "BindNever  attribute prevents the user supplying values for these properties in an HTTP request.", 
            "title": "Annotations"
        }, 
        {
            "location": "/dotnet/notes/#adding-migrations", 
            "text": "Suppose we add a new  DbSet  to our  ApplicationDbContext.cs :  public   class   ApplicationDbContext   :   DbContext  { \n     public   ApplicationDbContext ( DbContextOptions ApplicationDbContext   options ) \n         :   base ( options )   {   } \n     ... \n     public   DbSet Order   Orders   {   get ;   set ;   }  }   To create the  migration , open the NuGet  Package Manger Console  from the  Tools \u27a4 NuGet Package Manage  menu and run the following command :  Add-Migration Orders  This command tells EF Core to take a new snapshot of the application, work out how it differs from the previous database version, and generate a new migration called  Orders . The name  Orders  here is arbitrary but it is handy to let it reflect the change.  To update the database schema, run the following command:  Update-Database", 
            "title": "Adding migrations"
        }, 
        {
            "location": "/dotnet/notes/#resetting-the-database", 
            "text": "When you are making frequent changes to the model, there will come a point when your migrations and your database schema get out of sync. The easiest thing to do is delete the database and start over. However, this applies  only during development , of course, because you will lose any data you have stored.   Select the  SQL Server Object Explorer  item from the Visual Studio  View  menu and click the  Add Sql Server  button.  Enter  (localdb)\\mssqllocaldb  into the  Server Name  field and click the  Connect  button. A new item will appear in the  SQL Server Object Explorer  window, which you can expand to see the  LocalDB  databases that have been created.  Right-click the database you want to remove and select  Delete  from the pop-up menu.  Check the option to close the existing connections  and then click the  OK  button to delete the database.  Once the database has been removed, run the following command from the  Package Manager Console  to create the database and apply the migrations you have created by running the following command:   Update-Database   This will reset the database so that it accurately reflects your model and allow you to return to developing your application.", 
            "title": "Resetting the Database"
        }, 
        {
            "location": "/dotnet/notes/#using-tempdata", 
            "text": "We are using TempData in the POST method in a controller:  [HttpPost]  public   IActionResult   Edit ( Product   product )  { \n     if   ( ModelState . IsValid ) \n     { \n         _repository . SaveProduct ( product ); \n         TempData [ message ]   =   $ {product.Name} has been saved ; \n         return   RedirectToAction ( Index ); \n     } \n     else \n     { \n         // there is something wrong with the data values \n         return   View ( product ); \n     }  }   We check that the model binding process has been able to validate the data submitted to the user by reading the value of the  ModelState.IsValid  property. If everything is OK, we save the changes to the repository and redirect the user to the  Index  action so they see the modified list of products. If there is a problem with the data, we render the default view again so that the user can make corrections.  After we have saved the changes in the repository, we store a message using the  TempData  feature, which is part of the  ASP.NET Core session state  feature. This is a  key/value  dictionary similar to the  session data  and  view bag  features we used previously.  The key difference from  session data  is that  temp data  persists until it is read. We cannot use  ViewBag  in this situation because  ViewBag  passes data between the  controller  and  view , and it cannot hold data for longer than  the current HTTP request . When an edit succeeds, the browser is redirected to a new URL, so the  ViewBag  data is lost.  We could use the  session data  feature, but then the message would be persistent until we explicitly removed it, which we would rather not have to do.  So, the  temp data  feature is the perfect fit. The data is restricted to a  single user\u2019s session  (so that users do not see each other\u2019s  TempData ) and will persist long enough for us to read it. We will read the data in the  view  rendered by the  action method  to which we redirect the user  The message will be displayed once and disappear if you reload the screen with the template using this  temp data , because  TempData  is deleted when it is read. That is convenient since we do not want old messages hanging around.", 
            "title": "Using TempData"
        }, 
        {
            "location": "/dotnet/notes/#localization-hell", 
            "text": "By the time we get to editing with validation, something bad happens. It looks that by default the  jQuery-validation  (client side validation) expects  \"en-US\"  as its culture and the server side validation expects  \"nl-NL\" . Therefore, when I see  \u20ac  as currency and  \",\"  as decimal separator, I cannot change the price. Neither  \",\"  nor  \".\"  are accepted. One is rejected by the client side and the other by the server side validation.  Temporary workaround was to configure  \"en-US\"  as the default culture, so that  \"$\"  and  \".\"  are displayed on the screen. Then the validation works.", 
            "title": "Localization hell"
        }, 
        {
            "location": "/dotnet/notes/#adding-identity", 
            "text": "Add a new dependency to  project.json :  dependencies :   { \n     ... \n     Microsoft.AspNetCore.Identity.EntityFrameworkCore :   1.0.0  }   Add a new  AppIdentityDbContext  class to  Models  folder:  using   Microsoft.AspNetCore.Identity.EntityFrameworkCore ;  using   Microsoft.EntityFrameworkCore ;  namespace   SportsStore.Models  { \n     public   class   AppIdentityDbContext   :   IdentityDbContext IdentityUser \n     { \n         public   AppIdentityDbContext ( DbContextOptions AppIdentityDbContext   options ) \n             :   base ( options )   {   } \n     }  }   and a new connection string in  appsettings.json  file:  { \n     Data :   { \n         ... \n         SportStoreIdentity :   { \n             ConnectionString :   Server=(localdb)\\\\MSSQLLocalDB;Database=Identity;Trusted_Connection=True;MultipleActiveResultSets=true \n         } \n     }  }   Add new services to  ConfigureServices  in  Startup.cs :  public   void   ConfigureServices ( IServiceCollection   services )  { \n     ... \n     services . AddDbContext AppIdentityDbContext ( options   = \n         options . UseSqlServer ( Configuration [ Data:SportStoreIdentity:ConnectionString ])); \n\n     services . AddIdentity IdentityUser ,   IdentityRole () \n         . AddEntityFrameworkStores AppIdentityDbContext (); \n     ...  }   and new entries in  Configure :  public   void   Configure () \n     app . UseIdentity (); \n     app . UseMvc (); \n     SeedData . EnsurePopulated ( app ); \n     IdentitySeedData . EnsurePopulated ( app );  }   IdentitySeedData  should be created in the  Models  folder to create an administrative account.  using   Microsoft.AspNetCore.Builder ;  using   Microsoft.AspNetCore.Identity ;  using   Microsoft.AspNetCore.Identity.EntityFrameworkCore ;  using   Microsoft.Extensions.DependencyInjection ;  namespace   SportsStore.Models  { \n     public   static   class   IdentitySeedData \n     { \n         private   const   string   adminUser   =   Admin ; \n         private   const   string   adminPassword   =   Secret123$ ; \n\n         public   static   async   void   EnsurePopulated ( IApplicationBuilder   app ) \n         { \n             UserManager IdentityUser   userManager   =   app . ApplicationServices \n                 . GetRequiredService UserManager IdentityUser (); \n\n             IdentityUser   user   =   await   userManager . FindByIdAsync ( adminUser ); \n\n             if   ( user   ==   null ) \n             { \n                 user   =   new   IdentityUser ( Admin ); \n                 await   userManager . CreateAsync ( user ,   adminPassword ); \n             } \n         } \n     }  }", 
            "title": "Adding Identity"
        }, 
        {
            "location": "/dotnet/notes/#adding-identity-migrations", 
            "text": "Add-Migration Initial -Context AppIdentityDbContext  Update-Database -Context AppIdentityDbContext   This will create the new database and add the  AspNetUsers  and  AspNetRoles  in it.", 
            "title": "Adding Identity migrations"
        }, 
        {
            "location": "/dotnet/notes/#adding-authorization", 
            "text": "When  ASP.NET Core Identity  is in place, we can apply  Authorization . We don\u2019t want to stop unauthenticated users from accessing the other action methods in the  Order  controller, so we have applied the  Authorize  attribute only to the  List  and  MarkShipped  methods.  [Authorize]  public   ViewResult   List ()   = \n     View ( _repository . Orders . Where ( o   =   ! o . Shipped ));  [HttpPost]  [Authorize]  public   IActionResult   MarkShipped ( int   orderID )   {...}   We want to protect  all of the action methods  defined by the  Admin  controller, and we can do this by applying the  Authorize attribute to the controller class, which then applies the authorization policy to all the action methods it contains.  [Authorize]  public   class   AdminController   :   Controller  {...}    Caution  In general, using client-side data validation is a good idea. It offloads some of the work from your server and gives users immediate feedback about the data they are providing. However, you should not be tempted to perform authentication at the client, as this would typically involve sending valid credentials to the client so they can be used to check the username and password that the user has entered, or at least trusting the client\u2019s report of whether they have successfully authenticated. Authentication should always be done at the server.", 
            "title": "Adding Authorization"
        }, 
        {
            "location": "/dotnet/notes/#sources-used", 
            "text": "Adam Freeman - Pro ASP.NET Core MVC (2016)  Christian Nagel - Professional C# 6 and .NET Core 1.0 (2016)", 
            "title": "Sources used"
        }, 
        {
            "location": "/dotnet/tips/", 
            "text": ".NET Core Tips\n#\n\n\n\n\n\n\n.NET Core Tips\n\n\nDotnet Command Prompt\n\n\nDotnet NuGet Packages\n\n\nSome Definitions\n\n\nSome Facts\n\n\n\n\n\n\n\n\n\n\n\n\nDotnet Command Prompt\n#\n\n\nRun the web application on a specified port, e.g. 10000, via\n\n\ndotnet run --server.urls http://127.0.0.1:10000\n\n\n\n\n\n\n\nDotnet NuGet Packages\n#\n\n\nUsing command \ndotnet pack\n we can actually create a \nNuGet\n package from our project. This command will create two files in \nbin/debug/[runtime]\n directory:\n\n\n\n\nDNXConsoleDemo.1.0.0.nupkg\n\n\nDNXConsoleDemo.1.0.0.symbols.nupkg\n\n\n\n\nActually, the \n.nupkg\n files are just \n.zip\n files. If you rename the extension, you can see what is inside the package.\n\n\n\n\nApplication as a NuGet package\n\n\nIt should now be possible to install your project as a NuGet package.\n\n\n\n\n\n\nSome Definitions\n#\n\n\nASP.NET Services\n = objects that provide functionality to other parts of the application. Services registered in the \nStartup.ConfigureServices\n method can be accessed by creating a constructor that accepts an argument of the required service type.\n\n\nConfigureServices\n method hooks into the service registry all of the services we want our application to make use of. It is configuring the types of services that can be used in the infrastructur altogether.\n\n\nConfigure\n methods configures the behavior of the registered services.\n\n\nMiddleware\n = components that are combined to form the \nrequest pipeline\n.\n\n\nAddTransient\n = every time we call for the service to be used, we would get a new instance of the service from the \nDI Framework\n.\n\n\nAddScoped\n = same instance of the service is used in all stages of the middleware pipeline for the same request.\n\n\nAddSingleton\n = one instance of the service is created for the entire lifetime of the application across all user requests.\n\n\nAddInstance\n = similar to AddSingleton but we need to new up the instance of this service explicitly.\n\n\n\n\nSome Facts\n#\n\n\n\n\nJSON schema of the \nproject.json\n file: \njson.schemastore.org/project\n\n\nIt is possible to use more that one \nStartup\n class, e.g. \nStartup\n, \nStartupFoo\n, \nStartupBar\n, and to specify the one we need to be activated in the \nProgram.cs\n:\n\n\n\n\n  \npublic\n \nstatic\n \nvoid\n \nMain\n(\nstring\n[]\n \nargs\n)\n\n  \n{\n\n      \nvar\n \nhost\n \n=\n \nnew\n \nWebHostBuilder\n()\n\n          \n...\n\n          \n.\nUseStartup\nStartup\n()\n\n          \n...\n\n  \n}", 
            "title": "Tips"
        }, 
        {
            "location": "/dotnet/tips/#net-core-tips", 
            "text": ".NET Core Tips  Dotnet Command Prompt  Dotnet NuGet Packages  Some Definitions  Some Facts", 
            "title": ".NET Core Tips"
        }, 
        {
            "location": "/dotnet/tips/#dotnet-command-prompt", 
            "text": "Run the web application on a specified port, e.g. 10000, via  dotnet run --server.urls http://127.0.0.1:10000", 
            "title": "Dotnet Command Prompt"
        }, 
        {
            "location": "/dotnet/tips/#dotnet-nuget-packages", 
            "text": "Using command  dotnet pack  we can actually create a  NuGet  package from our project. This command will create two files in  bin/debug/[runtime]  directory:   DNXConsoleDemo.1.0.0.nupkg  DNXConsoleDemo.1.0.0.symbols.nupkg   Actually, the  .nupkg  files are just  .zip  files. If you rename the extension, you can see what is inside the package.   Application as a NuGet package  It should now be possible to install your project as a NuGet package.", 
            "title": "Dotnet NuGet Packages"
        }, 
        {
            "location": "/dotnet/tips/#some-definitions", 
            "text": "ASP.NET Services  = objects that provide functionality to other parts of the application. Services registered in the  Startup.ConfigureServices  method can be accessed by creating a constructor that accepts an argument of the required service type.  ConfigureServices  method hooks into the service registry all of the services we want our application to make use of. It is configuring the types of services that can be used in the infrastructur altogether.  Configure  methods configures the behavior of the registered services.  Middleware  = components that are combined to form the  request pipeline .  AddTransient  = every time we call for the service to be used, we would get a new instance of the service from the  DI Framework .  AddScoped  = same instance of the service is used in all stages of the middleware pipeline for the same request.  AddSingleton  = one instance of the service is created for the entire lifetime of the application across all user requests.  AddInstance  = similar to AddSingleton but we need to new up the instance of this service explicitly.", 
            "title": "Some Definitions"
        }, 
        {
            "location": "/dotnet/tips/#some-facts", 
            "text": "JSON schema of the  project.json  file:  json.schemastore.org/project  It is possible to use more that one  Startup  class, e.g.  Startup ,  StartupFoo ,  StartupBar , and to specify the one we need to be activated in the  Program.cs :      public   static   void   Main ( string []   args ) \n   { \n       var   host   =   new   WebHostBuilder () \n           ... \n           . UseStartup Startup () \n           ... \n   }", 
            "title": "Some Facts"
        }, 
        {
            "location": "/git/gitflow/", 
            "text": "GitFlow, a Git Workflow Extension\n#\n\n\n\n\n\n\nGitFlow, a Git Workflow Extension\n\n\nIntroduction\n\n\nInstallation\n\n\nPrerequisites\n\n\nPrepare the GitFlow local repository\n\n\nInstall GitFlow\n\n\nTest GitFlow installation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction\n#\n\n\n\n\n\n\nInstallation\n#\n\n\nPrerequisites\n#\n\n\nMake sure you have \nGit\n installed. Note the path to the \nGit\n directory. In this manual, we will use \nC:\\Program Files\\Git\n.\n\n\nPrepare the GitFlow local repository\n#\n\n\n\n\nExternal dependencies\n\n\n\n\nSubmodule dependency on \nshFlags\n\n\n3 files from the \nutil-linux-package\n\n\n\n\n\n\nGo to the \nutil-linux-ng for Windows\n website. Download the \nBinaries\n and \nDependencies\n in zip-format. Retrieve \ngetopt.exe\n file from the \nbin\n folder in the \nBinaries\n. Retrieve \nlibintl3.dll\n, and \nlibiconv2.dll\n from the \nbin\n folder in the \nDependencies\n packages. (This \nlink\n has them all in one place.)\n\n\nCopy all three files to the \nbin\n folder of your \nGit\n installation, e.g. \nC:\\Program Files\\Git\\bin\n.\n\n\nOpen an Administrator command window and run these commands (make sure you also get the right diagnostic messages):\n\n\ngit clone https://github.com/nvie/gitflow.git\n\n\ncd\n gitflow\n\ngit submodule\n-2fb06af13de884e9680f14a00c82e52a67c867f1 shFlags\n\ngit submodule init\nSubmodule \nshFlags\n \n(\ngit://github.com/nvie/shFlags.git\n)\n registered \nfor\n path \nshFlags\n\n\ngit submodule update\nCloning into \nshFlags\n...\nremote: Counting objects: \n454\n, \ndone\n.\nremote: Compressing objects: \n100\n% \n(\n55\n/55\n)\n, \ndone\n.\nremote: Total \n454\n \n(\ndelta \n389\n)\n, reused \n454\n \n(\ndelta \n389\n)\n\nReceiving objects: \n100\n% \n(\n454\n/454\n)\n, \n101\n.19 KiB, \ndone\n.\nResolving deltas: \n100\n% \n(\n389\n/389\n)\n, \ndone\n.\nSubmodule path \nshFlags\n: checked out \n2fb06af13de884e9680f14a00c82e52a67c867f1\n\n\ngit submodule status\n 2fb06af13de884e9680f14a00c82e52a67c867f1 shFlags \n(\n1\n.0.3\n)\n\n\n\n\n\n\nInstall GitFlow\n#\n\n\nRun the following commands with the correct path to your \nGit\n installation:\n\n\ncd\n contrib\nmsysgit-install.cmd \nC:\\Program Files\\Git\n\n\n\n\n\n\nTest GitFlow installation\n#\n\n\nTest the installation by running\n\n\ngit flow \nhelp\n\n\n\n\n\n\nYou should see something like this:\n\n\nusage: git flow \nsubcommand\n\n\nAvailable subcommands are:\n   init      Initialize a new git repo with support for the branching model.\n   feature   Manage your feature branches.\n   bugfix    Manage your bugfix branches.\n   release   Manage your release branches.\n   hotfix    Manage your hotfix branches.\n   support   Manage your support branches.\n   version   Shows version information.\n   config    Manage your git-flow configuration.\n   log       Show log deviating from base branch.\n\nTry \ngit flow \nsubcommand\n help\n for details.", 
            "title": "GitFlow"
        }, 
        {
            "location": "/git/gitflow/#gitflow-a-git-workflow-extension", 
            "text": "GitFlow, a Git Workflow Extension  Introduction  Installation  Prerequisites  Prepare the GitFlow local repository  Install GitFlow  Test GitFlow installation", 
            "title": "GitFlow, a Git Workflow Extension"
        }, 
        {
            "location": "/git/gitflow/#introduction", 
            "text": "", 
            "title": "Introduction"
        }, 
        {
            "location": "/git/gitflow/#installation", 
            "text": "", 
            "title": "Installation"
        }, 
        {
            "location": "/git/gitflow/#prerequisites", 
            "text": "Make sure you have  Git  installed. Note the path to the  Git  directory. In this manual, we will use  C:\\Program Files\\Git .", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/git/gitflow/#prepare-the-gitflow-local-repository", 
            "text": "External dependencies   Submodule dependency on  shFlags  3 files from the  util-linux-package    Go to the  util-linux-ng for Windows  website. Download the  Binaries  and  Dependencies  in zip-format. Retrieve  getopt.exe  file from the  bin  folder in the  Binaries . Retrieve  libintl3.dll , and  libiconv2.dll  from the  bin  folder in the  Dependencies  packages. (This  link  has them all in one place.)  Copy all three files to the  bin  folder of your  Git  installation, e.g.  C:\\Program Files\\Git\\bin .  Open an Administrator command window and run these commands (make sure you also get the right diagnostic messages):  git clone https://github.com/nvie/gitflow.git cd  gitflow\n\ngit submodule\n-2fb06af13de884e9680f14a00c82e52a67c867f1 shFlags\n\ngit submodule init\nSubmodule  shFlags   ( git://github.com/nvie/shFlags.git )  registered  for  path  shFlags \n\ngit submodule update\nCloning into  shFlags ...\nremote: Counting objects:  454 ,  done .\nremote: Compressing objects:  100 %  ( 55 /55 ) ,  done .\nremote: Total  454   ( delta  389 ) , reused  454   ( delta  389 ) \nReceiving objects:  100 %  ( 454 /454 ) ,  101 .19 KiB,  done .\nResolving deltas:  100 %  ( 389 /389 ) ,  done .\nSubmodule path  shFlags : checked out  2fb06af13de884e9680f14a00c82e52a67c867f1 \n\ngit submodule status\n 2fb06af13de884e9680f14a00c82e52a67c867f1 shFlags  ( 1 .0.3 )", 
            "title": "Prepare the GitFlow local repository"
        }, 
        {
            "location": "/git/gitflow/#install-gitflow", 
            "text": "Run the following commands with the correct path to your  Git  installation:  cd  contrib\nmsysgit-install.cmd  C:\\Program Files\\Git", 
            "title": "Install GitFlow"
        }, 
        {
            "location": "/git/gitflow/#test-gitflow-installation", 
            "text": "Test the installation by running  git flow  help   You should see something like this:  usage: git flow  subcommand \n\nAvailable subcommands are:\n   init      Initialize a new git repo with support for the branching model.\n   feature   Manage your feature branches.\n   bugfix    Manage your bugfix branches.\n   release   Manage your release branches.\n   hotfix    Manage your hotfix branches.\n   support   Manage your support branches.\n   version   Shows version information.\n   config    Manage your git-flow configuration.\n   log       Show log deviating from base branch.\n\nTry  git flow  subcommand  help  for details.", 
            "title": "Test GitFlow installation"
        }, 
        {
            "location": "/git/tools/", 
            "text": "Git Command Line Tools\n#\n\n\n\n\n\n\nGit Command Line Tools\n\n\nConEmu\n\n\nShow Branch Name on Command Line\n\n\nAdd ConEmu to the Windows context menu\n\n\n\n\n\n\nCmder\n\n\nEnvironment variables\n\n\nShortcut to open Cmder in a chosen folder\n\n\nConfiguring Tasks\n\n\nAliases\n\n\nStandard Aliases\n\n\nHow to update ConEmu within Cmder\n\n\nLinks\n\n\n\n\n\n\nFar Manager\n\n\nAdd Far Manager to the Windows context menu\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConEmu\n#\n\n\nHere is the main link to \nConemu\n website. \n\n\nShow Branch Name on Command Line\n#\n\n\nRun \nGitShowBranch /i\n to install showing branch, \nGitShowBranch /u\n to uninstall.\n\n\nAlso, you may run your \ncmd\n as following (within Task contents or ConEmu\ns Command line)\n\n\ncmd /k ver \n GitShowBranch /i\n\n\n\n\n\n\n\nDon\nt forget to recreate the console window!\n\n\nIf you changed the command line in the settings, you have to completely recreate the console window. Otherwise, you will not see the changes.\n\n\n\n\n\n\nAdd ConEmu to the Windows context menu\n#\n\n\nIt is convenient to be able to open the \nConEmu\n console at the current location. You would then want to be able to either\n\n\n\n\nright click either on the folder itself, or \n\n\nright click inside the white area within the folder open in the \nWindows Explorer\n.\n\n\n\n\nCreate (if not already created by the \nConEmu\n installation itself) the same group of keys and string values in the \nWindows Registry\n in the following two locations respectively:\n\n\n\n\nHCR/Directory/shell\n\n\nHCR/Directory/Background/shell\n\n\n\n\nKey: \nConEmu Here\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nData\n\n\n\n\n\n\n\n\n\n\n(Default)\n\n\nREG_SZ\n\n\n(value not set)\n\n\n\n\n\n\nIcon\n\n\nREG_SZ\n\n\nC:\\Program Files\\ConEmu\\ConEmu64.exe,0\n\n\n\n\n\n\n\n\nSubkey: \ncommand\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nData\n\n\n\n\n\n\n\n\n\n\n(Default)\n\n\nREG_SZ\n\n\n\"C:\\Program Files\\ConEmu\\ConEmu64.exe\" -here -run {cmd}\n-cur_console:n\n\n\n\n\n\n\n\n\nYou can also create the \nAdmin\n version of the same command with minimal changes:\n\n\n\n\nKey: \nConEmu Here (Admin)\n\n\nreplace \n:n\n with \n:a\n at the end of the \ncommand\n \nData\n value: \n-cur_console:a\n\n\n\n\n\n\nTODO\n\n\nIt would also be nice to be able to open the \nConEmu\n folder from within the \nFar Manager\n window.\n\n\n\n\n\n\nCmder\n#\n\n\nThis tool combines most of the features of \nConemu\n and \nClink\n.\n\n\nEnvironment variables\n#\n\n\n\n\nNo spaces in the path names!\n\n\nMake sure there are no spaces in the path. If necessary, substitute those paths with their short versions. You can find them by running \ndir /X\n in their parent directory.\n\n\n\n\nAdd the following environment system variables to Windows according to your specific situation:\n\n\nCMDER_ROOT = C:\\PROGRA~1\\Cmder\n\n\nAdd the path to \nCmder.exe\n to the \nPATH\n variable:\n\n\nC:\\PROGRA~1\\Cmder\n\n\nShortcut to open Cmder in a chosen folder\n#\n\n\n\n\nOpen a terminal as an \nAdministrator\n\n\nNavigate to the directory in which you have placed \nCmder\n\n\nExecute \n.\\cmder.exe /REGISTER ALL\n. If you get \nAccess Denied\n ensure you are executing the command in an \nAdministrator\n prompt\n\n\n\n\nIn the Windows explorer window right click in or on a directory to see \nCmder Here\n in the context menu.\n\n\nConfiguring Tasks\n#\n\n\nHere is a good example of how to configure the environment for editing files not related to Visual Studio and .NET. Another neat functionality are customized Tasks. Use those to store different project workspaces. One task equals one workspace. Thanks to that it is possible to easily start another \nproject\n and initialize it by opening specific folders and specific files in Vim. It is a lot faster than doing everything manually.\n\n\nIn the Settings navigate to \nStartup -\n Tasks\n and create a new predefined task with a \n+\n sign. Then add this code:\n\n\n-new_console:d:C:\n\\U\nsers\n\\m\nfranc\n\\D\nropbox \n%ProgramFiles(x86)%\\Vim\\vim80\\vim.exe\n /k\n-new_console:d:D:\n\\ \n%ProgramFiles%\\Vim\\vim74\\vim.exe\n /k -cur_console:n\n-cur_console:d:D:\n\\ \n%ProgramFiles%\\Git\\bin\\sh.exe\n --login -i -cur_console:n:sT25V\n-cur_console:d:D:\n\\ \n%ProgramFiles%\\Git\\bin\\sh.exe\n --login -i cur_console:n:sT66H cmd.exe -new_console:d:D:\n\\ \n-i -cur_console:n:sT50H\n\n\n\n\n\nWhat does those commands do? \n\n\n\n\nCreates new screen and opens Vim in my Dropbox folder context\n\n\nCreates new screen with Vim pointing to D:\\\n\n\nInitializes shell in this new window and splits current screen into \n75%/25% horizontaly\n\n\nInitializes shell in new (25%) window and splits it up into \n33.3%/66.6% vertically\n. Then initializes shell in the new (66.6%) window and splits it up into \n50%/50% vertically\n.\n\n\n\n\nAliases\n#\n\n\nYou can create an alias to any command by an \nalias\n command, e.g.:\n\n\nalias\n \npush\n=\ngit push -u \n$*\n\n\n\n\n\n\n\n\nNo space in between!\n\n\nMake sure there is no space between the alias and the equality sign \n=\n\n\n\n\nUndo the alias by \nunalias push\n.\n\n\nThe aliases can be found in \nconfig\n subdirectory of the cmder install directory in the \nuser-aliases.cmd\n file or by running \nalias\n command with no parameters.\n\n\nStandard Aliases\n#\n\n\n\n\ncmderr\n - open cmder window in the cmder install directory, e.g. \nC:\\Program Files\\Cmder\n\n\nhistory\n - show latest commands\n\n\n\n\nHow to update ConEmu within Cmder\n#\n\n\nMaximus5\n, the author of Cmder, explains how to update ConEmu to a new version. Current Cmder can contain an older ConEmu version. To update ConEmu, get the new package from the \nConEmu website\n and copy its content to \nyour cmder installation\n/vendor/conemu-maximus5 folder.\n\n\nLinks\n#\n\n\n\n\nCmder: Super Command Line Tool Window\n\n\n\n\n\n\nFar Manager\n#\n\n\nAdd Far Manager to the Windows context menu\n#\n\n\nIt is convenient to be able to open the \nFar Manager\n at the current location. You would then want to be able to either\n\n\n\n\nright click either on the folder itself, or \n\n\nright click inside the white area within the folder open in the \nWindows Explorer\n.\n\n\n\n\nCreate or rename (if already created by the \nFar Manager\n installation) the same group of keys and string values in the \nWindows Registry\n in the following two locations respectively:\n\n\n\n\nHCR/Directory/shell\n\n\nHCR/Directory/Background/shell\n\n\n\n\nKey: \nFar Here\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nData\n\n\n\n\n\n\n\n\n\n\n(Default)\n\n\nREG_SZ\n\n\n(value not set)\n\n\n\n\n\n\nIcon\n\n\nREG_SZ\n\n\nC:\\Program Files\\Far Manager\\Far.exe,0\n\n\n\n\n\n\n\n\nSubkey: \ncommand\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nData\n\n\n\n\n\n\n\n\n\n\n(Default)\n\n\nREG_SZ\n\n\n\"C:\\Program Files\\Far Manager\\Far.exe\"\n \n\"%\nX\n\" \"%\nX\n\"\n\n\n\n\n\n\n\n\n\n\nReplace X with a number!\n\n\nIn the \nshell\n, replace X with \n1\n and in the \nBackground/shell\n with \n2\n.", 
            "title": "Tools"
        }, 
        {
            "location": "/git/tools/#git-command-line-tools", 
            "text": "Git Command Line Tools  ConEmu  Show Branch Name on Command Line  Add ConEmu to the Windows context menu    Cmder  Environment variables  Shortcut to open Cmder in a chosen folder  Configuring Tasks  Aliases  Standard Aliases  How to update ConEmu within Cmder  Links    Far Manager  Add Far Manager to the Windows context menu", 
            "title": "Git Command Line Tools"
        }, 
        {
            "location": "/git/tools/#conemu", 
            "text": "Here is the main link to  Conemu  website.", 
            "title": "ConEmu"
        }, 
        {
            "location": "/git/tools/#show-branch-name-on-command-line", 
            "text": "Run  GitShowBranch /i  to install showing branch,  GitShowBranch /u  to uninstall.  Also, you may run your  cmd  as following (within Task contents or ConEmu s Command line)  cmd /k ver   GitShowBranch /i   Don t forget to recreate the console window!  If you changed the command line in the settings, you have to completely recreate the console window. Otherwise, you will not see the changes.", 
            "title": "Show Branch Name on Command Line"
        }, 
        {
            "location": "/git/tools/#add-conemu-to-the-windows-context-menu", 
            "text": "It is convenient to be able to open the  ConEmu  console at the current location. You would then want to be able to either   right click either on the folder itself, or   right click inside the white area within the folder open in the  Windows Explorer .   Create (if not already created by the  ConEmu  installation itself) the same group of keys and string values in the  Windows Registry  in the following two locations respectively:   HCR/Directory/shell  HCR/Directory/Background/shell   Key:  ConEmu Here     Name  Type  Data      (Default)  REG_SZ  (value not set)    Icon  REG_SZ  C:\\Program Files\\ConEmu\\ConEmu64.exe,0     Subkey:  command     Name  Type  Data      (Default)  REG_SZ  \"C:\\Program Files\\ConEmu\\ConEmu64.exe\" -here -run {cmd} -cur_console:n     You can also create the  Admin  version of the same command with minimal changes:   Key:  ConEmu Here (Admin)  replace  :n  with  :a  at the end of the  command   Data  value:  -cur_console:a    TODO  It would also be nice to be able to open the  ConEmu  folder from within the  Far Manager  window.", 
            "title": "Add ConEmu to the Windows context menu"
        }, 
        {
            "location": "/git/tools/#cmder", 
            "text": "This tool combines most of the features of  Conemu  and  Clink .", 
            "title": "Cmder"
        }, 
        {
            "location": "/git/tools/#environment-variables", 
            "text": "No spaces in the path names!  Make sure there are no spaces in the path. If necessary, substitute those paths with their short versions. You can find them by running  dir /X  in their parent directory.   Add the following environment system variables to Windows according to your specific situation:  CMDER_ROOT = C:\\PROGRA~1\\Cmder  Add the path to  Cmder.exe  to the  PATH  variable:  C:\\PROGRA~1\\Cmder", 
            "title": "Environment variables"
        }, 
        {
            "location": "/git/tools/#shortcut-to-open-cmder-in-a-chosen-folder", 
            "text": "Open a terminal as an  Administrator  Navigate to the directory in which you have placed  Cmder  Execute  .\\cmder.exe /REGISTER ALL . If you get  Access Denied  ensure you are executing the command in an  Administrator  prompt   In the Windows explorer window right click in or on a directory to see  Cmder Here  in the context menu.", 
            "title": "Shortcut to open Cmder in a chosen folder"
        }, 
        {
            "location": "/git/tools/#configuring-tasks", 
            "text": "Here is a good example of how to configure the environment for editing files not related to Visual Studio and .NET. Another neat functionality are customized Tasks. Use those to store different project workspaces. One task equals one workspace. Thanks to that it is possible to easily start another  project  and initialize it by opening specific folders and specific files in Vim. It is a lot faster than doing everything manually.  In the Settings navigate to  Startup -  Tasks  and create a new predefined task with a  +  sign. Then add this code:  -new_console:d:C: \\U sers \\m franc \\D ropbox  %ProgramFiles(x86)%\\Vim\\vim80\\vim.exe  /k\n-new_console:d:D: \\  %ProgramFiles%\\Vim\\vim74\\vim.exe  /k -cur_console:n\n-cur_console:d:D: \\  %ProgramFiles%\\Git\\bin\\sh.exe  --login -i -cur_console:n:sT25V\n-cur_console:d:D: \\  %ProgramFiles%\\Git\\bin\\sh.exe  --login -i cur_console:n:sT66H cmd.exe -new_console:d:D: \\  -i -cur_console:n:sT50H  What does those commands do?    Creates new screen and opens Vim in my Dropbox folder context  Creates new screen with Vim pointing to D:\\  Initializes shell in this new window and splits current screen into  75%/25% horizontaly  Initializes shell in new (25%) window and splits it up into  33.3%/66.6% vertically . Then initializes shell in the new (66.6%) window and splits it up into  50%/50% vertically .", 
            "title": "Configuring Tasks"
        }, 
        {
            "location": "/git/tools/#aliases", 
            "text": "You can create an alias to any command by an  alias  command, e.g.:  alias   push = git push -u  $*    No space in between!  Make sure there is no space between the alias and the equality sign  =   Undo the alias by  unalias push .  The aliases can be found in  config  subdirectory of the cmder install directory in the  user-aliases.cmd  file or by running  alias  command with no parameters.", 
            "title": "Aliases"
        }, 
        {
            "location": "/git/tools/#standard-aliases", 
            "text": "cmderr  - open cmder window in the cmder install directory, e.g.  C:\\Program Files\\Cmder  history  - show latest commands", 
            "title": "Standard Aliases"
        }, 
        {
            "location": "/git/tools/#how-to-update-conemu-within-cmder", 
            "text": "Maximus5 , the author of Cmder, explains how to update ConEmu to a new version. Current Cmder can contain an older ConEmu version. To update ConEmu, get the new package from the  ConEmu website  and copy its content to  your cmder installation /vendor/conemu-maximus5 folder.", 
            "title": "How to update ConEmu within Cmder"
        }, 
        {
            "location": "/git/tools/#links", 
            "text": "Cmder: Super Command Line Tool Window", 
            "title": "Links"
        }, 
        {
            "location": "/git/tools/#far-manager", 
            "text": "", 
            "title": "Far Manager"
        }, 
        {
            "location": "/git/tools/#add-far-manager-to-the-windows-context-menu", 
            "text": "It is convenient to be able to open the  Far Manager  at the current location. You would then want to be able to either   right click either on the folder itself, or   right click inside the white area within the folder open in the  Windows Explorer .   Create or rename (if already created by the  Far Manager  installation) the same group of keys and string values in the  Windows Registry  in the following two locations respectively:   HCR/Directory/shell  HCR/Directory/Background/shell   Key:  Far Here     Name  Type  Data      (Default)  REG_SZ  (value not set)    Icon  REG_SZ  C:\\Program Files\\Far Manager\\Far.exe,0     Subkey:  command     Name  Type  Data      (Default)  REG_SZ  \"C:\\Program Files\\Far Manager\\Far.exe\"   \"% X \" \"% X \"      Replace X with a number!  In the  shell , replace X with  1  and in the  Background/shell  with  2 .", 
            "title": "Add Far Manager to the Windows context menu"
        }, 
        {
            "location": "/git/styling/", 
            "text": "Git Prompt Styling\n#\n\n\n\n\n\n\nGit Prompt Styling\n\n\nPowerline Fonts\n\n\nCmder\n\n\nMain Font\n\n\nColor Scheme\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPowerline Fonts\n#\n\n\nTaken from the \nPowerline fonts\n repository. Start by cloning:\n\n\ngit clone https://github.com/powerline/fonts.git\n\ncd\n fonts\n\n\n\n\n\nIn \nbash\n prompt install the fonts like this:\n\n\n./install.sh\n\n\n\n\n\nand in \nPowershell\n as Administrator like this:\n\n\n./install.ps1\n\n\n\n\n\nInstall for Python:\n\n\npip install powerline-status\n\n\n\n\n\nor just for the current user:\n\n\npip install --user powerline-status\n\n\n\n\n\n\n\nCmder\n#\n\n\nMain Font\n#\n\n\nI like these fonts for the terminal:\n\n\n\n\nRoboto Mono for Powerline\n\n\nDroid Sans Mono Slashed for Powerline\n\n\nAnonymice Powerline\n\n\n\n\nColor Scheme\n#\n\n\nI like \nMurena Scheme\n with some tweaks in \nFeatures/Colors\n:\n\n\n\n\n\n\n\n\nPosition\n\n\nColor Code\n\n\nRole\n\n\n\n\n\n\n\n\n\n\n0\n\n\n0 43 54\n\n\nscreen background color\n\n\n\n\n\n\nidem\n\n\n38 42 47\n\n\nidem\n\n\n\n\n\n\n1/4\n\n\n0 65 100\n\n\npath background color\n\n\n\n\n\n\n2\n\n\n60 154 6\n\n\nclean branch - green\n\n\n\n\n\n\n6/3\n\n\n196 160 0\n\n\ndirty branch - yellow", 
            "title": "Styling"
        }, 
        {
            "location": "/git/styling/#git-prompt-styling", 
            "text": "Git Prompt Styling  Powerline Fonts  Cmder  Main Font  Color Scheme", 
            "title": "Git Prompt Styling"
        }, 
        {
            "location": "/git/styling/#powerline-fonts", 
            "text": "Taken from the  Powerline fonts  repository. Start by cloning:  git clone https://github.com/powerline/fonts.git cd  fonts  In  bash  prompt install the fonts like this:  ./install.sh  and in  Powershell  as Administrator like this:  ./install.ps1  Install for Python:  pip install powerline-status  or just for the current user:  pip install --user powerline-status", 
            "title": "Powerline Fonts"
        }, 
        {
            "location": "/git/styling/#cmder", 
            "text": "", 
            "title": "Cmder"
        }, 
        {
            "location": "/git/styling/#main-font", 
            "text": "I like these fonts for the terminal:   Roboto Mono for Powerline  Droid Sans Mono Slashed for Powerline  Anonymice Powerline", 
            "title": "Main Font"
        }, 
        {
            "location": "/git/styling/#color-scheme", 
            "text": "I like  Murena Scheme  with some tweaks in  Features/Colors :     Position  Color Code  Role      0  0 43 54  screen background color    idem  38 42 47  idem    1/4  0 65 100  path background color    2  60 154 6  clean branch - green    6/3  196 160 0  dirty branch - yellow", 
            "title": "Color Scheme"
        }, 
        {
            "location": "/git/ssh/", 
            "text": "Set up SSH\n#\n\n\n\n\n\n\nSet up SSH\n\n\nRequirements\n\n\nManage SSH keys on your local Windows machine\n\n\nAdd a new SSH key via PUTTYGEN\n\n\nAdd a new SSH key via SSH-KEYGEN\n\n\nAdd config file for SSH\n\n\nTest the connection\n\n\n\n\n\n\nHow to clone the remote private repo via SSH\n\n\n\n\n\n\n\n\n\n\n\n\nRequirements\n#\n\n\n\n\ninstall the latest full version of \nGit Extenstions\n\n\nstart command prompt and check that \ngit --version\n shows no error\n\n\nadd a new Windows environment variable: \nGIT_SSH = C:\\Program Files (x86)\\GitExtensions\\PuTTY\n\n\nAdd the path of the \nPuTTY\n directory to the System \nPATH\n variable: \nC:\\Program Files (x86)\\GitExtensions\\PuTTY\n\n\n\n\n\n\nManage SSH keys on your local Windows machine\n#\n\n\nSSH keys are stored locally in \n%USERPROFILE%/.ssh\n directory. If it does not exist, create one.\n\n\nAdd a new SSH key via PUTTYGEN\n#\n\n\n\n\nOpen your command prompt and type \nputtygen\n. This will open the generator screen.\n\n\nClick \nGenerate\n to generate a new key and move your mouse across the white area.\n\n\nType in the passphrase (\nremember it wel!\n) and save the private key to \n%USERPROFILE%\\.ssh\n directory as \nid_rsa.ppk\n.\n\n\n\n\nAlso, save the \nOpenSSH\n version of the key as \nid_rsa\n file via the top menu \nConversions\n -\n \nExport OpenSSH key\n.\n\n\n\n\nAdd a new SSH key via SSH-KEYGEN\n#\n\n\n\n\nAlternatively, you can generate the key via \nssh-keygen\n command\n\n\nSave the key as \nid_rsa\n file in \n.ssh\n directory\n\n\nOpen \nputtygen\n and load the generated key\n\n\nSave the corresponding private key as above for Puttygen\n\n\n\n\nAdd config file for SSH\n#\n\n\n\n\nIn your \n.ssh\n directory create an empty \nconfig\n textfile (no extension)\n\n\nFor your remote host, e.g. BitBucket, add the configuration information. It will look something like this:\n\n\n\n\n    Host BITBUCKET\n    Hostname bitbucket.org\n    User your-user-name-on-bitbucket\n    PubKeyAuthentication yes\n    IdentityFile id_rsa\n\n\n\n\n\nTest the connection\n#\n\n\n\n\nrun \nssh -T git@bitbucket.org\n\n\nyou may see something like this:\n\n\n\n\n    key_load_public: invalid format\n    Enter passphrase for key \n/c/Users/Andre/.ssh/id_rsa\n:\n    logged in as Madrusnl.\n\n    You can use git or hg to connect to Bitbucket. Shell access is disabled.\n\n\n\n\n\n\n\nyou may ignore the \ninvalid format\n error if you see the rest\n\n\notherwise you can do some \ntroubleshooting\n:\n\n\nuse \n-vvv\n option: \nssh -T git@bitbucket.org -vvv\n\n\nmake sure you have registered your PUBLIC key (.pub) on the (BitBucket) server\n\n\nmake sure your \nIdentiyFile\n variable in the \nconfig\n file points to your PRIVATE key (without extension).\n\n\n\n\n\n\n\n\n\n\nHow to clone the remote private repo via SSH\n#\n\n\n\n\nmake sure you have the private key for the remote repo in \n.ssh\n folder, e.g. \nid_rsa.ppk\n (otherwise create it as described hereabove)\n\n\ncreate the local folder to which you wish to clone the remote repo\n\n\ninitialize the empty git repo in it by \ngit init\n\n\nopen the repo with \nGit Extensions\n\n\nin its menu, go to \nRepository\n, \nRemote repositories...\n and create a new remote repository. Call it \norigin\n (or any other name you like). \n\n\nCopy the SSH url of the BitBucket repo and paste it in the \nUrl\n field\n\n\nFor the \nPuTTY SSH\n field, browse to the private key in \n.ssh\n directory and pick it up\n\n\n\n\nClick on \nLoad SSH key\n and type in your passphrase for the private key\n\n\nTest connection with \nTest connection\n\n\nIf everything is ok, save changes and close\n\n\nClick on the light blue down arrow, choose \nPull\n, fill in the right remote branch, e.g. \nmaster\n and choose \nMerge remote branch into current branch\n\n\n\n\nClick the \nPull\n button\n\n\nIf everything went fine, you should now see the branch tree with all the commits", 
            "title": "SSH"
        }, 
        {
            "location": "/git/ssh/#set-up-ssh", 
            "text": "Set up SSH  Requirements  Manage SSH keys on your local Windows machine  Add a new SSH key via PUTTYGEN  Add a new SSH key via SSH-KEYGEN  Add config file for SSH  Test the connection    How to clone the remote private repo via SSH", 
            "title": "Set up SSH"
        }, 
        {
            "location": "/git/ssh/#requirements", 
            "text": "install the latest full version of  Git Extenstions  start command prompt and check that  git --version  shows no error  add a new Windows environment variable:  GIT_SSH = C:\\Program Files (x86)\\GitExtensions\\PuTTY  Add the path of the  PuTTY  directory to the System  PATH  variable:  C:\\Program Files (x86)\\GitExtensions\\PuTTY", 
            "title": "Requirements"
        }, 
        {
            "location": "/git/ssh/#manage-ssh-keys-on-your-local-windows-machine", 
            "text": "SSH keys are stored locally in  %USERPROFILE%/.ssh  directory. If it does not exist, create one.", 
            "title": "Manage SSH keys on your local Windows machine"
        }, 
        {
            "location": "/git/ssh/#add-a-new-ssh-key-via-puttygen", 
            "text": "Open your command prompt and type  puttygen . This will open the generator screen.  Click  Generate  to generate a new key and move your mouse across the white area.  Type in the passphrase ( remember it wel! ) and save the private key to  %USERPROFILE%\\.ssh  directory as  id_rsa.ppk .   Also, save the  OpenSSH  version of the key as  id_rsa  file via the top menu  Conversions  -   Export OpenSSH key .", 
            "title": "Add a new SSH key via PUTTYGEN"
        }, 
        {
            "location": "/git/ssh/#add-a-new-ssh-key-via-ssh-keygen", 
            "text": "Alternatively, you can generate the key via  ssh-keygen  command  Save the key as  id_rsa  file in  .ssh  directory  Open  puttygen  and load the generated key  Save the corresponding private key as above for Puttygen", 
            "title": "Add a new SSH key via SSH-KEYGEN"
        }, 
        {
            "location": "/git/ssh/#add-config-file-for-ssh", 
            "text": "In your  .ssh  directory create an empty  config  textfile (no extension)  For your remote host, e.g. BitBucket, add the configuration information. It will look something like this:       Host BITBUCKET\n    Hostname bitbucket.org\n    User your-user-name-on-bitbucket\n    PubKeyAuthentication yes\n    IdentityFile id_rsa", 
            "title": "Add config file for SSH"
        }, 
        {
            "location": "/git/ssh/#test-the-connection", 
            "text": "run  ssh -T git@bitbucket.org  you may see something like this:       key_load_public: invalid format\n    Enter passphrase for key  /c/Users/Andre/.ssh/id_rsa :\n    logged in as Madrusnl.\n\n    You can use git or hg to connect to Bitbucket. Shell access is disabled.   you may ignore the  invalid format  error if you see the rest  otherwise you can do some  troubleshooting :  use  -vvv  option:  ssh -T git@bitbucket.org -vvv  make sure you have registered your PUBLIC key (.pub) on the (BitBucket) server  make sure your  IdentiyFile  variable in the  config  file points to your PRIVATE key (without extension).", 
            "title": "Test the connection"
        }, 
        {
            "location": "/git/ssh/#how-to-clone-the-remote-private-repo-via-ssh", 
            "text": "make sure you have the private key for the remote repo in  .ssh  folder, e.g.  id_rsa.ppk  (otherwise create it as described hereabove)  create the local folder to which you wish to clone the remote repo  initialize the empty git repo in it by  git init  open the repo with  Git Extensions  in its menu, go to  Repository ,  Remote repositories...  and create a new remote repository. Call it  origin  (or any other name you like).   Copy the SSH url of the BitBucket repo and paste it in the  Url  field  For the  PuTTY SSH  field, browse to the private key in  .ssh  directory and pick it up   Click on  Load SSH key  and type in your passphrase for the private key  Test connection with  Test connection  If everything is ok, save changes and close  Click on the light blue down arrow, choose  Pull , fill in the right remote branch, e.g.  master  and choose  Merge remote branch into current branch   Click the  Pull  button  If everything went fine, you should now see the branch tree with all the commits", 
            "title": "How to clone the remote private repo via SSH"
        }, 
        {
            "location": "/vuejs/basics/", 
            "text": "Basics of Vue.js\n#\n\n\n\n\n\n\nBasics of Vue.js\n\n\nInstallation\n\n\nQuick and dirty\n\n\nNormal Development\n\n\n\n\n\n\nAvoid Vue.js DOM templates\n\n\nIn Short\n\n\nAbstract markup to components\n\n\nx-templates\n\n\n\n\n\n\nMount to an empty node with a render function\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstallation\n#\n\n\nQuick and dirty\n#\n\n\nnpm install -g vue-cli\nvue init webpack-simple my-app\n\ncd\n my-app\nyarn install\nyarn upgrade\nnpm run dev\n\n\n\n\n\nNormal Development\n#\n\n\nnpm install -g vue-cli\nvue init webpack my-app\n\ncd\n my-app\nyarn install\nyarn upgrade\nnpm run dev\n\n\n\n\n\nWhen answering questions, choose standard installation (not airbnb) unless you like to fight with eslint and prefer to use semicolons everywhere.\n\n\n\n\nAvoid Vue.js DOM templates\n#\n\n\nThis advice comes from the Anthony Gore\ns article: \nWhy You Should Avoid Vue.js DOM Templates\n. The issue he writes about is that Vue.js DOM templates are not reliable in that they don\nt always render the DOM code you expect.\n\n\nIn Short\n#\n\n\n\n\nDOM templates are problematic as the DOM parser can mess with your markup. There\u2019s also a potential for clashes with templating engines and incompatibility with server-side rendering.\n\n\nTo minimize your DOM template, abstract your markup into components.\n\n\nTo completely eliminate your DOM template you\u2019ll need to mount your root-level component with a render function.\n\n\n\n\nSo, how can you architect a Vue.js app without a DOM template, or at least a small one?\n\n\nAbstract markup to components\n#\n\n\nYour root instance can hold some state, but generally, you want any presentational logic and markup to be abstracted to components so it\u2019s out of your DOM template.\n\n\nSingle-file components are the superior choice. If you\u2019re unable to include a build step in your project and don\u2019t like writing your templates as JavaScript strings (who does), you can try \nx-templates\n.\n\n\nx-templates\n#\n\n\nWith \nx-templates\n, your template is still defined in the page, but within a script tag, and will, therefore, avoid processing by the DOM parser. The script tag is marked with text/x-template and referenced by an id in your component definition.\n\n\nVue\n.\ncomponent\n(\nmy-component\n,\n \n{\n\n  \ntemplate\n:\n \n#my-component\n\n\n}\n\n\nscript\n \ntype\n=\ntext/x-template\n \nid\n=\nmy-component\n\n  \ndiv\nMy\n \ncomponent\n \ntemplate\n/div\n\n  \nNonStandardMarkupIsFineHere\n/\n\n\n/script\n\n\n\n\n\n\nMount to an empty node with a render function\n#\n\n\nAbstracting markup into components hits a wall when you realize you still need to declare your root-level component in the DOM template.\n\n\ndiv\n \nid\n=\napp\n\n  \n!--\n \nWe\n \nstill\n \nhave\n \na\n \nDOM\n \ntemplate\n \n:\n(\n \n--\n\n  \napp\n/app\n\n\n/div\n\n\n\n\n\n\nIf you want to totally eliminate your DOM template, you can mount your root-level component(s) with a render function.\n\n\nLet\u2019s say you have one all-encompassing component that declares the other components called \nApp\n. App can be declared with a render function and mounted to an empty node since render functions will replace their mount element.\n\n\nAutogenerated by \nvue-cli\n:\n\n\ndiv\n \nid\n=\napp\n/div\n\n\n\nnew\n \nVue\n({\n\n  \nel\n:\n \n#app\n,\n\n  \ntemplate\n:\n \nApp/\n,\n\n  \ncomponents\n:\n \n{\n \nApp\n \n}\n\n\n})\n\n\n\n\n\n\nReplace with:\n\n\ndiv\n \nid\n=\napp\n/div\n\n\n\nnew\n \nVue\n({\n\n  \nel\n:\n \n#app\n,\n\n  \ncomponents\n:\n \n{\n \nApp\n \n},\n\n  \nrender\n:\n \n(\ncreateElement\n)\n \n=\n \ncreateElement\n(\nApp\n)\n\n  \n}\n\n\n})\n\n\n\n\n\n\nAnd with that, your app is free of any DOM template!\n\n\nIf you can eliminate all string and DOM templates from your app you can use the smaller runtime-only build of Vue. This is an ideal project architecture and is the one you\u2019ll see used in vue-cli templates.", 
            "title": "Basics"
        }, 
        {
            "location": "/vuejs/basics/#basics-of-vuejs", 
            "text": "Basics of Vue.js  Installation  Quick and dirty  Normal Development    Avoid Vue.js DOM templates  In Short  Abstract markup to components  x-templates    Mount to an empty node with a render function", 
            "title": "Basics of Vue.js"
        }, 
        {
            "location": "/vuejs/basics/#installation", 
            "text": "", 
            "title": "Installation"
        }, 
        {
            "location": "/vuejs/basics/#quick-and-dirty", 
            "text": "npm install -g vue-cli\nvue init webpack-simple my-app cd  my-app\nyarn install\nyarn upgrade\nnpm run dev", 
            "title": "Quick and dirty"
        }, 
        {
            "location": "/vuejs/basics/#normal-development", 
            "text": "npm install -g vue-cli\nvue init webpack my-app cd  my-app\nyarn install\nyarn upgrade\nnpm run dev  When answering questions, choose standard installation (not airbnb) unless you like to fight with eslint and prefer to use semicolons everywhere.", 
            "title": "Normal Development"
        }, 
        {
            "location": "/vuejs/basics/#avoid-vuejs-dom-templates", 
            "text": "This advice comes from the Anthony Gore s article:  Why You Should Avoid Vue.js DOM Templates . The issue he writes about is that Vue.js DOM templates are not reliable in that they don t always render the DOM code you expect.", 
            "title": "Avoid Vue.js DOM templates"
        }, 
        {
            "location": "/vuejs/basics/#in-short", 
            "text": "DOM templates are problematic as the DOM parser can mess with your markup. There\u2019s also a potential for clashes with templating engines and incompatibility with server-side rendering.  To minimize your DOM template, abstract your markup into components.  To completely eliminate your DOM template you\u2019ll need to mount your root-level component with a render function.   So, how can you architect a Vue.js app without a DOM template, or at least a small one?", 
            "title": "In Short"
        }, 
        {
            "location": "/vuejs/basics/#abstract-markup-to-components", 
            "text": "Your root instance can hold some state, but generally, you want any presentational logic and markup to be abstracted to components so it\u2019s out of your DOM template.  Single-file components are the superior choice. If you\u2019re unable to include a build step in your project and don\u2019t like writing your templates as JavaScript strings (who does), you can try  x-templates .", 
            "title": "Abstract markup to components"
        }, 
        {
            "location": "/vuejs/basics/#x-templates", 
            "text": "With  x-templates , your template is still defined in the page, but within a script tag, and will, therefore, avoid processing by the DOM parser. The script tag is marked with text/x-template and referenced by an id in your component definition.  Vue . component ( my-component ,   { \n   template :   #my-component  }  script   type = text/x-template   id = my-component \n   div My   component   template /div \n   NonStandardMarkupIsFineHere /  /script", 
            "title": "x-templates"
        }, 
        {
            "location": "/vuejs/basics/#mount-to-an-empty-node-with-a-render-function", 
            "text": "Abstracting markup into components hits a wall when you realize you still need to declare your root-level component in the DOM template.  div   id = app \n   !--   We   still   have   a   DOM   template   : (   -- \n   app /app  /div   If you want to totally eliminate your DOM template, you can mount your root-level component(s) with a render function.  Let\u2019s say you have one all-encompassing component that declares the other components called  App . App can be declared with a render function and mounted to an empty node since render functions will replace their mount element.  Autogenerated by  vue-cli :  div   id = app /div  new   Vue ({ \n   el :   #app , \n   template :   App/ , \n   components :   {   App   }  })   Replace with:  div   id = app /div  new   Vue ({ \n   el :   #app , \n   components :   {   App   }, \n   render :   ( createElement )   =   createElement ( App ) \n   }  })   And with that, your app is free of any DOM template!  If you can eliminate all string and DOM templates from your app you can use the smaller runtime-only build of Vue. This is an ideal project architecture and is the one you\u2019ll see used in vue-cli templates.", 
            "title": "Mount to an empty node with a render function"
        }, 
        {
            "location": "/mac/nginx/", 
            "text": "Web Server on MacBook Pro\n#\n\n\nIt is possible to run different web servers on a Mac. I prefer \nNGINX\n to Apache.\n\n\nNGINX\n#\n\n\nInstallation\n#\n\n\nPrep work:\n\n\nbrew doctor\nbrew update\nbrew upgrade\n\n\n\n\n\nInstallation:\n\n\nbrew install nginx\nbrew services start nginx\nbrew services stop nginx\n\n\n\n\n\nUse these commands to start, stop or restart the nginx server:\n\n\nsudo nginx\nsudo nginx -s stop\nsudo nginx -s reload\n\n\n\n\n\nnginx.conf\n#\n\n\nIn the root of the main HDD, create a new \nwww\n directory and inside it another two subdirectories: \nhome\n and \nsites\n.\n\n\nNow, we can edit the \nnginx.conf\n file to point the root server at \n/www/sites\n and listen on port \n80\n. We can use VI or NANO for that:\n\n\nsudo vi /usr/local/etc/nginx/nginx.conf\nsudo nano /usr/local/etc/nginx/nginx.conf\n\n\n\n\n\nScroll to the second screen and you will see something like this:\n\n\nserver\n \n{\n\n        \nlisten\n       \n8080\n;\n\n        \nserver_name\n  \nlocalhost\n;\n\n\n        \n#charset koi8-r;\n\n\n        \n#access_log  logs/host.access.log  main;\n\n\n        \nlocation\n \n/\n \n{\n\n            \nroot\n   \nhtml\n;\n\n            \nindex\n  \nindex\n.\nhtml\n \nindex\n.\nhtm\n;\n\n        \n}\n\n        \n...\n\n\n}\n\n\n\n\n\n\nChange \n8080\n to \n80\n and \nroot html;\n to \n/www/sites\n or whatever other root path we created. \n\n\n\n\nErrors 500\n\n\nThere is another chunk of code after \nlocation\n, which deals with \n500\n errors that also has \nroot html\n setting. Possibly, it should also be changed in the same way.\n\n\n\n\nAnciliary Tools\n#\n\n\ndsnmasq\n#\n\n\nThis is a great little tool that allows us to use wildcard subdomain names. With the default apache settings, we can add as many sites as we like in subfolders of the web root, e.g.:\n\n\n\n\nhttp://home.dev/client1\n\n\nhttp://home.dev/client2\n\n\nhttp://home.dev/client3\n\n\n\n\nHowever, that creates a problem. When we have each site in a folder, it\u2019s more difficult to manage the settings for each site. Each one must then have a different absolute root. The solution is to create a subdomain for each site, and use URLs like these:\n\n\n\n\nhttp://client1.dev\n\n\nhttp://client2.dev\n\n\nhttp://client3.dev\n\n\n\n\nWe can accomplish this by placing all three sites in our \n/private/etc/hosts\n file, but then we need to keep adding entries every time we add a new site. \n\n\n\n\ndnsmasq\n allows us to do this by interrupting each request that ends with .dev and forwarding it to a designated IP address (127.0.0.1 in our case).\n\n\n\n\nThe following commands will install \ndnsmasq\n, configure it to point all requests to the .dev top-level domain to our local machine, and make sure it starts up and runs all of the time.\n\n\nbrew install dnsmasq\n\ncd\n \n$(\nbrew --prefix\n)\n;\n mkdir etc\n;\n \necho\n \naddress=/.dev/127.0.0.1\n \n etc/dnsmasq.conf\nsudo cp -v \n$(\nbrew --prefix dnsmasq\n)\n/homebrew.mxcl.dnsmasq.plist /Library/LaunchDaemons\nsudo launchctl load -w /Library/LaunchDaemons/homebrew.mxcl.dnsmasq.plist\nsudo mkdir /etc/resolver\nsudo bash -c \necho \nnameserver 127.0.0.1\n \n /etc/resolver/dev\n\n\n\n\n\n\nIf all goes well, we\u2019ll never need to think about it again.", 
            "title": "NGINX"
        }, 
        {
            "location": "/mac/nginx/#web-server-on-macbook-pro", 
            "text": "It is possible to run different web servers on a Mac. I prefer  NGINX  to Apache.", 
            "title": "Web Server on MacBook Pro"
        }, 
        {
            "location": "/mac/nginx/#nginx", 
            "text": "", 
            "title": "NGINX"
        }, 
        {
            "location": "/mac/nginx/#installation", 
            "text": "Prep work:  brew doctor\nbrew update\nbrew upgrade  Installation:  brew install nginx\nbrew services start nginx\nbrew services stop nginx  Use these commands to start, stop or restart the nginx server:  sudo nginx\nsudo nginx -s stop\nsudo nginx -s reload", 
            "title": "Installation"
        }, 
        {
            "location": "/mac/nginx/#nginxconf", 
            "text": "In the root of the main HDD, create a new  www  directory and inside it another two subdirectories:  home  and  sites .  Now, we can edit the  nginx.conf  file to point the root server at  /www/sites  and listen on port  80 . We can use VI or NANO for that:  sudo vi /usr/local/etc/nginx/nginx.conf\nsudo nano /usr/local/etc/nginx/nginx.conf  Scroll to the second screen and you will see something like this:  server   { \n         listen         8080 ; \n         server_name    localhost ; \n\n         #charset koi8-r; \n\n         #access_log  logs/host.access.log  main; \n\n         location   /   { \n             root     html ; \n             index    index . html   index . htm ; \n         } \n         ...  }   Change  8080  to  80  and  root html;  to  /www/sites  or whatever other root path we created.    Errors 500  There is another chunk of code after  location , which deals with  500  errors that also has  root html  setting. Possibly, it should also be changed in the same way.", 
            "title": "nginx.conf"
        }, 
        {
            "location": "/mac/nginx/#anciliary-tools", 
            "text": "", 
            "title": "Anciliary Tools"
        }, 
        {
            "location": "/mac/nginx/#dsnmasq", 
            "text": "This is a great little tool that allows us to use wildcard subdomain names. With the default apache settings, we can add as many sites as we like in subfolders of the web root, e.g.:   http://home.dev/client1  http://home.dev/client2  http://home.dev/client3   However, that creates a problem. When we have each site in a folder, it\u2019s more difficult to manage the settings for each site. Each one must then have a different absolute root. The solution is to create a subdomain for each site, and use URLs like these:   http://client1.dev  http://client2.dev  http://client3.dev   We can accomplish this by placing all three sites in our  /private/etc/hosts  file, but then we need to keep adding entries every time we add a new site.    dnsmasq  allows us to do this by interrupting each request that ends with .dev and forwarding it to a designated IP address (127.0.0.1 in our case).   The following commands will install  dnsmasq , configure it to point all requests to the .dev top-level domain to our local machine, and make sure it starts up and runs all of the time.  brew install dnsmasq cd   $( brew --prefix ) ;  mkdir etc ;   echo   address=/.dev/127.0.0.1    etc/dnsmasq.conf\nsudo cp -v  $( brew --prefix dnsmasq ) /homebrew.mxcl.dnsmasq.plist /Library/LaunchDaemons\nsudo launchctl load -w /Library/LaunchDaemons/homebrew.mxcl.dnsmasq.plist\nsudo mkdir /etc/resolver\nsudo bash -c  echo  nameserver 127.0.0.1    /etc/resolver/dev   If all goes well, we\u2019ll never need to think about it again.", 
            "title": "dsnmasq"
        }, 
        {
            "location": "/umbraco/technicalities/", 
            "text": "Some technical details\n#\n\n\n\n\n\n\nSome technical details\n\n\nUsing SSL in Production\n\n\nStep 1 \n Configure the Production web server\n\n\nStep 2 \n Create the SSL Certificate\n\n\nStep 3 \n Add transformations to the Web.Release.config file\n\n\n\n\n\n\nrobots.txt\n\n\n\n\n\n\n\n\n\n\n\n\nUsing SSL in Production\n#\n\n\n(This is a tip of \nSebastiaan Janssen\n at \nOur Umbraco\n.)\n\n\nOur aim is to use \nSSL\n in Production and to issue an \nautomatic 301-redirect\n for any non-secure url within the domain. For example,\n\n\n\n\nmydomain.com =\n https://mydomain.com\n\n\nwww.mydomain.com =\n https://www.mydomain.com\n\n\n\n\nIn order to achieve this, several things have to be done. This is based on GoDaddy\ns hosting, so for SSL one needs to buy their\n\n\n\n\nGoDaddy does not specialize on Windows hosting\n\n\nUnfortunately, the Windows hosting support of GoDaddy ends up when the place there minimal \nindex.html\n file in the root directory and can successfully view that page in the browser.\n\n\n\n\nStep 1 \n Configure the Production web server\n#\n\n\nGo to \nWebsites \n Domains\n and choose \nWeb Server Settings\n. Check \nRequire SSL\n checkbox to prevent non-secure access to the website. Don\nt forget to save the changes.\n\n\nStep 2 \n Create the SSL Certificate\n#\n\n\nGoDaddy offers a \nSHA-2\n type SSL-certificate.\n\n\nYou can also place the \nSSL Certificate security seal\n on your website that looks like this:\n\n\n\n\nGoDaddy provides the snippet for this. When you click on the seal, you see the confirmation:\n\n\n\n\nStep 3 \n Add transformations to the Web.Release.config file\n#\n\n\nconfiguration\n \nxmlns:xdt=\nhttp://schemas.microsoft.com/XML-Document-Transform\n\n  \nappSettings\n\n    \nadd\n \nkey=\ndebugWebErrors\n \nvalue=\nfalse\n\n      \nxdt:Transform=\nSetAttributes\n \nxdt:Locator=\nMatch(key)\n/\n\n  \n/appSettings\n\n  \nrewrite\n \nxdt:Transform=\nInsertAfter(/configuration/system.webServer/validation)\n\n    \nrules\n\n      \nrule\n \nname=\nRedirect to https\n \nstopProcessing=\ntrue\n\n        \nmatch\n \nurl=\n(.*)\n \n/\n\n        \nconditions\n\n          \nadd\n \ninput=\n{HTTPS}\n \npattern=\noff\n \nignoreCase=\ntrue\n \n/\n\n        \n/conditions\n\n        \naction\n \ntype=\nRedirect\n \nurl=\nhttps://{HTTP_HOST}{REQUEST_URI}\n \n                \nredirectType=\nPermanent\n \nappendQueryString=\nfalse\n \n/\n\n      \n/rule\n\n    \n/rules\n\n  \n/rewrite\n\n\n/configuration\n\n\n\n\n\n\n\n\nURL Rewriting plugin\n\n\nNote that the above rewrite only works if the URL Rewriting plugin for IIS has been installed on the server.\n\n\n\n\nYou\nll also need to update all your templates if they refer to (for example) fonts on a CDN, the easiest way to do that is to not give it the scheme (http or https). So instead of:\n\n\nlink\n \nhref\n=\nhttp://fonts.googleapis.com/css?family=Open+Sans:400,700\n\n\ntype\n=\ntext/css\n \nrel\n=\nstylesheet\n/\n\n\n\n\n\n\nyou can make:\n\n\nlink\n \nhref\n=\n//fonts.googleapis.com/css?family=Open+Sans:400,700\n\n\ntype\n=\ntext/css\n \nrel\n=\nstylesheet\n/\n\n\n\n\n\n\nNotice that \nhttp:\n has been removed. This way it will load over both https and also over http (if you ever decide to revert to http).\n\n\n\n\nrobots.txt\n#\n\n\n\n\ninstall \nCultiv DynamicRobots\n and \nRobots.txt Editor\n packages in the Umbraco backend.\n\n\n(I am not yet sure if this is a good option) intall the \nCultiv SearchEngineSitemap\n package, which supports multisite solutions out of the box.\n\n\nopen Developer section in the backend and you will see \nRobots.txt\n option. Click on it. Now, you can enter the code you need. Here is an example of such file for Umbraco projects:\n\n\n\n\n    # robots.txt for Umbraco\n    User-agent: *\n    Disallow: /bin/\n    Disallow: /config/\n    Disallow: /css/\n    Disallow: /data/\n    Disallow: /scripts/\n    Disallow: /umbraco/\n    Disallow: /umbraco_client/\n    Disallow: /usercontrols/\n    Sitemap: http://{HTTP_HOST}/sitemap\n\n\n\n\n\nThe interesting part here is that the \n{HTTP_HOST}\n template parameter here is dynamically substituted for the right URL when the project is deployed.\n\n\n\n\nDeployment error\n\n\nCurrently the \nCultiv.DynamicRobots.dll\n file in the \nbin\n directory is not being copied by the deployment process and has to be separately copied later.\n\n\n\n\nAlternatively, you could also create \nrobots.txt\n manually in the project root directory and make sure the link \n/robots.txt\n is redirected to \n/robotstxt\n in \n~\\Config\\UrlRewriting.config\n. For details see this article: \nHow to create a robots.txt in Umbraco and edit it from the backoffice", 
            "title": "Technicalities"
        }, 
        {
            "location": "/umbraco/technicalities/#some-technical-details", 
            "text": "Some technical details  Using SSL in Production  Step 1   Configure the Production web server  Step 2   Create the SSL Certificate  Step 3   Add transformations to the Web.Release.config file    robots.txt", 
            "title": "Some technical details"
        }, 
        {
            "location": "/umbraco/technicalities/#using-ssl-in-production", 
            "text": "(This is a tip of  Sebastiaan Janssen  at  Our Umbraco .)  Our aim is to use  SSL  in Production and to issue an  automatic 301-redirect  for any non-secure url within the domain. For example,   mydomain.com =  https://mydomain.com  www.mydomain.com =  https://www.mydomain.com   In order to achieve this, several things have to be done. This is based on GoDaddy s hosting, so for SSL one needs to buy their   GoDaddy does not specialize on Windows hosting  Unfortunately, the Windows hosting support of GoDaddy ends up when the place there minimal  index.html  file in the root directory and can successfully view that page in the browser.", 
            "title": "Using SSL in Production"
        }, 
        {
            "location": "/umbraco/technicalities/#step-1-configure-the-production-web-server", 
            "text": "Go to  Websites   Domains  and choose  Web Server Settings . Check  Require SSL  checkbox to prevent non-secure access to the website. Don t forget to save the changes.", 
            "title": "Step 1 -- Configure the Production web server"
        }, 
        {
            "location": "/umbraco/technicalities/#step-2-create-the-ssl-certificate", 
            "text": "GoDaddy offers a  SHA-2  type SSL-certificate.  You can also place the  SSL Certificate security seal  on your website that looks like this:   GoDaddy provides the snippet for this. When you click on the seal, you see the confirmation:", 
            "title": "Step 2 -- Create the SSL Certificate"
        }, 
        {
            "location": "/umbraco/technicalities/#step-3-add-transformations-to-the-webreleaseconfig-file", 
            "text": "configuration   xmlns:xdt= http://schemas.microsoft.com/XML-Document-Transform \n   appSettings \n     add   key= debugWebErrors   value= false \n       xdt:Transform= SetAttributes   xdt:Locator= Match(key) / \n   /appSettings \n   rewrite   xdt:Transform= InsertAfter(/configuration/system.webServer/validation) \n     rules \n       rule   name= Redirect to https   stopProcessing= true \n         match   url= (.*)   / \n         conditions \n           add   input= {HTTPS}   pattern= off   ignoreCase= true   / \n         /conditions \n         action   type= Redirect   url= https://{HTTP_HOST}{REQUEST_URI}  \n                 redirectType= Permanent   appendQueryString= false   / \n       /rule \n     /rules \n   /rewrite  /configuration    URL Rewriting plugin  Note that the above rewrite only works if the URL Rewriting plugin for IIS has been installed on the server.   You ll also need to update all your templates if they refer to (for example) fonts on a CDN, the easiest way to do that is to not give it the scheme (http or https). So instead of:  link   href = http://fonts.googleapis.com/css?family=Open+Sans:400,700  type = text/css   rel = stylesheet /   you can make:  link   href = //fonts.googleapis.com/css?family=Open+Sans:400,700  type = text/css   rel = stylesheet /   Notice that  http:  has been removed. This way it will load over both https and also over http (if you ever decide to revert to http).", 
            "title": "Step 3 -- Add transformations to the Web.Release.config file"
        }, 
        {
            "location": "/umbraco/technicalities/#robotstxt", 
            "text": "install  Cultiv DynamicRobots  and  Robots.txt Editor  packages in the Umbraco backend.  (I am not yet sure if this is a good option) intall the  Cultiv SearchEngineSitemap  package, which supports multisite solutions out of the box.  open Developer section in the backend and you will see  Robots.txt  option. Click on it. Now, you can enter the code you need. Here is an example of such file for Umbraco projects:       # robots.txt for Umbraco\n    User-agent: *\n    Disallow: /bin/\n    Disallow: /config/\n    Disallow: /css/\n    Disallow: /data/\n    Disallow: /scripts/\n    Disallow: /umbraco/\n    Disallow: /umbraco_client/\n    Disallow: /usercontrols/\n    Sitemap: http://{HTTP_HOST}/sitemap  The interesting part here is that the  {HTTP_HOST}  template parameter here is dynamically substituted for the right URL when the project is deployed.   Deployment error  Currently the  Cultiv.DynamicRobots.dll  file in the  bin  directory is not being copied by the deployment process and has to be separately copied later.   Alternatively, you could also create  robots.txt  manually in the project root directory and make sure the link  /robots.txt  is redirected to  /robotstxt  in  ~\\Config\\UrlRewriting.config . For details see this article:  How to create a robots.txt in Umbraco and edit it from the backoffice", 
            "title": "robots.txt"
        }, 
        {
            "location": "/umbraco/faq/", 
            "text": "Issues and solutions\n#\n\n\n\n\n\n\nIssues and solutions\n\n\nBundling and minifying\n\n\nWeb Deployment - Could not find part of the path\n\n\nQuestion\n\n\nAnswer\n\n\n\n\n\n\nWeb Deployment - Group policy prevents Roslyn\ns csc.exe from running\n\n\nQuestion\n\n\nAnswer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBundling and minifying\n#\n\n\nMost of the information comes from two articles: \nHow to bundle CSS and JS\n and \nBundling and minification in Umbraco\n.\n\n\n\n\nAdded \nApp_Start\n folder\n\n\nCreated \nBundleConfig.cs\n class with bundles for JavaScript and CSS files\n\n\nAdded \nBundleTable.EnableOptimizations = true;\n in \nBundleConfig.cs\n to be able to test bundling and minification.\n\n\nAt the same time, added \ncompilation debug=\"true\" /\n in \nsystem.web\n section of \nWeb.config\n, \ncompilation debug=\"false\" /\n in \nweb.Release.config\n.\n\n\n\n\n\n\nImportant\n\n\nEnableOptimizations\n takes precedence of \ncompilation debug\n value.\n\n\n\n\n\n\nIt is also important to make sure that \nbundles\n are included in the \numbracoReservedPaths\n:\n\n\n\n\n  \nappSettings\n\n    ...\n    \nadd\n \nkey=\numbracoReservedPaths\n \nvalue=\n~/umbraco,~/install/,~/bundles/\n \n/\n\n    ...\n  \n/appSettings\n\n\n\n\n\n\n\n\nWeb Deployment - Could not find part of the path\n#\n\n\nQuestion\n#\n\n\nError during web deploy\n\n\n\n\nCould not open Source file: Could not find a part of the path \nJ:\\U\\Ed4u\\Ed4u\\App_Plugins\\LeBlender\\Web.config;\\App_Plugins\\LeBlender\\Web.config\n.\n\n\n\n\nAnswer\n#\n\n\nFind the deployment profile \nenergydiet4u.nl - Web Deploy.pubxml\n\n\n\n\nand add the following key to the \nPropertyGroup\n section:\n\n\nAutoParameterizationWebConfigConnectionStrings\nFalse\n/AutoParameterizationWebConfigConnectionStrings\n\n\n\n\n\n\n\n\nWeb Deployment - Group policy prevents Roslyn\ns csc.exe from running\n#\n\n\nQuestion\n#\n\n\nWebsite runtime error after deployment to GoDaddy:\n\n\n\n\nAnswer\n#\n\n\nSince the .NET 4.5 version, Roslyn compilation is the default way of compiling. This means if you create any web application either Web Forms or MVC using .NET 4.5 you get this Roslyn csc.exe compilation pre-installed in your project.\n\n\n\n\nUninstall \nMicrosoft.CodeDOM.Providers.DotNetCompilerPlatform\n NuGet package, rebuild and redeploy the website\n\n\nDelete the corresponding .dll\ns from the \nbin\n directory\n\n\n\n\nNOTE\n This will be probably necessary to do every time \nUmbraco\n is upgraded.", 
            "title": "FAQ"
        }, 
        {
            "location": "/umbraco/faq/#issues-and-solutions", 
            "text": "Issues and solutions  Bundling and minifying  Web Deployment - Could not find part of the path  Question  Answer    Web Deployment - Group policy prevents Roslyn s csc.exe from running  Question  Answer", 
            "title": "Issues and solutions"
        }, 
        {
            "location": "/umbraco/faq/#bundling-and-minifying", 
            "text": "Most of the information comes from two articles:  How to bundle CSS and JS  and  Bundling and minification in Umbraco .   Added  App_Start  folder  Created  BundleConfig.cs  class with bundles for JavaScript and CSS files  Added  BundleTable.EnableOptimizations = true;  in  BundleConfig.cs  to be able to test bundling and minification.  At the same time, added  compilation debug=\"true\" /  in  system.web  section of  Web.config ,  compilation debug=\"false\" /  in  web.Release.config .    Important  EnableOptimizations  takes precedence of  compilation debug  value.    It is also important to make sure that  bundles  are included in the  umbracoReservedPaths :      appSettings \n    ...\n     add   key= umbracoReservedPaths   value= ~/umbraco,~/install/,~/bundles/   / \n    ...\n   /appSettings", 
            "title": "Bundling and minifying"
        }, 
        {
            "location": "/umbraco/faq/#web-deployment-could-not-find-part-of-the-path", 
            "text": "", 
            "title": "Web Deployment - Could not find part of the path"
        }, 
        {
            "location": "/umbraco/faq/#question", 
            "text": "Error during web deploy   Could not open Source file: Could not find a part of the path  J:\\U\\Ed4u\\Ed4u\\App_Plugins\\LeBlender\\Web.config;\\App_Plugins\\LeBlender\\Web.config .", 
            "title": "Question"
        }, 
        {
            "location": "/umbraco/faq/#answer", 
            "text": "Find the deployment profile  energydiet4u.nl - Web Deploy.pubxml   and add the following key to the  PropertyGroup  section:  AutoParameterizationWebConfigConnectionStrings False /AutoParameterizationWebConfigConnectionStrings", 
            "title": "Answer"
        }, 
        {
            "location": "/umbraco/faq/#web-deployment-group-policy-prevents-roslyns-cscexe-from-running", 
            "text": "", 
            "title": "Web Deployment - Group policy prevents Roslyn's csc.exe from running"
        }, 
        {
            "location": "/umbraco/faq/#question_1", 
            "text": "Website runtime error after deployment to GoDaddy:", 
            "title": "Question"
        }, 
        {
            "location": "/umbraco/faq/#answer_1", 
            "text": "Since the .NET 4.5 version, Roslyn compilation is the default way of compiling. This means if you create any web application either Web Forms or MVC using .NET 4.5 you get this Roslyn csc.exe compilation pre-installed in your project.   Uninstall  Microsoft.CodeDOM.Providers.DotNetCompilerPlatform  NuGet package, rebuild and redeploy the website  Delete the corresponding .dll s from the  bin  directory   NOTE  This will be probably necessary to do every time  Umbraco  is upgraded.", 
            "title": "Answer"
        }, 
        {
            "location": "/playground/todo/", 
            "text": "TODOs\n#\n\n\n\n\n\n\nTODOs\n\n\nFunctionality\n\n\nBuild and Deployment\n\n\nSEO\n\n\nLearning\n\n\nNew EGGHEAD.IO courses\n\n\nTOOLS\n\n\nREACT\n\n\n\n\n\n\nGet the excercise files\n\n\nREACT\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFunctionality\n#\n\n\n\n\nFood / Non-Food (Umbraco)\n\n\nDisqus comments (MkDocs)\n\n\nHave I set up \nindentifier\n and \nurl\n correctly?\n\n\nHow do I append \n#disqus_thread\n to the \nhref\n attribute in my links?\n\n\nAdd Disqus chapter to the Docs\n\n\n\n\n\n\n\n\n\n\nBuild and Deployment\n#\n\n\n\n\ndeployment \nCultiv.DynamicRobots.dll\n \n should be copied to the target \n/bin\n\n\nTravis CI: \nmy profile\n (MkDocs) \n how to?\n\n\n\n\n\n\nSEO\n#\n\n\n\n\nSitemap\n\n\nGoogle Search\n\n\nMicrocode snippets\n\n\nSitemap in Google and Yandex\n\n\n\n\n\n\nLearning\n#\n\n\nNew EGGHEAD.IO courses\n#\n\n\nThis is the main link of \nEGGHEAD.IO\n.\n\n\nTOOLS\n#\n\n\n\n\nDebug the DOM in Chrome with the Devtools Elements Panel\n\n\nDebug JavaScript in Chrome with DevTool Sources\n\n\nDebug HTTP with Chrome DevTools Network Panel\n\n\nDeploy Web Apps with Zeit Now\n\n\n\n\nREACT\n#\n\n\n\n\nBuild Your First React.js App\n\n\nStart Using React to Build Web Applications\n\n\nReact Native Fundamentals\n\n\nGetting Started with React Router\n\n\nReact Testing Cookbook\n\n\nReact: Flux Architecture (ES6)\n\n\nAnimate React Native UI Elements\n\n\n\n\nGet the excercise files\n#\n\n\nREACT\n#\n\n\n\n\nGetting started with Redux\n\n\nBuilding React Applications with Idiomatic Redux", 
            "title": "TODOs"
        }, 
        {
            "location": "/playground/todo/#todos", 
            "text": "TODOs  Functionality  Build and Deployment  SEO  Learning  New EGGHEAD.IO courses  TOOLS  REACT    Get the excercise files  REACT", 
            "title": "TODOs"
        }, 
        {
            "location": "/playground/todo/#functionality", 
            "text": "Food / Non-Food (Umbraco)  Disqus comments (MkDocs)  Have I set up  indentifier  and  url  correctly?  How do I append  #disqus_thread  to the  href  attribute in my links?  Add Disqus chapter to the Docs", 
            "title": "Functionality"
        }, 
        {
            "location": "/playground/todo/#build-and-deployment", 
            "text": "deployment  Cultiv.DynamicRobots.dll    should be copied to the target  /bin  Travis CI:  my profile  (MkDocs)   how to?", 
            "title": "Build and Deployment"
        }, 
        {
            "location": "/playground/todo/#seo", 
            "text": "Sitemap  Google Search  Microcode snippets  Sitemap in Google and Yandex", 
            "title": "SEO"
        }, 
        {
            "location": "/playground/todo/#learning", 
            "text": "", 
            "title": "Learning"
        }, 
        {
            "location": "/playground/todo/#new-eggheadio-courses", 
            "text": "This is the main link of  EGGHEAD.IO .", 
            "title": "New EGGHEAD.IO courses"
        }, 
        {
            "location": "/playground/todo/#tools", 
            "text": "Debug the DOM in Chrome with the Devtools Elements Panel  Debug JavaScript in Chrome with DevTool Sources  Debug HTTP with Chrome DevTools Network Panel  Deploy Web Apps with Zeit Now", 
            "title": "TOOLS"
        }, 
        {
            "location": "/playground/todo/#react", 
            "text": "Build Your First React.js App  Start Using React to Build Web Applications  React Native Fundamentals  Getting Started with React Router  React Testing Cookbook  React: Flux Architecture (ES6)  Animate React Native UI Elements", 
            "title": "REACT"
        }, 
        {
            "location": "/playground/todo/#get-the-excercise-files", 
            "text": "", 
            "title": "Get the excercise files"
        }, 
        {
            "location": "/playground/todo/#react_1", 
            "text": "Getting started with Redux  Building React Applications with Idiomatic Redux", 
            "title": "REACT"
        }, 
        {
            "location": "/playground/test/", 
            "text": "Test Document\n#\n\n\n\n\n\n\nTest Document\n\n\nTable\n\n\n\n\n\n\n\n\n\n\n\n\nTable\n#\n\n\nThis is an example of a table:\n\n\n\n\n\n\n\n\nheader1\n\n\nheader2\n\n\n\n\n\n\n\n\n\n\ncell 1.1\n\n\ncell 1.2\n\n\n\n\n\n\ncell 2.1\n\n\ncell 2.2\n\n\n\n\n\n\ncell 3.1\n\n\ncell 3.2", 
            "title": "Test Document"
        }, 
        {
            "location": "/playground/test/#test-document", 
            "text": "Test Document  Table", 
            "title": "Test Document"
        }, 
        {
            "location": "/playground/test/#table", 
            "text": "This is an example of a table:     header1  header2      cell 1.1  cell 1.2    cell 2.1  cell 2.2    cell 3.1  cell 3.2", 
            "title": "Table"
        }
    ]
}